[
  {
    "objectID": "0109CH3.html",
    "href": "0109CH3.html",
    "title": "0109CH3 多參數模型",
    "section": "",
    "text": "date: 2026/01/09 - 2026/01/10",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#ａ.-鋪陳",
    "href": "0109CH3.html#ａ.-鋪陳",
    "title": "0109CH3 多參數模型",
    "section": "Ａ. 鋪陳",
    "text": "Ａ. 鋪陳\n\n幾乎所有統計學中的實際問題都涉及不止一個未知或無法觀測的量。\n\n當拿到一組只有 3 個採樣點的數據時，你既不知道真實的平均暴露濃度（GM），也不知道真實的變異程度（GSD）。這兩個未知數彼此牽制、互相影響。如果你只盯著其中一個看（例如只看平均值），而忽略了另一個（變異程度）的不確定性，你對風險的評估就會失準，甚至可能做出錯誤的決策，導致勞工受害。\n\n在職業衛生EA中，這「不止一個未知量」通常指的就是 幾何平均數（GM） 和 幾何標準差（GSD）。\n\n這兩個參數共同決定了對數常態分佈（Lognormal Distribution）的形狀，也就是勞工暴露的分佈樣貌。\n傳統統計方法（如 t 檢定或最大似然估計）在樣本數很少時（OSH 的常態），處理這兩個未知參數往往顯得左支右絀，容易低估不確定性。\n而貝氏方法提供了一個統一的框架，讓我們能夠同時處理這些未知數。\n\n在這種情況下，貝氏分析的最終目標是獲得特定感興趣參數的「邊際後驗分佈」（marginal posterior distribution）。\n\n想像經理問你：「勞工暴露超過容許濃度（OEL）的機率是多少？」這就是「感興趣的參數」（或由參數推導出的量）。經理並不關心暴露數據的變異係數是多少，也不關心標準差的精確數值。他只關心那個核心的風險指標。\n為了回答經理的問題，我們必須把那個他不關心的、但又影響計算結果的參數（例如標準差）給「處理」掉。這個「處理」的過程，在數學上就叫做「邊際化」（Marginalization）。\n\n實現這一目標的路徑：我們首先需要所有未知數的「聯合後驗分佈」（joint posterior distribution），然後我們對那些非當前感興趣的未知數進行積分（integrate），從而獲得所需的邊際分佈。\n\n這就是貝氏分析的標準作業程序（SOP）：\n\n建立聯合模型：把 GM 和 GSD 綁在一起看，形成一座機率的「山峰」（聯合後驗分佈）。\n積分（Integration）：這是一個數學動作，相當於從側面看這座山，把所有可能的 GSD 值都加總起來，只留下我們關心的 GM 分佈。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#a.對滋擾參數進行平均",
    "href": "0109CH3.html#a.對滋擾參數進行平均",
    "title": "0109CH3 多參數模型",
    "section": "A.對「滋擾參數」進行平均",
    "text": "A.對「滋擾參數」進行平均\n\n現代貝氏計算（包括 MCMC、Gibbs Sampling）的邏輯基石。\n\n\n3.1.1 什麼是「滋擾參數」？3.1.2 數學架構的建立3.1.3 核心邏輯：條件機率的混合3.1.4 計算策略：模擬積分\n\n\n\n在許多問題中，我們需要建立一個真實的模型，因此必須包含某些參數，但我們並不想對這些參數進行推論。這類參數通常被稱為「滋擾參數」（nuisance parameters）。最經典的例子就是測量問題中的隨機誤差尺度（scale of random errors），也就是變異數（variance）或標準差。\n試想你在評估暴露平均值時，變異數（標準差）會影響你的評估結果。你的目標是準確估計平均暴露，但是，如果你忽略變異數，你就可能會有估計誤差。所以，標準差對你來說是一個「滋擾」（Nuisance）。你必須測量它、考慮它，把它納入計算。\n在統計上，我們透過「對滋擾參數進行平均」來消除它的影響，同時保留它帶來的不確定性。\n\n\n\n\n參數向量 \\theta 可以分為兩部分：\\theta = (\\theta_1, \\theta_2)。\n\n\\theta_1：我們感興趣的參數（例如：平均暴露濃度 \\mu）。\n\\theta_2：滋擾參數（例如：變異數 \\sigma^2）。\n\n我們的目標是求出 p(\\theta_1 | y)，即在給定數據 y 的情況下，我們感興趣參數的後驗分佈。\n\n公式解析：積分公式： p(\\theta_1 | y) = \\int p(\\theta_1, \\theta_2 | y) d\\theta_2\n\n「這個公式的意思是，我們考慮了 \\theta_2（變異數）所有可能的值。對於每一個可能的變異數值，我們都計算一次 \\theta_1（平均值）的可能性，然後把這些結果全部加總起來（加權平均）。這樣一來，我們最終得到的平均值估計，就已經『包含』了變異數可能忽大忽小的風險。」\n\n\n\n\n接著將聯合後驗分佈 p(\\theta_1, \\theta_2 | y) 分解（這是理解貝氏邏輯的關鍵一步）\n\np(\\theta_1, \\theta_2 | y) = p(\\theta_1 | \\theta_2, y) p(\\theta_2 | y)， 將其代入積分公式，\np(\\theta_1 | y) = \\int p(\\theta_1 | \\theta_2, y) p(\\theta_2 | y) d\\theta_2\n\n它告訴我們，邊際後驗分佈 p(\\theta_1 | y) 其實是條件後驗分佈 p(\\theta_1 | \\theta_2, y) 的混合（Mixture）。\n\n\n\n\n\n\n\n\n\n數學項\n統計意義\n解釋\n\n\np(\\theta_1|y)\n\n邊際後驗分佈\n\n\n\\int... d\\theta_2\n對滋擾參數積分\n我們不只看一種情況，而是全面考量所有可能的變異程度。\n\n\np(\\theta_1|\\theta_2, y)\n\n條件後驗分佈\n\n\np(\\theta_2|y)\n\n滋擾參數的邊際後驗\n\n\n\n\n\n[OHS應用]\n\n想像我們評估一個工廠的風險，數據很少，我們不確定這個工廠的製程是否穩定（因為變異數未知）。貝氏思考如下：\n\n情境 A：如果製程很穩定（變異數小），那平均暴露可能是 10 ppm。數據顯示這種情況的可能性是 20%。\n情境 B：如果製程很不穩定（變異數大），那為了符合現有的數據，平均暴露可能其實只有 5 ppm（因為大變異數會讓偶爾測到的高值變得不那麼奇怪）。數據顯示這種情況的可能性是 50%。\n情境 C…\n\n貝氏公式 (3.1) 就是在做這件事：它把情境 A、B、C… 的結果，依照它們發生的可能性（加權），全部混合起來。最終給出的答案，不是基於某個單一的猜測，而是綜合了所有可能性的加權平均。這就是為什麼貝氏方法在小樣本下比較『周延』，因為它沒有忽略那些極端情況的可能性。」\n\n\n\n\n\n\n我們很少真的去手算這個積分，相反地，使用一種 計算策略，這也是現代軟體（如 JAGS, Stan, Expostats）的運作原理。\n策略步驟：\n\n\n第一步：從滋擾參數的邊際後驗分佈 p(\\theta_2 | y) 中抽取一個樣本。\n\n電腦做的事：根據數據，隨機選一個「可能」的 GSD 值（例如 GSD = 2.1）。\n\n第二步：利用剛剛抽到的 \\theta_2，從條件後驗分佈 p(\\theta_1 | \\theta_2, y) 中抽取一個 \\theta_1。\n\n電腦做的事：假設 GSD = 2.1 是真的，再根據數據推算 GM 可能是多少（例如 GM = 0.5 ppm）。\n\n重複：重複上述步驟成千上萬次。\n\n\n結果：如果把這成千上萬個抽出來的 \\theta_1（GM）畫成直方圖，這個直方圖就是我們夢寐以求的 邊際後驗分佈 p(\\theta_1 | y)。\n透過模擬，我們繞過了複雜的微積分，直接用電腦的算力完成了「對滋擾參數平均」的任務。這就是為什麼在 Expostats 中按下 “Calculate” 後需要等幾秒鐘，因為電腦正在後台進行這場成千上萬次的「情境演練」。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#b.職業衛生中的滋擾參數從-gsd-到測量誤差",
    "href": "0109CH3.html#b.職業衛生中的滋擾參數從-gsd-到測量誤差",
    "title": "0109CH3 多參數模型",
    "section": "B.職業衛生中的滋擾參數：從 GSD 到測量誤差",
    "text": "B.職業衛生中的滋擾參數：從 GSD 到測量誤差\n\n在 OSH 領域，最惡名昭彰的滋擾參數就是 幾何標準差（GSD）。\n\n\n4.1 對數常態分佈中的 \\mu 與 \\sigma4.2 傳統方法的失敗：Plug-in 估計4.3 貝氏方法的優越性4.4 其他滋擾參數：測量誤差\n\n\n\n職業暴露數據通常服從對數常態分佈。若 X 為暴露濃度，則 \\ln(X) \\sim N(\\mu, \\sigma^2)。\n\n\\mu：對數幾何平均值（Log GM）。\n\\sigma：對數幾何標準差（Log GSD）。\n\n通常，我們關心的 \\theta_1 是 第 95 百分位數（95th Percentile, X_{95}） 或 超過容許濃度的機率（Exceedance Fraction）。\n\nX_{95} = \\exp(\\mu + 1.645\\sigma)\n\n這裡的參數 (\\theta_1) 實際上是 \\mu 和 \\sigma 的函數，但在貝氏分析的過程中，我們通常會將 \\sigma 視為滋擾參數來處理 \\mu 的不確定性，或者更準確地說，我們在計算 X_{95} 的後驗分佈時，是同時考慮了 (\\mu, \\sigma) 的聯合分佈。\n\n\n\n\n在傳統做法中（例如使用 AIHA 的舊版試算表或手算），衛生師通常會先計算樣本的 GM 和 GSD，然後直接代入公式：\n\n\\text{點估計 } X_{95} = \\text{Sample GM} \\times (\\text{Sample GSD})^{1.645}\n\n這相當於假設 樣本 GSD = 真實 GSD。也就是說，它把 \\theta_2 當作了一個已知的常數，完全忽略了 \\theta_2 的不確定性。\n\n當樣本數 n&lt;=6 時，樣本 GSD 的變動非常大（可能從 1.5 到 3.5 都有可能）。\n如果你運氣好，採樣到的 GSD 偏小，你算出來的 X_{95} 就會嚴重低估風險，導致你誤判環境是安全的，勞工可能因此受害。\n這就是未進行「滋擾參數平均」的後果。\n\n\n\n\n\n貝氏分析不假設 GSD 是某個定值。它會考慮：「雖然樣本 GSD 是 1.8，但真實 GSD 有可能是 2.5（機率 10%）。」\n在計算 X_{95} 的分佈時，那 10% 的「高 GSD 情境」會被納入考量，拉高 X_{95} 的上界。\n這導致貝氏信用區間（Credible Interval）通常比傳統信賴區間更寬、更偏向保守（在小樣本下），這正符合職業衛生的 預警原則（Precautionary Principle）。\n\n\n\n\n滋擾參數不僅限於 GSD。在 brms 軟體包的介紹中，提到了 測量誤差（Measurement Error） 的處理。\n在 OSH 中，採樣泵和實驗室分析都有誤差（例如 CV = 5%）。\n\n傳統上：我們忽略它，或者假設它包含在環境變異中。\n\n貝氏模型應用：我們可以把「真實濃度」視為 \\theta_1，把「儀器誤差」視為 \\theta_2。\n\n透過對儀器誤差進行平均（積分），我們可以還原出更接近真實的暴露分佈。這在處理接近偵測極限（LOD）的數據時特別重要。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#c.工具expostats-與-aiha-bda",
    "href": "0109CH3.html#c.工具expostats-與-aiha-bda",
    "title": "0109CH3 多參數模型",
    "section": "C.工具：Expostats 與 AIHA BDA",
    "text": "C.工具：Expostats 與 AIHA BDA\n\n5.1 Expostats：貝氏工具箱5.2 AIHA 貝氏決策分析（BDA）\n\n\n\n由 Lavoué 等人開發的 Expostats 是目前國際上最先進的 OSH 貝氏分析工具。\n\n核心機制：Expostats 使用 JAGS（Just Another Gibbs Sampler）作為運算引擎。\n\n運行方式：\n\n使用者輸入數據（包括未檢出數據 &lt;LOQ）。\nJAGS 在後台定義了 \\mu 和 \\sigma 的先驗分佈（Priors）。\nJAGS 進行 MCMC 模擬：\n\n抽取 \\sigma（滋擾參數）。\n抽取 \\mu（給定 \\sigma）。\n計算當下的 X_{95}。\n\n積分結果：Expostats 最後呈現的「過度暴露風險圖」（Overexposure Risk）和 X_{95} 的信用區間，就是對 \\sigma 積分後的 邊際後驗分佈。\n\n不確定性管理：Expostats 特別強調「個體過度暴露機率」（Probability of Individual Overexposure），這是在階層模型（Hierarchical Model）下，將「群體變異」（Between-worker variability）視為滋擾參數進行平均後，對「隨機工人」暴露風險的評估。\n\n\n\n\nHewett 等人提出的 AIHA BDA 模型是另一個經典案例。\n參數空間（Parameter Space）：被限制在一個合理的 (\\mu, \\sigma) 參數空間內。\n先驗決策圖：職業衛生師根據專業判斷（Professional Judgment）設定先驗機率。這其實是在定義 p(\\theta_1, \\theta_2) 的形狀。\n決策機率：最終輸出的「第 4 類暴露機率為 80%」，這個 80% 是怎麼來的？它是透過對所有落在第 4 類定義範圍內的 (\\mu, \\sigma) 組合進行積分（加總其後驗機率）得來的，這屬於離散化應用。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#d.常態分佈均值與變異數未知",
    "href": "0109CH3.html#d.常態分佈均值與變異數未知",
    "title": "0109CH3 多參數模型",
    "section": "D.常態分佈均值與變異數未知",
    "text": "D.常態分佈均值與變異數未知\n理解「平均掉滋擾參數」的威力。\n\n6.1 標準常態模型6.2 滋擾參數的邊際後驗6.3 關注參數的邊際後驗E.小結\n\n\n\n假設數據 y \\sim N(\\mu, \\sigma^2)。我們想估計 \\mu，但不知道 \\sigma^2。使用無訊息先驗（Noninformative Prior）：\n\np(\\mu, \\sigma^2) \\propto (\\sigma^2)^{-1}\n\n\n\n\n\n根據 Gelman 的推導，\\sigma^2 的邊際後驗分佈服從 Scaled Inverse-Chi-Square 分佈。這告訴我們，由於數據量有限，變異數有可能是某個很大的值（分佈有長尾）。\n\n\n\n\n如果我們知道 \\sigma，\\mu 的後驗分佈應該是常態分佈（Normal）。\n當把那個服從 Inverse-Chi-Square 的 \\sigma^2 積掉之後，\\mu 的邊際後驗分佈變成了什麼？答案是：t 分佈（Student’s t-distribution）。\n\n\\mu | y \\sim t_{n-1}(\\bar{y}, s^2/n)\n\n這也就是「為什麼我們在小樣本時要用 t 檢定，而不是 Z 檢定（常態分佈）？」。因為，「因為樣本數小，標準差未知。」。\nt 分佈之所以比常態分佈『胖』（Fatter tails），正是因為它包含了對未知標準差（滋擾參數）的平均！」\n那個胖胖的尾巴，就是貝氏積分過程中所保留下來的「不確定性」。這證明了貝氏方法與經典統計學在這一點上是殊途同歸的，而且貝氏方法提供了更直觀的數學解釋：我們為了解決對 \\sigma 的無知，付出了讓 \\mu 的估計範圍變寬的代價。\n\n\n\n\n不要假裝知道我們不知道的事（例如真實的 GSD）。透過對這些滋擾參數進行嚴謹的積分或模擬，我們給出的暴露評估結果才是經得起考驗的，才能真正保護勞工免受潛在危害的威脅。\n傳統統計與貝氏比較表\n\n\n\n\n\n\n\n\n\n\n比較項目\n傳統頻率學派\n貝氏統計 (Bayesian)\n對 OSH 的影響\n\n\n參數視角\n參數是固定的常數 (\\theta)\n參數是隨機變數，有其機率分佈\n貝氏能描述 GSD 的不確定性範圍\n\n\n滋擾參數處理\nPlug-in Method (直接代入樣本估計值)\nMarginalization (對所有可能值進行積分/平均)\n傳統方法在小樣本下易低估風險\n\n\n結果呈現\n點估計 + 信賴區間 (Confidence Interval)\n後驗機率分佈 + 信用區間 (Credible Interval)\n貝氏產出可直接用於決策的機率 (如: &gt;95% OEL 的機率)\n\n\n小樣本表現\n往往過度自信 (區間過窄)\n較為保守 (區間較寬，如 t 分佈)\n貝氏更符合預警原則\n\n\n\n\n\n參考資料：\n\nGelman et al., Bayesian Data Analysis, Chapter 3.\nHewett et al., Rating Exposure Control Using Bayesian Decision Analysis.\nLavoué et al., Expostats: A Bayesian Toolkit.\nbrms package documentation (Measurement Error).",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#常態數據與無訊息先驗分布",
    "href": "0109CH3.html#常態數據與無訊息先驗分布",
    "title": "0109CH3 多參數模型",
    "section": "3.2 常態數據與無訊息先驗分布",
    "text": "3.2 常態數據與無訊息先驗分布\n\n當我們站在工廠的作業現場，手中握著僅有的三、五個空氣採樣數據，卻要對成千上萬個工作日的工人健康風險做出攸關性命的判斷時，傳統統計學往往讓我們感到力不從心。\n在變異數未知的情況下，對平均值的估計必然遵循 t 分佈（Student’s t-distribution），這正是職業衛生中處理小樣本數據時「不確定性」的數學根源。\n我們將連結理論與實務，探討如何利用 Hewett 等人提出的貝氏決策分析（Bayesian Decision Analysis, BDA）框架 ，以及現代化的 Expostats 工具箱 ，將這些抽象的數學符號轉化為保護勞工健康的具體決策。  \n\n\n\nＡ. 傳統頻率學派的侷限性B. 貝氏統計的直觀優勢C. 常態數據與無訊息先驗分布2. OHS實務問題D. 貝氏決策分析（BDA）的應用E. 計算實作：Expostats 工具箱的演進F. 常見誤區G. 結論附表：小樣本暴露評估方法的比較摘要\n\n\n\n在職業衛生領域，長期以來我們依賴頻率學派（Frequentist）的統計方法，例如 NIOSH 77-173 手冊中建立的抽樣策略 。在這種框架下，我們假設暴露參數（如真實的幾何平均值 GM 或幾何標準差 GSD）是固定但未知的常數。機率被解釋為「長期重複抽樣下的頻率」。  \n然而，這種觀點在面對職業衛生現場數據時經常出現問題：\n\n\n樣本極度稀缺：對於一個由 50 名工人組成、每年運作 250 天的相似暴露群（Similar Exposure Group, SEG），總暴露人天數達 12,500 天。若我們僅進行 6 到 10 次採樣，樣本量僅佔母體的 0.08% 。在 N=3 的極端情況下，頻率學派的信賴區間（Confidence Interval）往往寬到毫無實用價值。  \n變異數的不確定性：頻率學派通常使用樣本標準差 s 作為母體標準差 σ 的點估計。但當樣本很小時，s 本身就有巨大的不確定性，且容易低估真實的變異。\n無法回答核心問題：業主和勞工想知道的是「這個環境安全的機率是多少？」。頻率學派只能回答「如果這個環境是安全的，我們觀察到這些數據的機率很低」，這是一種迂迴的邏輯。\n\n\n\n\n\n貝氏統計（Bayesian Statistics）提供了一個更符合人類直覺的框架。在這裡，機率代表的是我們對某個假設的「信念程度」（Degree of Belief）。參數不再是固定的未知數，而是隨機變數，擁有自己的機率分布。  \n這與工業衛生師（Industrial Hygienist, IH）的決策過程不謀而合：\n\n先驗分布（Prior）：在採樣前，我們根據專業判斷、原料毒性、通風設備狀況，已經對暴露風險有一個初步的「信念」。\n概似函數（Likelihood）：我們收集到的空氣採樣數據。\n後驗分布（Posterior）：結合先驗知識與數據證據，更新我們對暴露風險的看法。\n\n這種方法允許我們在數據稀缺時引入專業知識（Informative Priors），或者在完全無知時使用無訊息先驗（Noninformative Priors）來讓數據說話。接下來介紹處理「當我們先驗知識為空白時，如何客觀處理常態分佈數據」。  \n\n\n\n\n\n在職業衛生中，暴露數據通常呈現對數常態分佈（Lognormal Distribution），取對數後即為常態分佈。因此，這裡討論的 μ 對應的是 ln(GM)，而 σ 對應的是 ln(GSD)。  \n\n\n1. 雙參數模型的挑戰\n\n在單參數模型中（如二項式分佈估計盛行率），我們只有一個未知數。但在常態分佈模型\\ N(μ,σ^2) 中，我們同時面臨兩個未知參數：平均值 \\ μ 和變異數 \\ σ^2。\n通常，我們最關心的是\\ μ （代表平均暴露水準）。但在貝氏分析中，為了準確估計\\ μ ，我們必須同時處理 \\ σ^2。這裡的\\ σ^2被稱為「滋擾參數」（Nuisance Parameter）。它雖然不是我們推論的直接目標，但它是構建真實模型所必需的，且其不確定性會直接影響我們對 \\ μ 的估計精度。  \n貝氏方法不將\\ σ^2視為一個固定值代入，而是透過積分將其「邊緣化」（Marginalize），從而將 \\ σ^2的不確定性完整地傳遞給\\ μ 的後驗分布。這就是為什麼貝氏區間在小樣本下往往比傳統區間更合理的原因。\n\n\n\n\n\n當樣本量 n 很小（例如 3 個樣本）時，變異數分布的右尾會拖得很長。 這解釋了為什麼在小樣本下，GSD 的信賴區間上限（UCL）往往高得嚇人（例如 GSD 估計值是 2.5，但 95% UCL 可能是 10.0）。這是數學上的必然，反映了我們無法排除「運氣好抽到數值相近的樣本，但實際變異極大」的可能性。\n當你只有 3 個樣本時，真實暴露濃度極高（或極低）的可能性，比常態分佈預測的要大得多。這就是為什麼 NIOSH 統計手冊要求使用 t 值來計算 UCL 的根本原因—它是對我們「無知」的補償。\n\n\n\n\n\n在 2006 年，Hewett, Logan 等人將這一理論推進了一步，提出了適合職業衛生的 貝氏決策分析（Bayesian Decision Analysis, BDA） ，解決了純數學推導在實務上的不足。  \n\n\n1. 引入專業判斷：從無訊息到有訊息\n\n假設 μ 和 lnσ 可以是任意值。但在工廠裡，但我們知道：\n\n苯的濃度不可能是一百萬 ppm（那是純物質）。\n暴露的 GSD 通常介於 1.1 到 4.0 之間，極少超過 6.0 。  \n\nHewett 的 BDA 框架引入了 參數空間限制（Parameter Space Constraints） 。這相當於使用了一個「截斷的均勻先驗」（Truncated Uniform Prior）。  \n\n不再假設 p(σ)∝1/σ 在 (0,∞) 上。\n限制 σ 在合理的範圍內（例如 ln(1.05) 到 ln(4.0)）。\n這個簡單的動作產生了巨大的實務影響。它切斷了 t 分布那條代表「物理上不可能的巨大變異」的長尾巴，從而大幅縮小了不確定性區間，使得即便在 N=3 的情況下，也能做出更有信心的判斷。\n\n\n\n\n2. 決策三部曲\n\nBDA 框架將貝氏推理具象化為三個分佈圖 ：  \n\n\n先驗決策分佈（Prior Decision Distribution）：這代表了 IH 在採樣前的專業判斷。例如，根據製程封閉程度，IH 可能有 70% 的信心認為該暴露屬於「高度控制」（Category 1）。這不再是數學上的 1/σ2，而是專家經驗的量化。\n概似決策分佈（Likelihood Decision Distribution）：這完全由數據決定，背後運算的數學核心正是聯合概似函數。它展示了如果只看這 3 個樣本，數據告訴我們什麼。通常對於小樣本，這個分佈會非常寬（反映 t 分布的特性）。\n後驗決策分佈（Posterior Decision Distribution）：這是先驗與概似的數學合成。如果先驗很強（專家很有信心），它會收斂數據的雜訊；如果數據很強（樣本很多），它會修正專家的偏見。\n\n\n\n3. 暴露分級範疇\n\n為了讓統計結果具有行動指導意義，BDA 將後驗機率映射到 AIHA 的暴露控制等級 ：  \n\nCategory 0 (可忽略): 真實第 95 百分位數 (X95​) ≤1% OEL。\nCategory 1 (高度控制): X95​≤10% OEL。\nCategory 2 (良好控制): X95​≤50% OEL。\nCategory 3 (受控): X95​≤100% OEL。\nCategory 4 (控制不良): X95​&gt;100% OEL。\n\n這樣的輸出（例如：「有 95% 的機率屬於 Category 2」）比傳統的「平均值 95% UCL 為 20 ppm」更易於與管理層溝通。\n\n\n\n\n\n在處理更複雜的現實情況（如數據低於偵測極限 LOD）時，需要依賴數值運算，而 Expostats 正是此領域的佼佼者 。\n\n1. 從積分到模擬（MCMC）\n\nExpostats 使用 JAGS (Just Another Gibbs Sampler) 引擎進行運算 。這對應到課程中將會學到的 馬可夫鏈蒙地卡羅（MCMC） 方法。  \n\n在通過數學技巧積分掉 σ2 得到 μ 的 t 分布。\n在 Expostats 中，電腦在 (μ,σ) 的參數空間中進行數萬次的隨機跳躍（Sampling）。\n這些跳躍點的集合構成了聯合後驗分布。如果我們把這些點畫成直方圖。\n\n\n\n\n2. 處理設限數據（Censored Data）\n\n這是 Expostats 超越傳統 t 檢定最大的優勢。\n\n傳統方法：遇到「&lt; LOD」的數據，常粗糙地用 LOD/2 或 LOD/2​ 取代。這會扭曲平均值和變異數的估計。\n貝氏方法：在概似函數中，對於 &lt; LOD 的數據，我們不代入機率密度函數 p(y∣θ)，而是代入累積分布函數 P(y&lt;LOD∣θ) 。  \n這意味著，模型會嘗試尋找一組 (μ,σ)，使得這組參數「產生小於 LOD 的數據」的機率最大化。這在數學上是非常嚴謹的處理方式。\n\n\n\n\n3. 超標風險（Overexposure Risk）的計算\n\nExpostats 能夠直接回答：「真實的 95 百分位數超過 OEL 的機率是多少？」 這在數學上是對聯合後驗分布進行積分：\n\nP(X_{0.95} &gt; \\text{OEL} | y) = \\iint_{R} p(\\mu, \\sigma | y) d\\mu d\\sigma\n\n其中區域 R 是滿足 \\mu + 1.645\\sigma &gt; \\ln(\\text{OEL}) 的參數空間。這種直接的機率陳述（例如「有 85% 的風險超標」）是頻率學派無法提供的，因為在頻率學派中，參數是固定的，沒有機率可言 。  \n\n\n\n\n\n\n頻率學派 95% 信賴區間（CI）：「如果我們重複做 100 次採樣實驗，算出 100 個區間，其中有 95 個會包含真實平均值。」（這對單次決策毫無幫助，且極其拗口）。\n貝氏 95% 可信區間（Credible Interval, CrI）：「真實平均值落在這個範圍內的機率是 95%。」（這正是業主想聽的）。\n關鍵連結：在無訊息先驗的條件下，貝氏的 CrI 數值上完全等於頻率學派的 CI 。這賦予了我們在實務上使用 t 分布公式，但心裡用貝氏直覺來解釋的理論正當性。  \n「只採 3 個樣真的夠嗎？」\n\n從 BDA 的角度（Hewett 方法），如果我們先驗知識很強（例如這是封閉管路，過去十年都沒洩漏），強大的先驗會「壓制」t 分布的寬度。\n數據少時，結論的信心來自於先驗知識。如果沒有先驗知識（無訊息先驗），單靠 3 個樣本做決策是非常危險的（除非檢測值極低，例如 &lt; 1% OEL）。\n\n\n\n\n\n\n對於職業安全衛生專業人員而言，掌握這一段理論具有雙重意義：\n\n\n理解風險的本質：明白小樣本帶來的高不確定性是來自於對「變異程度」的無知。\n擁抱貝氏的優勢：看見從無訊息先驗跨越到有訊息先驗（Hewett/Expostats）時，決策品質的巨大飛躍。\n\n\n\n\n\n\n\n\n\n\n\n\n\n特徵\n頻率學派 (NIOSH 77-173)\n貝氏無訊息先驗\n貝氏有訊息先驗 (BDA/Hewett)\n\n\n機率哲學\n機率 = 長期錯誤率\n機率 = 信念程度\n機率 = 信念 + 先前知識\n\n\n先前知識\n忽略 (隱含均勻先驗)\n明確定義為「模糊」(1/σ2)\n明確建模 (如 GSD ≈ 2)\n\n\n變異數處理\n點估計 s，使用 t 統計量\n積分消除 σ，導出 t 分布\n使用先驗約束 σ 的範圍\n\n\n輸出結果\n信賴區間 (如 UCL)\n可信區間 (CrI)\n暴露等級的機率分布\n\n\n小樣本 (N=3) 表現\nUCL 極大，常無法決策\nCrI 也很寬 (數值上同頻率學派)\nCrI 較窄，可輔助決策\n\n\n結果解釋\n“95% 的區間會覆蓋真值”\n“真值在區間內的機率為 95%”\n“真值在區間內的機率為 95%”",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#具有共軛先驗分佈的常態數據",
    "href": "0109CH3.html#具有共軛先驗分佈的常態數據",
    "title": "0109CH3 多參數模型",
    "section": "3.3 具有共軛先驗分佈的常態數據",
    "text": "3.3 具有共軛先驗分佈的常態數據\n\n我們將深入探討以下核心主題：\n\n\n職業暴露數據的隨機本質：為何常態分佈模型（對數常態）是暴露評估的核心。\n共軛先驗的架構：如何將「專業判斷」量化為數學參數。\n貝氏更新機制：解析數據如何修正我們對職場危害的認知。\n邊際後驗分佈：如何從聯合分佈中提取出關於 GM 和 GSD 的具體推論。\n後驗預測分佈：如何預測「下一個工人」的暴露風險（Exceedance Fraction）。\n\n\n第一部分：理論背景與職業衛生脈絡第二部分：共軛先驗分佈第三部分：後驗分佈的推導與更新機制第四部分：邊際後驗分佈第五部分：後驗預測分佈第六部分：職業衛生實務案例演練第七部分：進階議題與軟體應用結論\n\n\n\n1.1 觀念轉換\n\ny（常態數據） \\rightarrow \\ln(X)（暴露濃度的自然對數）\n\\mu（均值） \\rightarrow \\ln(GM)（幾何平均數的對數）\n\\sigma（標準差） \\rightarrow \\ln(GSD)（幾何標準差的對數）\n\n所有的數學推導都在對數尺度上進行，最終結果需取指數（exp）還原為濃度單位（ppm 或 mg/m³）。\n\n\n1.2 似然函數：數據的數學形狀\n\n假設我們有一組觀測值 y = (y_1, \\dots, y_n)，它們獨立且同分佈（i.i.d.）於常態分佈 N(\\mu, \\sigma^2)。\n對於單個數據點 y_i，其機率密度函數（pdf）為：\n\np(y_i|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{1}{2\\sigma^2}(y_i - \\mu)^2\\right)\n\n對於整組數據 y，其聯合似然函數是個別密度的乘積：\n\np(y|\\mu, \\sigma^2) = \\prod_{i=1}^n p(y_i|\\mu, \\sigma^2) \\propto \\sigma^{-n} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2 \\right)\n\n無論我們收集了多少暴露數據，對於常態模型而言，我們只需要知道兩個數值：樣本均值 \\bar{y} 和 樣本變異數 s^2。這兩個數值包含了數據中關於 \\mu 和 \\sigma^2 的所有訊息 。\n\n\n\n\n\n\nGelman 提出，為了使後驗分佈具有解析解（Analytical Solution），我們必須選擇一個與似然函數「共軛」的先驗分佈族。對於未知均值和變異數的常態分佈，這個共軛先驗是 常態-逆卡方分佈（Normal-Inverse-Chi-Square, N-Inv\\chi^2）。\n\n\n2.1 聯合先驗的分解\n\n聯合先驗 p(\\mu, \\sigma^2) 被分解為條件機率的乘積：\n\np(\\mu, \\sigma^2) = p(\\sigma^2) \\times p(\\mu|\\sigma^2)\n\n這意味著我們必須先描述變異數（製程波動），然後在此基礎上描述均值（暴露水準）。\n\n\n\n2.2 變異數的先驗：縮放逆卡方分佈 p(\\sigma^2)\n\n先驗變異數猜測 (Prior Variance Guess)這是我們在採樣前，根據經驗認為該製程的波動程度。例如，對於一個控制良好的連續製程，我們可能預期 GSD=2.0，則 \\sigma_0 = \\ln(2.0) \\approx 0.693，故 \\sigma_0^2 \\approx 0.48。\n\n\n\n2.3 均值的條件先驗：常態分佈 p(\\mu|\\sigma^2)\n\n在給定變異數 \\sigma^2 的情況下，均值 \\mu 服從常態分佈。\n先驗均值猜測 (Prior Mean Guess)這是我們預期的暴露濃度中心。例如，若預期 GM 為 10 ppm，則 \\mu_0 = \\ln(10)。這通常來自於類似暴露群（SEG）的歷史數據或物理模型推估。\n如果製程本身變異很大（\\sigma^2 大），那麼我們對均值 \\mu 的估計也會自然地變得不確定（分佈變寬）。這是貝氏模型內建的合理性檢驗機制。\n\n\n\n\n\n\n將上述的先驗與似然函數相乘，我們發現後驗分佈 p(\\mu, \\sigma^2|y) 依然是 常態-逆卡方分佈。這就是「共軛」的魔力。\n如果工業衛生師「自以為是」地設定了一個很低的先驗均值 \\mu_0（認為很安全），但實際數據 \\bar{y} 卻很高， (\\bar{y} - \\mu_0)^2 就會變得非常大。這會導致後驗變異數 \\sigma_n^2 劇烈膨脹。\n這是一個自動的安全閥機制：當專家的判斷與數據打架時，模型會告訴我們：「情況不明朗，變異性可能比你想像的更大。」這會導致推估的 95 百分位數（P95）上升，從而做出更保守（保護工人）的決策。這解釋了為什麼錯誤的先驗不會導致災難性的低估風險，反而會增加不確定性區間 1。\n\n1 文獻1\n\n\n\n我們通常不關心 \\mu 和 \\sigma^2 的聯合機率，他們想知道的是單獨的風險指標。\n\n\n4.1 變異數的邊際後驗 \\sigma^2 | y\n\n如果我們對 \\mu 進行積分，\\sigma^2 的後驗分佈服從縮放逆卡方分佈。\n\n\\sigma^2 | y \\sim Inv-\\chi^2(\\nu_n, \\sigma_n^2)\n\n\n\n\n4.2 均值的邊際後驗 \\mu | y\n\n如果我們對 \\sigma^2 進行積分，\\mu 的後驗分佈服從 非標準 t 分佈（location-scale t-distribution）。\n\n\n\n\n\n\n我們關心的往往不是「母體平均是多少」，而是「明天某個工人會不會吸入過量的化學品」。這就是後驗預測分佈 p(\\tilde{y}|y)。\n對於一個新的觀測值 \\tilde{y}，其預測分佈也是一個 t 分佈。\n這個預測分佈是計算 Exceedance Fraction（超過 OEL 的比例） 的數學基礎。我們計算這個 t 分佈大於 \\ln(OEL) 的面積，即得到該工作場所的超標風險機率。這是 AIHA 暴露評估策略中「Category 4」判定的核心依據。\n\n\n\n\n\n情境：評估甲苯暴露（OEL = 20 ppm）。\n先驗設定：\n\n資深 IH 判斷：該製程有局部排氣，濃度應很低，約在 2 ppm (\\mu_0 = \\ln(2) \\approx 0.69)。\n變異性：一般作業環境，預估 GSD = 2.0 (\\sigma_0 \\approx 0.69, \\sigma_0^2 \\approx 0.48)。\n信心：中等信心，相當於 2 個樣本的權重 (\\kappa_0 = 2, \\nu_0 = 2)。\n\n新數據：採樣 3 點，分別為 5, 8, 12 ppm。\n\n對數數據 y: 1.61, 2.08, 2.48。\n樣本統計：\\bar{y} = 2.06 (GM \\approx 7.8 ppm), s^2 = 0.19。\n\n貝氏更新計算：\n\n\n\\kappa_n = 2 + 3 = 5。\n\\mu_n = \\frac{2(0.69) + 3(2.06)}{5} = \\frac{1.38 + 6.18}{5} = 1.51。\n\n解讀：後驗 GM \\approx \\exp(1.51) \\approx 4.5 ppm。數據把先驗的 2 ppm 拉高到了 4.5 ppm。\n\n\\nu_n = 2 + 3 = 5。\n\\nu_n \\sigma_n^2 = 2(0.48) + 2(0.19) + \\frac{2\\cdot3}{5}(2.06 - 0.69)^2\n\n= 0.96 + 0.38 + 1.2(1.87) = 1.34 + 2.24 = 3.58。\n\\sigma_n^2 = 3.58 / 5 = 0.716。\n解讀：後驗 GSD \\approx \\exp(\\sqrt{0.716}) \\approx 2.33。\n關鍵點： 2.24 貢獻了大部分的變異。因為先驗覺得濃度很低 (0.69)，但數據很高 (2.06)，模型「困惑」了，因此增加了對變異性的估計（從先驗的 0.48 增加到 0.716）。這是一個警訊，告訴 IH 製程可能不如預期穩定。\n\n\n\n\n\n理論在現代工具中的實踐與局限：\n\n\n左設限數據 (Censored Data/LOD)：\n解析解前提是數據是完整的常態分佈。但在 OSH 中，我們常遇到「&lt; LOD」的數據。這時，共軛先驗的解析解失效。現代工具如 Expostats 使用 JAGS (MCMC) 來解決這個問題，通過數值模擬而非公式推導來獲得後驗分佈，但其背後的邏輯（先驗+似然=後驗）完全一致 。\n軟體實現：\n雖然手算公式有助理解，但實務上應推薦使用 IHDataAnalyst (IHDA) 或免費的 Expostats。這些工具內部封裝了上述 \\kappa_n, \\nu_n 的更新算法，用戶只需通過滑桿設定「先驗信心」即可。\n\n\n\n\n\n通過 常態-逆卡方共軛先驗，我們得以將「經驗」合法化、量化，並與「數據」有機結合。\n貝氏方法不是在操弄數據，而是在管理不確定性。 當樣本數少時，它通過先驗（\\kappa_0）保護我們免受隨機性的愚弄；當先驗錯誤時，它通過膨脹變異數（衝突項）來警告我們潛在的風險。這正是我們作為安全衛生專家的核心價值所在。\n\n\n\n參考文獻整合與引用說明\n\n本報告整合了 Gelman BDA3 的理論架構 1、Hewett 等人的 BDA 應用框架 1、Expostats 的演算邏輯 1，以及 Normal-Inverse-Chi-Square 的數學性質研究 2。所有公式推導均基於 BDA3 第 3 章的標準定義。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  }
]