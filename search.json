[
  {
    "objectID": "0109CH3.html",
    "href": "0109CH3.html",
    "title": "0109CH3 多參數模型",
    "section": "",
    "text": "date: 2026/01/09 - 2026/01/10",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#ａ.-鋪陳",
    "href": "0109CH3.html#ａ.-鋪陳",
    "title": "0109CH3 多參數模型",
    "section": "Ａ. 鋪陳",
    "text": "Ａ. 鋪陳\n\n幾乎所有統計學中的實際問題都涉及不止一個未知或無法觀測的量。\n\n當拿到一組只有 3 個採樣點的數據時，你既不知道真實的平均暴露濃度（GM），也不知道真實的變異程度（GSD）。這兩個未知數彼此牽制、互相影響。如果你只盯著其中一個看（例如只看平均值），而忽略了另一個（變異程度）的不確定性，你對風險的評估就會失準，甚至可能做出錯誤的決策，導致勞工受害。\n\n在職業衛生EA中，這「不止一個未知量」通常指的就是 幾何平均數（GM） 和 幾何標準差（GSD）。\n\n這兩個參數共同決定了對數常態分佈（Lognormal Distribution）的形狀，也就是勞工暴露的分佈樣貌。\n傳統統計方法（如 t 檢定或最大似然估計）在樣本數很少時（OSH 的常態），處理這兩個未知參數往往顯得左支右絀，容易低估不確定性。\n而貝氏方法提供了一個統一的框架，讓我們能夠同時處理這些未知數。\n\n在這種情況下，貝氏分析的最終目標是獲得特定感興趣參數的「邊際後驗分佈」（marginal posterior distribution）。\n\n想像經理問你：「勞工暴露超過容許濃度（OEL）的機率是多少？」這就是「感興趣的參數」（或由參數推導出的量）。經理並不關心暴露數據的變異係數是多少，也不關心標準差的精確數值。他只關心那個核心的風險指標。\n為了回答經理的問題，我們必須把那個他不關心的、但又影響計算結果的參數（例如標準差）給「處理」掉。這個「處理」的過程，在數學上就叫做「邊際化」（Marginalization）。\n\n實現這一目標的路徑：我們首先需要所有未知數的「聯合後驗分佈」（joint posterior distribution），然後我們對那些非當前感興趣的未知數進行積分（integrate），從而獲得所需的邊際分佈。\n\n這就是貝氏分析的標準作業程序（SOP）：\n\n建立聯合模型：把 GM 和 GSD 綁在一起看，形成一座機率的「山峰」（聯合後驗分佈）。\n積分（Integration）：這是一個數學動作，相當於從側面看這座山，把所有可能的 GSD 值都加總起來，只留下我們關心的 GM 分佈。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#a.對滋擾參數進行平均",
    "href": "0109CH3.html#a.對滋擾參數進行平均",
    "title": "0109CH3 多參數模型",
    "section": "A.對「滋擾參數」進行平均",
    "text": "A.對「滋擾參數」進行平均\n\n現代貝氏計算（包括 MCMC、Gibbs Sampling）的邏輯基石。\n\n\n3.1.1 什麼是「滋擾參數」？3.1.2 數學架構的建立3.1.3 核心邏輯：條件機率的混合3.1.4 計算策略：模擬積分\n\n\n\n在許多問題中，我們需要建立一個真實的模型，因此必須包含某些參數，但我們並不想對這些參數進行推論。這類參數通常被稱為「滋擾參數」（nuisance parameters）。最經典的例子就是測量問題中的隨機誤差尺度（scale of random errors），也就是變異數（variance）或標準差。\n試想你在評估暴露平均值時，變異數（標準差）會影響你的評估結果。你的目標是準確估計平均暴露，但是，如果你忽略變異數，你就可能會有估計誤差。所以，標準差對你來說是一個「滋擾」（Nuisance）。你必須測量它、考慮它，把它納入計算。\n在統計上，我們透過「對滋擾參數進行平均」來消除它的影響，同時保留它帶來的不確定性。\n\n\n\n\n參數向量 \\theta 可以分為兩部分：\\theta = (\\theta_1, \\theta_2)。\n\n\\theta_1：我們感興趣的參數（例如：平均暴露濃度 \\mu）。\n\\theta_2：滋擾參數（例如：變異數 \\sigma^2）。\n\n我們的目標是求出 p(\\theta_1 | y)，即在給定數據 y 的情況下，我們感興趣參數的後驗分佈。\n\n公式解析：積分公式： p(\\theta_1 | y) = \\int p(\\theta_1, \\theta_2 | y) d\\theta_2\n\n「這個公式的意思是，我們考慮了 \\theta_2（變異數）所有可能的值。對於每一個可能的變異數值，我們都計算一次 \\theta_1（平均值）的可能性，然後把這些結果全部加總起來（加權平均）。這樣一來，我們最終得到的平均值估計，就已經『包含』了變異數可能忽大忽小的風險。」\n\n\n\n\n接著將聯合後驗分佈 p(\\theta_1, \\theta_2 | y) 分解（這是理解貝氏邏輯的關鍵一步）\n\np(\\theta_1, \\theta_2 | y) = p(\\theta_1 | \\theta_2, y) p(\\theta_2 | y)， 將其代入積分公式，\np(\\theta_1 | y) = \\int p(\\theta_1 | \\theta_2, y) p(\\theta_2 | y) d\\theta_2\n\n它告訴我們，邊際後驗分佈 p(\\theta_1 | y) 其實是條件後驗分佈 p(\\theta_1 | \\theta_2, y) 的混合（Mixture）。\n\n\n\n\n\n\n\n\n\n數學項\n統計意義\n解釋\n\n\np(\\theta_1|y)\n\n邊際後驗分佈\n\n\n\\int... d\\theta_2\n對滋擾參數積分\n我們不只看一種情況，而是全面考量所有可能的變異程度。\n\n\np(\\theta_1|\\theta_2, y)\n\n條件後驗分佈\n\n\np(\\theta_2|y)\n\n滋擾參數的邊際後驗\n\n\n\n\n\n[OHS應用]\n\n想像我們評估一個工廠的風險，數據很少，我們不確定這個工廠的製程是否穩定（因為變異數未知）。貝氏思考如下：\n\n情境 A：如果製程很穩定（變異數小），那平均暴露可能是 10 ppm。數據顯示這種情況的可能性是 20%。\n情境 B：如果製程很不穩定（變異數大），那為了符合現有的數據，平均暴露可能其實只有 5 ppm（因為大變異數會讓偶爾測到的高值變得不那麼奇怪）。數據顯示這種情況的可能性是 50%。\n情境 C…\n\n貝氏公式 (3.1) 就是在做這件事：它把情境 A、B、C… 的結果，依照它們發生的可能性（加權），全部混合起來。最終給出的答案，不是基於某個單一的猜測，而是綜合了所有可能性的加權平均。這就是為什麼貝氏方法在小樣本下比較『周延』，因為它沒有忽略那些極端情況的可能性。」\n\n\n\n\n\n\n我們很少真的去手算這個積分，相反地，使用一種 計算策略，這也是現代軟體（如 JAGS, Stan, Expostats）的運作原理。\n策略步驟：\n\n\n第一步：從滋擾參數的邊際後驗分佈 p(\\theta_2 | y) 中抽取一個樣本。\n\n電腦做的事：根據數據，隨機選一個「可能」的 GSD 值（例如 GSD = 2.1）。\n\n第二步：利用剛剛抽到的 \\theta_2，從條件後驗分佈 p(\\theta_1 | \\theta_2, y) 中抽取一個 \\theta_1。\n\n電腦做的事：假設 GSD = 2.1 是真的，再根據數據推算 GM 可能是多少（例如 GM = 0.5 ppm）。\n\n重複：重複上述步驟成千上萬次。\n\n\n結果：如果把這成千上萬個抽出來的 \\theta_1（GM）畫成直方圖，這個直方圖就是我們夢寐以求的 邊際後驗分佈 p(\\theta_1 | y)。\n透過模擬，我們繞過了複雜的微積分，直接用電腦的算力完成了「對滋擾參數平均」的任務。這就是為什麼在 Expostats 中按下 “Calculate” 後需要等幾秒鐘，因為電腦正在後台進行這場成千上萬次的「情境演練」。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#b.職業衛生中的滋擾參數從-gsd-到測量誤差",
    "href": "0109CH3.html#b.職業衛生中的滋擾參數從-gsd-到測量誤差",
    "title": "0109CH3 多參數模型",
    "section": "B.職業衛生中的滋擾參數：從 GSD 到測量誤差",
    "text": "B.職業衛生中的滋擾參數：從 GSD 到測量誤差\n\n在 OSH 領域，最惡名昭彰的滋擾參數就是 幾何標準差（GSD）。\n\n\n4.1 對數常態分佈中的 \\mu 與 \\sigma4.2 傳統方法的失敗：Plug-in 估計4.3 貝氏方法的優越性4.4 其他滋擾參數：測量誤差\n\n\n\n職業暴露數據通常服從對數常態分佈。若 X 為暴露濃度，則 \\ln(X) \\sim N(\\mu, \\sigma^2)。\n\n\\mu：對數幾何平均值（Log GM）。\n\\sigma：對數幾何標準差（Log GSD）。\n\n通常，我們關心的 \\theta_1 是 第 95 百分位數（95th Percentile, X_{95}） 或 超過容許濃度的機率（Exceedance Fraction）。\n\nX_{95} = \\exp(\\mu + 1.645\\sigma)\n\n這裡的參數 (\\theta_1) 實際上是 \\mu 和 \\sigma 的函數，但在貝氏分析的過程中，我們通常會將 \\sigma 視為滋擾參數來處理 \\mu 的不確定性，或者更準確地說，我們在計算 X_{95} 的後驗分佈時，是同時考慮了 (\\mu, \\sigma) 的聯合分佈。\n\n\n\n\n在傳統做法中（例如使用 AIHA 的舊版試算表或手算），衛生師通常會先計算樣本的 GM 和 GSD，然後直接代入公式：\n\n\\text{點估計 } X_{95} = \\text{Sample GM} \\times (\\text{Sample GSD})^{1.645}\n\n這相當於假設 樣本 GSD = 真實 GSD。也就是說，它把 \\theta_2 當作了一個已知的常數，完全忽略了 \\theta_2 的不確定性。\n\n當樣本數 n&lt;=6 時，樣本 GSD 的變動非常大（可能從 1.5 到 3.5 都有可能）。\n如果你運氣好，採樣到的 GSD 偏小，你算出來的 X_{95} 就會嚴重低估風險，導致你誤判環境是安全的，勞工可能因此受害。\n這就是未進行「滋擾參數平均」的後果。\n\n\n\n\n\n貝氏分析不假設 GSD 是某個定值。它會考慮：「雖然樣本 GSD 是 1.8，但真實 GSD 有可能是 2.5（機率 10%）。」\n在計算 X_{95} 的分佈時，那 10% 的「高 GSD 情境」會被納入考量，拉高 X_{95} 的上界。\n這導致貝氏信用區間（Credible Interval）通常比傳統信賴區間更寬、更偏向保守（在小樣本下），這正符合職業衛生的 預警原則（Precautionary Principle）。\n\n\n\n\n滋擾參數不僅限於 GSD。在 brms 軟體包的介紹中，提到了 測量誤差（Measurement Error） 的處理。\n在 OSH 中，採樣泵和實驗室分析都有誤差（例如 CV = 5%）。\n\n傳統上：我們忽略它，或者假設它包含在環境變異中。\n\n貝氏模型應用：我們可以把「真實濃度」視為 \\theta_1，把「儀器誤差」視為 \\theta_2。\n\n透過對儀器誤差進行平均（積分），我們可以還原出更接近真實的暴露分佈。這在處理接近偵測極限（LOD）的數據時特別重要。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#c.工具expostats-與-aiha-bda",
    "href": "0109CH3.html#c.工具expostats-與-aiha-bda",
    "title": "0109CH3 多參數模型",
    "section": "C.工具：Expostats 與 AIHA BDA",
    "text": "C.工具：Expostats 與 AIHA BDA\n\n5.1 Expostats：貝氏工具箱5.2 AIHA 貝氏決策分析（BDA）\n\n\n\n由 Lavoué 等人開發的 Expostats 是目前國際上最先進的 OSH 貝氏分析工具。\n\n核心機制：Expostats 使用 JAGS（Just Another Gibbs Sampler）作為運算引擎。\n\n運行方式：\n\n使用者輸入數據（包括未檢出數據 &lt;LOQ）。\nJAGS 在後台定義了 \\mu 和 \\sigma 的先驗分佈（Priors）。\nJAGS 進行 MCMC 模擬：\n\n抽取 \\sigma（滋擾參數）。\n抽取 \\mu（給定 \\sigma）。\n計算當下的 X_{95}。\n\n積分結果：Expostats 最後呈現的「過度暴露風險圖」（Overexposure Risk）和 X_{95} 的信用區間，就是對 \\sigma 積分後的 邊際後驗分佈。\n\n不確定性管理：Expostats 特別強調「個體過度暴露機率」（Probability of Individual Overexposure），這是在階層模型（Hierarchical Model）下，將「群體變異」（Between-worker variability）視為滋擾參數進行平均後，對「隨機工人」暴露風險的評估。\n\n\n\n\nHewett 等人提出的 AIHA BDA 模型是另一個經典案例。\n參數空間（Parameter Space）：被限制在一個合理的 (\\mu, \\sigma) 參數空間內。\n先驗決策圖：職業衛生師根據專業判斷（Professional Judgment）設定先驗機率。這其實是在定義 p(\\theta_1, \\theta_2) 的形狀。\n決策機率：最終輸出的「第 4 類暴露機率為 80%」，這個 80% 是怎麼來的？它是透過對所有落在第 4 類定義範圍內的 (\\mu, \\sigma) 組合進行積分（加總其後驗機率）得來的，這屬於離散化應用。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#d.常態分佈均值與變異數未知",
    "href": "0109CH3.html#d.常態分佈均值與變異數未知",
    "title": "0109CH3 多參數模型",
    "section": "D.常態分佈均值與變異數未知",
    "text": "D.常態分佈均值與變異數未知\n理解「平均掉滋擾參數」的威力。\n\n6.1 標準常態模型6.2 滋擾參數的邊際後驗6.3 關注參數的邊際後驗E.小結\n\n\n\n假設數據 y \\sim N(\\mu, \\sigma^2)。我們想估計 \\mu，但不知道 \\sigma^2。使用無訊息先驗（Noninformative Prior）：\n\np(\\mu, \\sigma^2) \\propto (\\sigma^2)^{-1}\n\n\n\n\n\n根據 Gelman 的推導，\\sigma^2 的邊際後驗分佈服從 Scaled Inverse-Chi-Square 分佈。這告訴我們，由於數據量有限，變異數有可能是某個很大的值（分佈有長尾）。\n\n\n\n\n如果我們知道 \\sigma，\\mu 的後驗分佈應該是常態分佈（Normal）。\n當把那個服從 Inverse-Chi-Square 的 \\sigma^2 積掉之後，\\mu 的邊際後驗分佈變成了什麼？答案是：t 分佈（Student’s t-distribution）。\n\n\\mu | y \\sim t_{n-1}(\\bar{y}, s^2/n)\n\n這也就是「為什麼我們在小樣本時要用 t 檢定，而不是 Z 檢定（常態分佈）？」。因為，「因為樣本數小，標準差未知。」。\nt 分佈之所以比常態分佈『胖』（Fatter tails），正是因為它包含了對未知標準差（滋擾參數）的平均！」\n那個胖胖的尾巴，就是貝氏積分過程中所保留下來的「不確定性」。這證明了貝氏方法與經典統計學在這一點上是殊途同歸的，而且貝氏方法提供了更直觀的數學解釋：我們為了解決對 \\sigma 的無知，付出了讓 \\mu 的估計範圍變寬的代價。\n\n\n\n\n不要假裝知道我們不知道的事（例如真實的 GSD）。透過對這些滋擾參數進行嚴謹的積分或模擬，我們給出的暴露評估結果才是經得起考驗的，才能真正保護勞工免受潛在危害的威脅。\n傳統統計與貝氏比較表\n\n\n\n\n\n\n\n\n\n\n比較項目\n傳統頻率學派\n貝氏統計 (Bayesian)\n對 OSH 的影響\n\n\n參數視角\n參數是固定的常數 (\\theta)\n參數是隨機變數，有其機率分佈\n貝氏能描述 GSD 的不確定性範圍\n\n\n滋擾參數處理\nPlug-in Method (直接代入樣本估計值)\nMarginalization (對所有可能值進行積分/平均)\n傳統方法在小樣本下易低估風險\n\n\n結果呈現\n點估計 + 信賴區間 (Confidence Interval)\n後驗機率分佈 + 信用區間 (Credible Interval)\n貝氏產出可直接用於決策的機率 (如: &gt;95% OEL 的機率)\n\n\n小樣本表現\n往往過度自信 (區間過窄)\n較為保守 (區間較寬，如 t 分佈)\n貝氏更符合預警原則\n\n\n\n\n\n參考資料：\n\nGelman et al., Bayesian Data Analysis, Chapter 3.\nHewett et al., Rating Exposure Control Using Bayesian Decision Analysis.\nLavoué et al., Expostats: A Bayesian Toolkit.\nbrms package documentation (Measurement Error).",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#常態數據與無訊息先驗分布",
    "href": "0109CH3.html#常態數據與無訊息先驗分布",
    "title": "0109CH3 多參數模型",
    "section": "3.2 常態數據與無訊息先驗分布",
    "text": "3.2 常態數據與無訊息先驗分布\n\n當我們站在工廠的作業現場，手中握著僅有的三、五個空氣採樣數據，卻要對成千上萬個工作日的工人健康風險做出攸關性命的判斷時，傳統統計學往往讓我們感到力不從心。\n在變異數未知的情況下，對平均值的估計必然遵循 t 分佈（Student’s t-distribution），這正是職業衛生中處理小樣本數據時「不確定性」的數學根源。\n我們將連結理論與實務，探討如何利用 Hewett 等人提出的貝氏決策分析（Bayesian Decision Analysis, BDA）框架 ，以及現代化的 Expostats 工具箱 ，將這些抽象的數學符號轉化為保護勞工健康的具體決策。  \n\n\n\nＡ. 傳統頻率學派的侷限性B. 貝氏統計的直觀優勢C. 常態數據與無訊息先驗分布2. OHS實務問題D. 貝氏決策分析（BDA）的應用E. 計算實作：Expostats 工具箱的演進F. 常見誤區G. 結論附表：小樣本暴露評估方法的比較摘要\n\n\n\n在職業衛生領域，長期以來我們依賴頻率學派（Frequentist）的統計方法，例如 NIOSH 77-173 手冊中建立的抽樣策略 。在這種框架下，我們假設暴露參數（如真實的幾何平均值 GM 或幾何標準差 GSD）是固定但未知的常數。機率被解釋為「長期重複抽樣下的頻率」。  \n然而，這種觀點在面對職業衛生現場數據時經常出現問題：\n\n\n樣本極度稀缺：對於一個由 50 名工人組成、每年運作 250 天的相似暴露群（Similar Exposure Group, SEG），總暴露人天數達 12,500 天。若我們僅進行 6 到 10 次採樣，樣本量僅佔母體的 0.08% 。在 N=3 的極端情況下，頻率學派的信賴區間（Confidence Interval）往往寬到毫無實用價值。  \n變異數的不確定性：頻率學派通常使用樣本標準差 s 作為母體標準差 σ 的點估計。但當樣本很小時，s 本身就有巨大的不確定性，且容易低估真實的變異。\n無法回答核心問題：業主和勞工想知道的是「這個環境安全的機率是多少？」。頻率學派只能回答「如果這個環境是安全的，我們觀察到這些數據的機率很低」，這是一種迂迴的邏輯。\n\n\n\n\n\n貝氏統計（Bayesian Statistics）提供了一個更符合人類直覺的框架。在這裡，機率代表的是我們對某個假設的「信念程度」（Degree of Belief）。參數不再是固定的未知數，而是隨機變數，擁有自己的機率分布。  \n這與工業衛生師（Industrial Hygienist, IH）的決策過程不謀而合：\n\n先驗分布（Prior）：在採樣前，我們根據專業判斷、原料毒性、通風設備狀況，已經對暴露風險有一個初步的「信念」。\n概似函數（Likelihood）：我們收集到的空氣採樣數據。\n後驗分布（Posterior）：結合先驗知識與數據證據，更新我們對暴露風險的看法。\n\n這種方法允許我們在數據稀缺時引入專業知識（Informative Priors），或者在完全無知時使用無訊息先驗（Noninformative Priors）來讓數據說話。接下來介紹處理「當我們先驗知識為空白時，如何客觀處理常態分佈數據」。  \n\n\n\n\n\n在職業衛生中，暴露數據通常呈現對數常態分佈（Lognormal Distribution），取對數後即為常態分佈。因此，這裡討論的 μ 對應的是 ln(GM)，而 σ 對應的是 ln(GSD)。  \n\n\n1. 雙參數模型的挑戰\n\n在單參數模型中（如二項式分佈估計盛行率），我們只有一個未知數。但在常態分佈模型\\ N(μ,σ^2) 中，我們同時面臨兩個未知參數：平均值 \\ μ 和變異數 \\ σ^2。\n通常，我們最關心的是\\ μ （代表平均暴露水準）。但在貝氏分析中，為了準確估計\\ μ ，我們必須同時處理 \\ σ^2。這裡的\\ σ^2被稱為「滋擾參數」（Nuisance Parameter）。它雖然不是我們推論的直接目標，但它是構建真實模型所必需的，且其不確定性會直接影響我們對 \\ μ 的估計精度。  \n貝氏方法不將\\ σ^2視為一個固定值代入，而是透過積分將其「邊緣化」（Marginalize），從而將 \\ σ^2的不確定性完整地傳遞給\\ μ 的後驗分布。這就是為什麼貝氏區間在小樣本下往往比傳統區間更合理的原因。\n\n\n\n\n\n當樣本量 n 很小（例如 3 個樣本）時，變異數分布的右尾會拖得很長。 這解釋了為什麼在小樣本下，GSD 的信賴區間上限（UCL）往往高得嚇人（例如 GSD 估計值是 2.5，但 95% UCL 可能是 10.0）。這是數學上的必然，反映了我們無法排除「運氣好抽到數值相近的樣本，但實際變異極大」的可能性。\n當你只有 3 個樣本時，真實暴露濃度極高（或極低）的可能性，比常態分佈預測的要大得多。這就是為什麼 NIOSH 統計手冊要求使用 t 值來計算 UCL 的根本原因—它是對我們「無知」的補償。\n\n\n\n\n\n在 2006 年，Hewett, Logan 等人將這一理論推進了一步，提出了適合職業衛生的 貝氏決策分析（Bayesian Decision Analysis, BDA） ，解決了純數學推導在實務上的不足。  \n\n\n1. 引入專業判斷：從無訊息到有訊息\n\n假設 μ 和 lnσ 可以是任意值。但在工廠裡，但我們知道：\n\n苯的濃度不可能是一百萬 ppm（那是純物質）。\n暴露的 GSD 通常介於 1.1 到 4.0 之間，極少超過 6.0 。  \n\nHewett 的 BDA 框架引入了 參數空間限制（Parameter Space Constraints） 。這相當於使用了一個「截斷的均勻先驗」（Truncated Uniform Prior）。  \n\n不再假設 p(σ)∝1/σ 在 (0,∞) 上。\n限制 σ 在合理的範圍內（例如 ln(1.05) 到 ln(4.0)）。\n這個簡單的動作產生了巨大的實務影響。它切斷了 t 分布那條代表「物理上不可能的巨大變異」的長尾巴，從而大幅縮小了不確定性區間，使得即便在 N=3 的情況下，也能做出更有信心的判斷。\n\n\n\n\n2. 決策三部曲\n\nBDA 框架將貝氏推理具象化為三個分佈圖 ：  \n\n\n先驗決策分佈（Prior Decision Distribution）：這代表了 IH 在採樣前的專業判斷。例如，根據製程封閉程度，IH 可能有 70% 的信心認為該暴露屬於「高度控制」（Category 1）。這不再是數學上的 1/σ2，而是專家經驗的量化。\n概似決策分佈（Likelihood Decision Distribution）：這完全由數據決定，背後運算的數學核心正是聯合概似函數。它展示了如果只看這 3 個樣本，數據告訴我們什麼。通常對於小樣本，這個分佈會非常寬（反映 t 分布的特性）。\n後驗決策分佈（Posterior Decision Distribution）：這是先驗與概似的數學合成。如果先驗很強（專家很有信心），它會收斂數據的雜訊；如果數據很強（樣本很多），它會修正專家的偏見。\n\n\n\n3. 暴露分級範疇\n\n為了讓統計結果具有行動指導意義，BDA 將後驗機率映射到 AIHA 的暴露控制等級 ：  \n\nCategory 0 (可忽略): 真實第 95 百分位數 (X95​) ≤1% OEL。\nCategory 1 (高度控制): X95​≤10% OEL。\nCategory 2 (良好控制): X95​≤50% OEL。\nCategory 3 (受控): X95​≤100% OEL。\nCategory 4 (控制不良): X95​&gt;100% OEL。\n\n這樣的輸出（例如：「有 95% 的機率屬於 Category 2」）比傳統的「平均值 95% UCL 為 20 ppm」更易於與管理層溝通。\n\n\n\n\n\n在處理更複雜的現實情況（如數據低於偵測極限 LOD）時，需要依賴數值運算，而 Expostats 正是此領域的佼佼者 。\n\n1. 從積分到模擬（MCMC）\n\nExpostats 使用 JAGS (Just Another Gibbs Sampler) 引擎進行運算 。這對應到課程中將會學到的 馬可夫鏈蒙地卡羅（MCMC） 方法。  \n\n在通過數學技巧積分掉 σ2 得到 μ 的 t 分布。\n在 Expostats 中，電腦在 (μ,σ) 的參數空間中進行數萬次的隨機跳躍（Sampling）。\n這些跳躍點的集合構成了聯合後驗分布。如果我們把這些點畫成直方圖。\n\n\n\n\n2. 處理設限數據（Censored Data）\n\n這是 Expostats 超越傳統 t 檢定最大的優勢。\n\n傳統方法：遇到「&lt; LOD」的數據，常粗糙地用 LOD/2 或 LOD/2​ 取代。這會扭曲平均值和變異數的估計。\n貝氏方法：在概似函數中，對於 &lt; LOD 的數據，我們不代入機率密度函數 p(y∣θ)，而是代入累積分布函數 P(y&lt;LOD∣θ) 。  \n這意味著，模型會嘗試尋找一組 (μ,σ)，使得這組參數「產生小於 LOD 的數據」的機率最大化。這在數學上是非常嚴謹的處理方式。\n\n\n\n\n3. 超標風險（Overexposure Risk）的計算\n\nExpostats 能夠直接回答：「真實的 95 百分位數超過 OEL 的機率是多少？」 這在數學上是對聯合後驗分布進行積分：\n\nP(X_{0.95} &gt; \\text{OEL} | y) = \\iint_{R} p(\\mu, \\sigma | y) d\\mu d\\sigma\n\n其中區域 R 是滿足 \\mu + 1.645\\sigma &gt; \\ln(\\text{OEL}) 的參數空間。這種直接的機率陳述（例如「有 85% 的風險超標」）是頻率學派無法提供的，因為在頻率學派中，參數是固定的，沒有機率可言 。  \n\n\n\n\n\n\n頻率學派 95% 信賴區間（CI）：「如果我們重複做 100 次採樣實驗，算出 100 個區間，其中有 95 個會包含真實平均值。」（這對單次決策毫無幫助，且極其拗口）。\n貝氏 95% 可信區間（Credible Interval, CrI）：「真實平均值落在這個範圍內的機率是 95%。」（這正是業主想聽的）。\n關鍵連結：在無訊息先驗的條件下，貝氏的 CrI 數值上完全等於頻率學派的 CI 。這賦予了我們在實務上使用 t 分布公式，但心裡用貝氏直覺來解釋的理論正當性。  \n「只採 3 個樣真的夠嗎？」\n\n從 BDA 的角度（Hewett 方法），如果我們先驗知識很強（例如這是封閉管路，過去十年都沒洩漏），強大的先驗會「壓制」t 分布的寬度。\n數據少時，結論的信心來自於先驗知識。如果沒有先驗知識（無訊息先驗），單靠 3 個樣本做決策是非常危險的（除非檢測值極低，例如 &lt; 1% OEL）。\n\n\n\n\n\n\n對於職業安全衛生專業人員而言，掌握這一段理論具有雙重意義：\n\n\n理解風險的本質：明白小樣本帶來的高不確定性是來自於對「變異程度」的無知。\n擁抱貝氏的優勢：看見從無訊息先驗跨越到有訊息先驗（Hewett/Expostats）時，決策品質的巨大飛躍。\n\n\n\n\n\n\n\n\n\n\n\n\n\n特徵\n頻率學派 (NIOSH 77-173)\n貝氏無訊息先驗\n貝氏有訊息先驗 (BDA/Hewett)\n\n\n機率哲學\n機率 = 長期錯誤率\n機率 = 信念程度\n機率 = 信念 + 先前知識\n\n\n先前知識\n忽略 (隱含均勻先驗)\n明確定義為「模糊」(1/σ2)\n明確建模 (如 GSD ≈ 2)\n\n\n變異數處理\n點估計 s，使用 t 統計量\n積分消除 σ，導出 t 分布\n使用先驗約束 σ 的範圍\n\n\n輸出結果\n信賴區間 (如 UCL)\n可信區間 (CrI)\n暴露等級的機率分布\n\n\n小樣本 (N=3) 表現\nUCL 極大，常無法決策\nCrI 也很寬 (數值上同頻率學派)\nCrI 較窄，可輔助決策\n\n\n結果解釋\n“95% 的區間會覆蓋真值”\n“真值在區間內的機率為 95%”\n“真值在區間內的機率為 95%”",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#具有共軛先驗分佈的常態數據",
    "href": "0109CH3.html#具有共軛先驗分佈的常態數據",
    "title": "0109CH3 多參數模型",
    "section": "3.3 具有共軛先驗分佈的常態數據",
    "text": "3.3 具有共軛先驗分佈的常態數據\n\n我們將深入探討以下核心主題：\n\n\n職業暴露數據的隨機本質：為何常態分佈模型（對數常態）是暴露評估的核心。\n共軛先驗的架構：如何將「專業判斷」量化為數學參數。\n貝氏更新機制：解析數據如何修正我們對職場危害的認知。\n邊際後驗分佈：如何從聯合分佈中提取出關於 GM 和 GSD 的具體推論。\n後驗預測分佈：如何預測「下一個工人」的暴露風險（Exceedance Fraction）。\n\n\n第一部分：理論背景與職業衛生脈絡第二部分：共軛先驗分佈第三部分：後驗分佈的推導與更新機制第四部分：邊際後驗分佈第五部分：後驗預測分佈第六部分：職業衛生實務案例演練第七部分：進階議題與軟體應用結論\n\n\n\n1.1 觀念轉換\n\ny（常態數據） \\rightarrow \\ln(X)（暴露濃度的自然對數）\n\\mu（均值） \\rightarrow \\ln(GM)（幾何平均數的對數）\n\\sigma（標準差） \\rightarrow \\ln(GSD)（幾何標準差的對數）\n\n所有的數學推導都在對數尺度上進行，最終結果需取指數（exp）還原為濃度單位（ppm 或 mg/m³）。\n\n\n1.2 似然函數：數據的數學形狀\n\n假設我們有一組觀測值 y = (y_1, \\dots, y_n)，它們獨立且同分佈（i.i.d.）於常態分佈 N(\\mu, \\sigma^2)。\n對於單個數據點 y_i，其機率密度函數（pdf）為：\n\np(y_i|\\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{1}{2\\sigma^2}(y_i - \\mu)^2\\right)\n\n對於整組數據 y，其聯合似然函數是個別密度的乘積：\n\np(y|\\mu, \\sigma^2) = \\prod_{i=1}^n p(y_i|\\mu, \\sigma^2) \\propto \\sigma^{-n} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu)^2 \\right)\n\n無論我們收集了多少暴露數據，對於常態模型而言，我們只需要知道兩個數值：樣本均值 \\bar{y} 和 樣本變異數 s^2。這兩個數值包含了數據中關於 \\mu 和 \\sigma^2 的所有訊息 。\n\n\n\n\n\n\nGelman 提出，為了使後驗分佈具有解析解（Analytical Solution），我們必須選擇一個與似然函數「共軛」的先驗分佈族。對於未知均值和變異數的常態分佈，這個共軛先驗是 常態-逆卡方分佈（Normal-Inverse-Chi-Square, N-Inv\\chi^2）。\n\n\n2.1 聯合先驗的分解\n\n聯合先驗 p(\\mu, \\sigma^2) 被分解為條件機率的乘積：\n\np(\\mu, \\sigma^2) = p(\\sigma^2) \\times p(\\mu|\\sigma^2)\n\n這意味著我們必須先描述變異數（製程波動），然後在此基礎上描述均值（暴露水準）。\n\n\n\n2.2 變異數的先驗：縮放逆卡方分佈 p(\\sigma^2)\n\n先驗變異數猜測 (Prior Variance Guess)這是我們在採樣前，根據經驗認為該製程的波動程度。例如，對於一個控制良好的連續製程，我們可能預期 GSD=2.0，則 \\sigma_0 = \\ln(2.0) \\approx 0.693，故 \\sigma_0^2 \\approx 0.48。\n\n\n\n2.3 均值的條件先驗：常態分佈 p(\\mu|\\sigma^2)\n\n在給定變異數 \\sigma^2 的情況下，均值 \\mu 服從常態分佈。\n先驗均值猜測 (Prior Mean Guess)這是我們預期的暴露濃度中心。例如，若預期 GM 為 10 ppm，則 \\mu_0 = \\ln(10)。這通常來自於類似暴露群（SEG）的歷史數據或物理模型推估。\n如果製程本身變異很大（\\sigma^2 大），那麼我們對均值 \\mu 的估計也會自然地變得不確定（分佈變寬）。這是貝氏模型內建的合理性檢驗機制。\n\n\n\n\n\n\n將上述的先驗與似然函數相乘，我們發現後驗分佈 p(\\mu, \\sigma^2|y) 依然是 常態-逆卡方分佈。這就是「共軛」的魔力。\n如果工業衛生師「自以為是」地設定了一個很低的先驗均值 \\mu_0（認為很安全），但實際數據 \\bar{y} 卻很高， (\\bar{y} - \\mu_0)^2 就會變得非常大。這會導致後驗變異數 \\sigma_n^2 劇烈膨脹。\n這是一個自動的安全閥機制：當專家的判斷與數據打架時，模型會告訴我們：「情況不明朗，變異性可能比你想像的更大。」這會導致推估的 95 百分位數（P95）上升，從而做出更保守（保護工人）的決策。這解釋了為什麼錯誤的先驗不會導致災難性的低估風險，反而會增加不確定性區間 1。\n\n1 文獻1\n\n\n\n我們通常不關心 \\mu 和 \\sigma^2 的聯合機率，他們想知道的是單獨的風險指標。\n\n\n4.1 變異數的邊際後驗 \\sigma^2 | y\n\n如果我們對 \\mu 進行積分，\\sigma^2 的後驗分佈服從縮放逆卡方分佈。\n\n\\sigma^2 | y \\sim Inv-\\chi^2(\\nu_n, \\sigma_n^2)\n\n\n\n\n4.2 均值的邊際後驗 \\mu | y\n\n如果我們對 \\sigma^2 進行積分，\\mu 的後驗分佈服從 非標準 t 分佈（location-scale t-distribution）。\n\n\n\n\n\n\n我們關心的往往不是「母體平均是多少」，而是「明天某個工人會不會吸入過量的化學品」。這就是後驗預測分佈 p(\\tilde{y}|y)。\n對於一個新的觀測值 \\tilde{y}，其預測分佈也是一個 t 分佈。\n這個預測分佈是計算 Exceedance Fraction（超過 OEL 的比例） 的數學基礎。我們計算這個 t 分佈大於 \\ln(OEL) 的面積，即得到該工作場所的超標風險機率。這是 AIHA 暴露評估策略中「Category 4」判定的核心依據。\n\n\n\n\n\n情境：評估甲苯暴露（OEL = 20 ppm）。\n先驗設定：\n\n資深 IH 判斷：該製程有局部排氣，濃度應很低，約在 2 ppm (\\mu_0 = \\ln(2) \\approx 0.69)。\n變異性：一般作業環境，預估 GSD = 2.0 (\\sigma_0 \\approx 0.69, \\sigma_0^2 \\approx 0.48)。\n信心：中等信心，相當於 2 個樣本的權重 (\\kappa_0 = 2, \\nu_0 = 2)。\n\n新數據：採樣 3 點，分別為 5, 8, 12 ppm。\n\n對數數據 y: 1.61, 2.08, 2.48。\n樣本統計：\\bar{y} = 2.06 (GM \\approx 7.8 ppm), s^2 = 0.19。\n\n貝氏更新計算：\n\n\n\\kappa_n = 2 + 3 = 5。\n\\mu_n = \\frac{2(0.69) + 3(2.06)}{5} = \\frac{1.38 + 6.18}{5} = 1.51。\n\n解讀：後驗 GM \\approx \\exp(1.51) \\approx 4.5 ppm。數據把先驗的 2 ppm 拉高到了 4.5 ppm。\n\n\\nu_n = 2 + 3 = 5。\n\\nu_n \\sigma_n^2 = 2(0.48) + 2(0.19) + \\frac{2\\cdot3}{5}(2.06 - 0.69)^2\n\n= 0.96 + 0.38 + 1.2(1.87) = 1.34 + 2.24 = 3.58。\n\\sigma_n^2 = 3.58 / 5 = 0.716。\n解讀：後驗 GSD \\approx \\exp(\\sqrt{0.716}) \\approx 2.33。\n關鍵點： 2.24 貢獻了大部分的變異。因為先驗覺得濃度很低 (0.69)，但數據很高 (2.06)，模型「困惑」了，因此增加了對變異性的估計（從先驗的 0.48 增加到 0.716）。這是一個警訊，告訴 IH 製程可能不如預期穩定。\n\n\n\n\n\n理論在現代工具中的實踐與局限：\n\n\n左設限數據 (Censored Data/LOD)：\n解析解前提是數據是完整的常態分佈。但在 OSH 中，我們常遇到「&lt; LOD」的數據。這時，共軛先驗的解析解失效。現代工具如 Expostats 使用 JAGS (MCMC) 來解決這個問題，通過數值模擬而非公式推導來獲得後驗分佈，但其背後的邏輯（先驗+似然=後驗）完全一致 。\n軟體實現：\n雖然手算公式有助理解，但實務上應推薦使用 IHDataAnalyst (IHDA) 或免費的 Expostats。這些工具內部封裝了上述 \\kappa_n, \\nu_n 的更新算法，用戶只需通過滑桿設定「先驗信心」即可。\n\n\n\n\n\n通過 常態-逆卡方共軛先驗，我們得以將「經驗」合法化、量化，並與「數據」有機結合。\n貝氏方法不是在操弄數據，而是在管理不確定性。 當樣本數少時，它通過先驗（\\kappa_0）保護我們免受隨機性的愚弄；當先驗錯誤時，它通過膨脹變異數（衝突項）來警告我們潛在的風險。這正是我們作為安全衛生專家的核心價值所在。\n\n\n\n參考文獻整合與引用說明\n\n本報告整合了 Gelman BDA3 的理論架構 1、Hewett 等人的 BDA 應用框架 1、Expostats 的演算邏輯 1，以及 Normal-Inverse-Chi-Square 的數學性質研究 2。所有公式推導均基於 BDA3 第 3 章的標準定義。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0102CH1.html",
    "href": "0102CH1.html",
    "title": "BDA3_CH1 機率與貝氏推論 Probability and inference",
    "section": "",
    "text": "Caution提醒\n\n\n\n\n\n“Alert - 這是作者的教學網站，需要輔導或諮詢者，請與作者聯繫。”",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "1.機率與推論"
    ]
  },
  {
    "objectID": "0102CH1.html#sec-references",
    "href": "0102CH1.html#sec-references",
    "title": "BDA3_CH1 機率與貝氏推論 Probability and inference",
    "section": "References",
    "text": "References",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "1.機率與推論"
    ]
  },
  {
    "objectID": "0109CH3.html#類別數據的多項式模型",
    "href": "0109CH3.html#類別數據的多項式模型",
    "title": "0109CH3 多參數模型",
    "section": "3.4 類別數據的多項式模型",
    "text": "3.4 類別數據的多項式模型\n\n如何在數據稀缺（Data Scarcity）的現實下，做出關乎勞工暴露風險的重大決策？\n傳統的頻率學派統計（Frequentist Statistics）在樣本數充足時表現優異，但在面對僅有 3 至 6 個樣本的相似暴露群（Similar Exposure Group, SEG）時，往往顯得捉襟見肘。計算出的信賴區間（Confidence Interval）常寬至涵蓋 0.1 倍到 10 倍的容許暴露標準（OEL），這種「可能極其安全，也可能極其危險」的結論，對於需要決定是否投資百萬改善通風設備的管理層而言，似乎沒有實質指導意義。\n我們為職業衛生專業人員引介一套更為強大的決策邏輯——貝氏統計（Bayesian Statistics），從數學原理出發，推導至 AIHA 暴露分級（Categories 0-4）的實務應用，展示如何將專家的專業判斷（Professional Judgment）轉化為嚴謹的數學參數，從而實現從「合規管理」到「風險治理」的精神。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#第三章-實務架構aiha-暴露分級與-hewett-的貝氏決策分析",
    "href": "0109CH3.html#第三章-實務架構aiha-暴露分級與-hewett-的貝氏決策分析",
    "title": "0109CH3 多參數模型",
    "section": "第三章 實務架構：AIHA 暴露分級與 Hewett 的貝氏決策分析",
    "text": "第三章 實務架構：AIHA 暴露分級與 Hewett 的貝氏決策分析\n理解了 Gelman 的數學模型後，我們需要將其應用於具體的職業衛生場景。這需要引入 Hewett 等人（2006）在文獻1 中提出的**貝氏決策分析（Bayesian Decision Analysis, BDA）**架構，以及 AIHA 的暴露分級系統。  \n\n3.1 AIHA 暴露控制分級（Exposure Categories 0-4）深度解析\n在 Hewett 的架構中，暴露評估不再是單純的「濃度 vs 標準」，而是將暴露分佈（Exposure Profile）歸類為五個管理等級。這是連結統計數據與管理行動的關鍵介面。\n下表詳細整理了各分級的定義、統計意義與建議行動（整合自文獻1 ）：  \n\n\n\n\n\n\n\n\n\n暴露分級 (Category)\n定義描述 (Qualitative Description)\n統計定義 (X0.95​ vs OEL)\n管理意涵與建議行動 (Action)\n\n\nCategory 0\n\n\n(微不足道)\nTrivial：暴露極微或不存在。員工幾乎無吸入接觸。\nX0.95​≤1% OEL\n無需行動 (No action)。資源可移轉至其他高風險區。\n\n\nCategory 1\n\n\n(高度控制)\nHighly Controlled：暴露極低。偶爾發生但頻率極低（&lt;5%時間）。\n1%&lt;X0.95​≤10% OEL\n一般危害通識。定期（如每數年）確認製程未變更。\n\n\nCategory 2\n\n\n(良好控制)\nWell Controlled：常有低濃度接觸，極少有高濃度接觸。\n10%&lt;X0.95​≤50% OEL\n化學品特定危害通識。需定期監測以防惡化。\n\n\nCategory 3\n\n\n(受控)\nControlled：在標準內，但安全裕度小。偶有高濃度（&gt;OEL）但不頻繁。\n50%&lt;X0.95​≤100% OEL\n加強管理：化學品特定通識、暴露監測、醫學監測、作業檢討。\n\n\nCategory 4\n\n\n(控制不良)\nPoorly Controlled：經常超過容許暴露標準。\nX0.95​&gt;100% OEL\n立即改善：工程控制（通風）、呼吸防護計畫、密集監測。\n\n\n\n專家洞察：為什麼要這樣分類？ 傳統的合規性檢測（Compliance Testing）是二分法（過/不過）。但在 AIHA 架構下，我們將「未超標」的區域細分為 0-3 四個等級。這不僅是為了精確，更是為了資源分配。\n\n對於 Cat 0 和 Cat 1，我們幾乎可以「放手」，將寶貴的採樣資源集中到 Cat 3。\n這就是為什麼我們需要計算「屬於各 Category 的機率」，而不僅僅是「P95 是多少」。\n\n\n\n3.2 貝氏決策分析（BDA）的操作流程\nHewett 提出的 BDA 流程，實際上是在單一 SEG 層次上應用貝氏推論。這個過程產出的結果，正是上一章多項式模型所需的輸入數據。\n流程詳解：\n\n建立先驗決策分佈（Prior Decision Distribution）： 工業衛生師根據製程知識、物理模型或同業經驗，主觀判斷該 SEG 屬於各 Category 的可能性。\n\n例如：這是一個封閉管路系統，經驗顯示這類系統 90% 是 Cat 1，10% 是 Cat 2。這就是您的先驗。\n\n計算似然決策分佈（Likelihood Decision Distribution）： 進行現場採樣（例如 n=6）。利用統計方法（如對數常態分佈的似然函數）計算這組數據「最像」哪一類。\n\n例如：數據顯示 GM = 5% OEL，GSD = 1.8。這組數據在統計上強烈支持 Cat 1。\n\n導出後驗決策分佈（Posterior Decision Distribution）： 結合 Prior 與 Likelihood，得出最終判定。\n\n結果：95% 機率是 Cat 1，5% 機率是 Cat 2。\n\n\n關鍵連結： Hewett 的方法產出了「單一 SEG 屬於各類別的機率」。當我們管理整個工廠時，我們會對數十個 SEG 進行這樣的評估，然後將這些分類結果（Categorical Data）彙整起來，這時就回到了 Gelman 3.4 節的 Dirichlet-Multinomial 模型，用來評估「整廠的暴露控制績效」。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#第四章-現代化工具應用expostats-tool-3-與群組比較",
    "href": "0109CH3.html#第四章-現代化工具應用expostats-tool-3-與群組比較",
    "title": "0109CH3 多參數模型",
    "section": "第四章 現代化工具應用：Expostats Tool 3 與群組比較",
    "text": "第四章 現代化工具應用：Expostats Tool 3 與群組比較\n理論與架構完備後，我們需要強大的運算工具。Lavoué 等人開發的 Expostats 是目前職業衛生領域最先進的貝氏分析工具箱，其中的 Tool 3 專門用於處理類別數據的比較。  \n\n4.1 Expostats Tool 3 功能解析：群組比較（Group Comparison）\n根據文獻2 ，Tool 3 的設計核心是回答：「不同群組之間的暴露分佈是否有顯著差異？」這在本質上就是類別數據分析的應用。  \n\n介入成效評估：這是 Tool 3 最典型的應用。將數據分為「改善前（Group A）」與「改善後（Group B）」。這裡的「前/後」就是類別變數。\n群組同質性驗證：比較「早班」與「晚班」，或「一廠」與「二廠」。\n\n\n\n4.2 貝氏計算的優勢：處理受限數據（Censored Data）\n職業衛生數據常包含「低於偵測極限（&lt;LOD）」的值，稱為左受限數據（Left-censored data）。傳統統計常粗暴地用 LOD/2 或 LOD/2​ 取代，這會嚴重扭曲 P95 的估計，導致錯誤的分類（例如將 Cat 2 誤判為 Cat 1）。\nExpostats 利用 JAGS (Just Another Gibbs Sampler) 進行蒙地卡羅模擬（MCMC），能精確處理各種受限數據（左受限、右受限、區間受限）。這意味著：  \n\n即便是充滿 “ND”（未檢出）的數據，Expostats 也能給出合理的 P95 估計區間。\n這保證了我們將 SEG 歸類到 Category 0-4 時的準確性，為後續的多項式模型分析提供高品質的輸入數據。\n\n\n\n4.3 Tool 3 的輸出與決策\nTool 3 不僅比較平均值，還能計算機率聲明（Probabilistic Statements）。 例如：\n\n「改善後，P95 下降的機率為 98%。」\n「改善後，該 SEG 屬於 Category 4 的機率從 80% 降至 5%。」\n\n這種直接的機率語言，比起傳統的「t檢定 p &lt; 0.05」，更容易讓工廠經理理解介入措施的價值。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#第五章-綜合應用案例半導體廠暴露管控儀表板",
    "href": "0109CH3.html#第五章-綜合應用案例半導體廠暴露管控儀表板",
    "title": "0109CH3 多參數模型",
    "section": "第五章 綜合應用案例：半導體廠暴露管控儀表板",
    "text": "第五章 綜合應用案例：半導體廠暴露管控儀表板\n為了將上述理論融會貫通，我們設計一個完整的實務案例。這個案例展示了如何結合 Gelman 的數學模型、Hewett 的分級架構與 Expostats 的計算能力，解決真實世界的管理問題。\n案例背景： 您是一家大型半導體廠的工安經理。廠內有 50 個不同的化學品操作單元（SEGs）。總經理問您：「我們廠的化學品暴露控制到底做得好不好？有多少比例是高風險的？」\n步驟 1：建立先驗（The Prior）- 專家直覺的量化\n\n情境：基於過去的稽核經驗與同業水準，您認為大部分單元控制良好，但仍有少數死角。\n設定 Dirichlet 先驗參數 α（偽計數）：\n\nα0​ (Cat 0): 5 (相當有把握有些地方極微量)\nα1​ (Cat 1): 15 (高度控制區應是主流)\nα2​ (Cat 2): 20 (良好控制區)\nα3​ (Cat 3): 8 (邊緣區)\nα4​ (Cat 4): 2 (預期很少有失控區)\n總信心強度：∑α=50。這代表您的經驗強度相當於已經評估過 50 個 SEG。\n\n\n步驟 2：數據收集與個別評估（The Data）- Expostats 的應用\n\n執行：對這 50 個 SEG 進行採樣（受限於預算，每組僅測 3-6 個樣本）。\n運算：使用 Expostats 計算每個 SEG 的 P95，並處理 &lt;LOD 數據。\n分類：根據 Hewett 的標準（P95 vs OEL），將每個 SEG 歸類。\n\n實際觀測結果 y：\n\ny0​ (Cat 0): 8 個\ny1​ (Cat 1): 12 個\ny2​ (Cat 2): 18 個\ny3​ (Cat 3): 10 個\ny4​ (Cat 4): 2 個\n\n\n\n步驟 3：貝氏更新（The Posterior）- Gelman 3.4 的計算\n\n利用多項式模型的共軛性質更新參數 (αnew​=αold​+y)：\n\nα0′​=5+8=13\nα1′​=15+12=27\nα2′​=20+18=38\nα3′​=8+10=18\nα4′​=2+2=4\n∑α′=50+50=100\n\n\n步驟 4：決策與報告 - 風險儀表板 現在，您可以回答總經理的問題了。\n\n控制不良率（Cat 4）估計：後驗期望值為 4/100=4%。\n\n洞察：雖然實際只測到 2 個（佔4%），且先驗也預估 4%，這顯示目前的高風險區域比例穩定在 4% 左右。\n\n高風險警示（Cat 3 + Cat 4）：(18+4)/100=22%。\n\n洞察：全廠有約 22% 的區域處於風險邊緣或失控狀態。這比您原先預期的 (8+2)/50=20% 稍高。這是一個警訊。\n\n行動建議：建議針對這 22% 的區域（Cat 3 & 4）啟動專案改善計畫，並利用 Expostats Tool 3 追蹤改善前後的成效。\n\n步驟 5：敏感度分析（Sensitivity Analysis） 如果有人質疑：「那是因為你先驗設得太樂觀了！」 您可以試著將先驗改為「均勻分佈（Uniform Prior）」，即 α=(1,1,1,1,1)。\n\n新的後驗 Cat 4 期望值：(1+2)/(5+50)=3/55≈5.45%。\n結果顯示，即使移除專家的樂觀先驗，Cat 4 的比例也僅上升到 5.5% 左右。這證明了您的結論是**穩健（Robust）**的。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#第六章-結論與展望",
    "href": "0109CH3.html#第六章-結論與展望",
    "title": "0109CH3 多參數模型",
    "section": "第六章 結論與展望",
    "text": "第六章 結論與展望\n貝氏統計並非遙不可及的象牙塔理論，它是解決職業衛生「數據稀缺」與「決策不確定性」的最佳工具。\n\n理論連結：Gelman 的 Dirichlet-Multinomial 模型 為我們處理「暴露分級」這類數據提供了堅實的數學骨架。它證明了「專家經驗」可以合法且科學地轉化為「偽計數」參與運算。\n實務架構：Hewett 的 AIHA 暴露分級（Cat 0-4） 將連續的濃度數據轉化為具體的管理行動，是連結統計與決策的介面。它讓我們從糾結於「0.49 ppm vs 0.51 ppm」的泥淖中解脫，轉向關注「控制等級」的宏觀圖景。\n工具賦能：Lavoué 的 Expostats 解決了繁瑣的運算問題，特別是 Tool 3 提供了群組比較與介入評估的強大功能，讓貝氏分析不再只是紙上談兵，而是現場工程師手中的利器。\n\n未來的職業衛生管理，將從「合規導向（Compliance-based）」轉向「風險導向（Risk-based）」。掌握這套從連續數據到類別決策、從單一評估到群體推論的邏輯，將是每一位高階職安衛人員必備的核心能力。\n我們鼓勵所有從業人員：\n\n擁抱不確定性：不要害怕數據少，利用貝氏方法量化它。\n善用先驗知識：您的經驗是有價值的數據，請將其納入模型。\n使用現代工具：停止使用 Excel 計算幾何平均數，開始使用 Expostats 進行完整的機率評估。\n\n透過科學的方法，我們能更有效地守護勞工健康，這正是我們這行的價值所在。\n(本報告參考文獻整合)\n\nGelman, A., et al. (2013). Bayesian Data Analysis, 3rd Edition. (Chapter 3).  \nHewett, P., et al. (2006). Rating Exposure Control Using Bayesian Decision Analysis. Journal of Occupational and Environmental Hygiene.  \nLavoué, J., et al. (2019). Expostats: A Bayesian Toolkit to Aid the Interpretation of Occupational Exposure Measurements. Annals of Work Exposures and Health.",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "introduction",
    "section": "",
    "text": "Hi\n\n\n\n Back to top",
    "crumbs": [
      "介紹Home",
      "介紹"
    ]
  },
  {
    "objectID": "0104CH2.html",
    "href": "0104CH2.html",
    "title": "BDA3_CH2 單參數模型",
    "section": "",
    "text": "date: 2026/01/04 - 2026/01/05",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#ch2-單參數模型",
    "href": "0104CH2.html#ch2-單參數模型",
    "title": "BDA3_CH2 單參數模型",
    "section": "CH2 單參數模型",
    "text": "CH2 單參數模型\n\n核心概念2.1 估計二項式數據的機率2.2 後驗分佈：數據與先驗資訊的折衷 (Posterior as compromise)2.3 後驗推論2.4 有訊息之先驗分佈 (Informative prior distributions)2.5 常態分佈（已知變異數）2.6 其他標準單參數模型2.7 範例：癌症率的有訊息先驗2.8 無訊息先驗分佈 (Noninformative prior distributions)2.9 弱訊息先驗分佈 (Weakly informative prior distributions)\n\n\n\n\n「貝氏統計讓我們將『過去的經驗（Prior）』與『現在的採樣數據（Data）』結合，形成對暴露風險更穩健的『新認知（Posterior）』。」\n職業衛生（OHS）常需要在「專家經驗」與「稀少的採樣數據」之間做決策。\n\n\n\n\n\n\n單參數？\n使用二項式分佈（Binomial Model）來估計一系列試驗中成功(或失敗)的**比例 \\theta**。透過貝氏推論，我們可以得到 \\theta 的後驗分佈。\nOHS 實務\n\n場景： **「超標率（Exceedance Fraction）」**評估。\n應用： 假設我們採樣了 n 個樣本，其中有 y 個樣本超過了容許濃度（OEL）。我們想知道該作業環境「真實可靠的超標機率 \\theta」是多少。\n傳統方法只看點估計（例如 10 個樣本有 1 個超標，超標率就是 10%）。\n但，貝氏方法會給出一個機率分佈，告訴我們超標率可能落在哪些範圍（例如：雖然看到 10%，但我們有 95% 的信心認為真實超標率在 2% 到 30% 之間）。ＱＡ❓判斷–&gt;這樣可以接受？\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.1(右圖)展示當樣本數 n 不同時，即便比例相同，我們對 \\theta 的確定程度（曲線的尖銳度）是完全不同的。(樣本越多，我們越確定)\n\n\n\n\n\n後驗均值（Posterior Mean）是「先驗均值」與「樣本均值」的加權平均。樣本數 n 越大，數據的權重就越重。\nOHS 實務\n\n場景： 修正我們對暴露風險的看法。\n應用： 假設過去經驗（Prior）告訴我們某製程很安全（超標率低），但今天採樣發現一個超標（Data）。貝氏統計不會立刻讓我們驚慌失措，而是「折衷/調和」兩者。\n這在我們只有 1-2 個樣本時特別好用，避免了「0 個超標就代表風險為 0」這種危險(不科學)的結論。\n關鍵觀念： 隨著採樣數據變多，過去的經驗（Prior）影響力會變小，讓數據說話。\n\n\n\n\n\n如何用數值描述後驗分佈：均值（Mean）、中位數（Median）、眾數（Mode）以及可信區間（Credible Intervals）。\nOHS 實務\n\n場景： 撰寫暴露評估報告。\n應用： 不要只給一個數字（均值）。要給出「不確定性範圍」(風險概念)。\n\n95% 後驗信賴區間，可以說「我們有 95% 的把握，該勞工的暴露風險是在 多少之間」。\n\n\n\n\n\n\n共軛先驗（Conjugate Prior），如 Beta 分佈對應二項式似然函數。解釋如何將「先驗知識」轉化為數學參數 \\alpha 和 \\beta 。\nOHS 實務\n\n場景： 利用「專家評估判斷」或「相似暴露群（SEG）的歷史數據」。\n應用： 在還沒採樣前，我們作為專家已經知道某些製程（如全密閉管線）風險很低。我們可以設定一個有資訊的先驗分佈（Informative Prior）來反映這個事實。\nBeta 分佈中的 \\alpha 和 \\beta 可以被想像成「虛擬的成功與失敗次數」。\n於 OHS 中的「罕見職業病」或「特殊製程安全事故」，即便數據顯示比例稍低，但因為我們有強大的背景知識（暴露致病機率或製程安全指標偏離），後驗分佈會被拉回接近實際背景值。這教導我們不要因為小樣本的極端值而過度反應。\n\n\n\n\n\n用於單一觀測值或多個觀測值在常態分佈下的推論。\n已知後驗精確度（Precision，變異數的倒數）是先驗精確度 \\tau_0^2 與數據精確度\\sigma^2 之和。\nOHS 實務\n\n場景： 噪音劑量(Normal)或對數轉換後的化學品濃度（Lognormal）。\n應用： 這是 AIHA 暴露評估策略的基礎模型。通常我們假設量測儀器的誤差（變異數）是已知的或可估計的，我們要推算的是勞工的平均暴露濃度。\n如果採樣儀器很準（\\sigma^2 小），數據說話大聲；如果專家經驗很豐富（\\tau_0^2 小），專家說話大聲。\n\n\n\n\n\nPoisson（計數資料）和 Exponential（等待時間）模型及其共軛先驗。\nOHS 實務\n\nPoisson 分佈： 用於分析「職災事故件數」或「職業病發生數」。例如：某工廠每年發生多少次外洩？\n\n透過 Gamma 先驗分佈，結合「過去十年的事故率」與「今年的事故數」，預估未來的風險。\n\nExponential 分佈： 用於「可靠度工程」或「兩次事故間隔時間」。\n\n評估安全防護設備（如呼吸防護具濾毒罐）的失效時間。\n\n\n\n\n\n\n分析美國腎臟癌死亡率地圖。發現最高與最低死亡率的縣市都集中在人口稀少的區域（中西部）。這是因為樣本數小（人口少）導致變異數極大。\nOHS 實務\n\n場景： 中小企業（SME）vs. 大型企業的職傷率比較。\n我們常看到小工廠（5人）連續 3 年「零職災」，老闆就說很安全。或者小工廠發生 1 件事故，職災率馬上飆升到全台最高。\n對於小工廠（樣本少），我們不能只看它自己的數據，必須「借用（Borrowing strength）」整體行業的平均值來進行貝氏修正（Shrinkage）。修正後，極端的低死亡率和高死亡率都會被拉回平均值，這才是真實的風險樣貌。\n\n\n\n\n\n當沒有背景知識時，如何設定「客觀」的先驗分佈（如 Uniform 或 Jeffreys Prior），讓數據主導結果。\nOHS 實務\n\n場景： 面對全新的化學物質或全新製程。\n應用： 當我們完全沒有文獻參考，也不敢亂猜時，我們使用無訊息先驗。\n雖然聽起來很「客觀」，但在數學上可能有問題（Improper prior，無法積分至 1）。在實務上，完全的無知（Ignorance）很少見，通常我們至少知道濃度不可能小於 0 或大於 1,000,000 ppm。\n\n\n\n\n\n不追求完全無訊息，而是設定一個範圍寬鬆但合理的先驗，目的是「正規化（Regularize）」結果，避免荒謬的極端值。\nOHS 實務\n\n場景： 現代暴露評估模型的標準做法。(推薦)\n應用： 例如在 Logistic 回歸分析聽力損失風險時，我們設定係數不應過大。\n「不要假裝你什麼都不知道（無訊息），也不要武斷地說你知道一切（強訊息）。設定一個『合理的物理界線』，剩下的交給數據。」",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#a.統計概念澄清",
    "href": "0104CH2.html#a.統計概念澄清",
    "title": "BDA3_CH2 單參數模型",
    "section": "A.統計概念澄清",
    "text": "A.統計概念澄清\n\n二項式分佈與單參數模型\n\n1. 什麼是二項式分佈 -「從二項式數據估計機率」？2. 為何二項式分佈適用「單參數模型 」？3. 原理為何？ (核心概念：可交換性 Exchangeability)4. OHS 專業: 可以科學合理解釋單參數模型？\n\n\n\n當數據來自於一個大母群體中抽出的 n 次可交換試驗，且每次只有兩種可能的結果（成功/失敗）時，二項式分佈是描述這類數據最自然的數學模型。它不是硬套的公式，而是基於計數邏輯的自然推導。\n二項式模型（Binomial Model）的目標是從一系列的「伯努利試驗（Bernoulli trials）」結果中，估計一個未知的母群體比例（population proportion）。\n數據形式： 數據 y_1, ..., y_n 是一連串的 0 與 1。例如在 OHS 領域，1 代表「超標」，0 代表「合規」。\n目標參數： 我們想知道的是 \\theta（theta），即母群體中超標的比例。\n模型公式：\n二項式採樣模型如下：p(y|\\theta) = \\text{B}(y|n,\\theta) = \\binom{n}{y}\\theta^y(1-\\theta)^{n-y}, 其中 n 是總採樣數，y 是超標的總次數 。\n\n\n\n\n\n唯一未知的純量或參數：在這個模型設定中，我們關注的估計量（Estimand）只有一個維度，那就是 \\theta（發生的機率或比例）。\n固定要素 (n)：總樣本數 n 被視為實驗設計的一部分，是固定的已知數，而不是需要估計的參數。\n條件獨立性：所有的機率討論都是基於 n 已知的情況下，針對單一未知數 \\theta 進行推論。\n當我們問：「這個相似暴露群（SEG）的超標率\\theta是多少？」這就是一個典型的單參數問題。我們不討論變異數、不討論測量誤差（假設已知或忽略），只專注於「超標率（Rate/Proportion）」這一個參數。\n\n\n\n\n\n支撐這個模型能運作的數學與邏輯原理，在於**「可交換性（Exchangeability）」**。\n由於可交換性，數據的所有資訊都可以被濃縮（Summarized）在「總超標次數 y」裡面。二項式分佈正是基於 n 和 y 建立的。這意味著，只要知道 n 次中有 y 次超標，我們就擁有了推斷 \\theta 所需的全部數據資訊，這在科學上是非常高效且合理的。\n定義： 如果我們對數據的順序沒有任何額外資訊（例如我們不知道這是週一還是週五採樣的，或者無法區分樣本之間的差異），我們就判斷這些試驗是「可交換的」。（假設無自相關，前後樣本是獨立的）\n推論： 因為具有可交換性，數據的詳細順序（例如「超標、合規、合規」vs「合規、合規、超標」）並不重要，重要的是「總共出現幾次超標 (y)」。\n轉化為機率： 可交換性讓我們可以將問題轉化為「獨立同分佈（Independent and Identically Distributed, i.i.d.）」的隨機變數，並用參數 \\theta 來代表每次試驗成功的機率。\n\n\n\n\n\n從 1763 年 Thomas Bayes 發表的論文開始，二項式模型就是貝氏推論的起點。透過結合先驗分佈（如 Uniform [0,1]），我們可以利用貝氏定理： p(\\theta|y) \\propto \\theta^y(1-\\theta)^{n-y}\n算出 \\theta 的後驗分佈。這讓我們能科學地量化對參數 \\theta 的不確定性（例如：超標率 \\theta 有 95% 的機率落在 0.05 到 0.15 之間），而不僅僅是給出一個點估計值。\n只要我們的採樣是隨機的（可交換性），不管採樣順序為何，我們只需要關心『採了幾個樣本 (n)』以及『超標了幾次 (y)』。因為樣本數 n 是我們決定的（固定的），剩下的唯一未知數就是『真實的超標率 (\\theta)』，這就是為什麼它叫單參數模型。利用這個模型，我們就能算出該作業環境真實超標風險的機率分佈，而不只是看到表面的超標次數。」",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#b.共軛conjugacy",
    "href": "0104CH2.html#b.共軛conjugacy",
    "title": "BDA3_CH2 單參數模型",
    "section": "B.共軛（Conjugacy）",
    "text": "B.共軛（Conjugacy）\n\n貝氏統計在實務上（特別是早期計算能力不足時）能被廣泛應用的關鍵。\n\n\n1. 什麼是「二項式分佈與 Beta 分佈共軛」？2. 為何選擇 Beta 分佈？3. ＯＳＨ範例\n\n\n\n在貝氏定理中，我們有以下關係：\n\n\\text{後驗分佈 (Posterior)} \\propto \\text{似然函數 (Likelihood)} \\times \\text{先驗分佈 (Prior)}\n\n所謂的「共軛（Conjugate）」，指的是一種「數學上的門當戶對」。\n當我們的數據模型（似然函數）是 二項式分佈 (Binomial) 時，如果我們選擇 Beta 分佈 作為先驗分佈，那麼算出來的 後驗分佈，依然會是 Beta 分佈。\n\n\n「這就像是遺傳學。如果你選擇 Beta 家族當『先驗（父母）』，而你的採樣數據是二項式類型，那麼生出來的『後驗（孩子）』，保證還是 Beta 家族的成員，只是長相（參數）稍微變了。這種特性就叫共軛。」\n\n\n\n\n因為 Beta 分佈具有兩個完美的特性，非常適合處理「機率」或「比率」問題。\n\nA. 數學結構的吻合 (Mathematical Convenience)\n\n二項式似然函數的長相是：\\theta^y (1-\\theta)^{n-y} 。\nBeta 先驗分佈的長相是：\\theta^{\\alpha-1} (1-\\theta)^{\\beta-1} 。\n當兩者相乘時，底數 \\theta 和 (1-\\theta) 是一樣的，我們只需要把指數相加即可。這讓數學運算變得極其簡單，不需要複雜的微積分積分。\n\nB. 物理意義：它定義在 [0, 1] 區間\n\n在 OHS 中，我們關心的「超標率」、「患病率」或「防護具失效機率」，數值一定介於 0% 到 100% 之間。\nBeta 分佈的定義域剛好就是 [0, 1]，天生就是用來描述「機率的機率分佈」。\n此外，Beta 分佈形狀非常有彈性。它可以是平坦的（代表無知）、鐘形的（代表確定）、或是偏向一邊的（代表高風險或低風險），足以涵蓋我們所有的專家經驗或先驗資料。\n它讓貝氏統計變得「可操作」且「直觀」，計算變得像小學加法一樣簡單。\n因為共軛性，我們不需要做積分。更新知識（從先驗變後驗）只需要更新 Beta 的兩個參數 (\\alpha, \\beta)：\n\n先驗 (Prior)： \\text{Beta}(\\alpha, \\beta)\n數據 (Data)： n 個樣本中有 y 個超標，n-y 個合規。\n後驗 (Posterior)： \\text{Beta}(\\alpha + y, \\beta + n - y) 。\n\n假設我們先驗認為製程超標率分佈是 \\text{Beta}(2, 20)（代表我們覺得大概率安全）。\n\n今天採樣 5 個點，發現 1 個超標 (y=1, n=5)。\n新的後驗分佈就是 \\text{Beta}(2+1, 20+4) = \\text{Beta}(3, 24)。就這麼簡單，不用電腦也能算！\n\n參數具有極強的「可解釋性」 (Interpretability)，在 Beta-Binomial 模型中，先驗參數 \\alpha 和 \\beta 可以被解釋為「虛擬的數據 (Pseudo-counts)」。\n\n\\alpha - 1 可以看作是「過去經驗中累積的超標次數」。\n\\beta - 1 可以看作是「過去經驗中累積的合規次數」。\n\\alpha + \\beta - 2 相當於我們過去累積的樣本總數（證據強度）。\n\n連續更新 (Sequential Updating)：今天的後驗分佈，可以直接當成明天的先驗分佈。因為形式永遠是 Beta 分佈，我們可以隨著每天新的採樣數據進來，不斷地用加法更新 \\alpha 和 \\beta，讓風險評估模型越來越準確。\n為什麼我們要用 Beta 分佈來配合二項式採樣？\n\n因為它算得快： 只要會加法就能算出新的風險分佈（後驗），不需要跑複雜的電腦程式。\n因為它聽得懂： Beta 的參數可以直接翻譯成『過去我們看過多少次超標、多少次合格』，這讓『專家經驗』或先驗資訊可以量化並加入計算。\n因為它合邏輯： 它保證算出來的機率永遠在 0 到 1 之間，符合物理現實。\n\n\n\n\n\n在二項式模型中，只要算出了後驗 Beta 分佈的兩個參數 \\alpha_{new}（新的 \\alpha）與 \\beta_{new}（新的 \\beta），您就擁有了關於該參數 \\theta（例如：超標率）的「完整資訊」。不需要回頭去翻原始數據，所有的知識都濃縮在這兩個數字裡了，這正是貝氏統計配合共軛分佈（Conjugate Distributions）最強大的地方。\n情境： 您有一個先驗認為超標率很低 (\\alpha=1, \\beta=19，約 5%)。\n數據： 採樣 10 個點，發現 2 個超標 (y=2, n=10)。\n後驗參數： \\alpha_{new} = 1+2 = 3, \\beta_{new} = 19+8 = 27。\n\n\n\n[1] \"後驗平均超標率: 10.0%\"\n\n\n[1] \"95% 可信區間: [2.2%, 22.8%]\"\n\n\n\n\n\n\n\n\n\n\n留意事項：\n\n最高後驗密度區域 (Highest Posterior Density, HPD)： 這是包含 95% 機率且密度最高的區域。當分佈極度歪斜（例如超標率極低，堆在 0 附近）時，HPD 可能比中央區間更準確，但在單參數模型且樣本數稍多時，兩者差異通常不大 。\n在職業衛生法規遵循判斷上，我們有時更關心「上限（如ＯＥＬ）」。這時可以計算 95% 上限（即 qbeta(0.95, ...)），這樣可以回答：「我們有 95% 的信心，超標率不會超過**多少？」這在保守的風險評估中非常有用。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#c.拉普拉斯預測",
    "href": "0104CH2.html#c.拉普拉斯預測",
    "title": "BDA3_CH2 單參數模型",
    "section": "C.拉普拉斯預測",
    "text": "C.拉普拉斯預測\n\nLaplace’s Law of Succession提供了一種簡單卻強大的方法，來解決傳統統計在小樣本下容易做出「過度武斷」結論的問題。\n\n\n1. 「貝氏的拉普拉斯預測」？2. OHS 應用？3. 觀念4. 廣義形式\n\n\n\n當我們想預測「下一次採樣（\\tilde{y}）」是否會超標時，我們不直接使用傳統的比例 \\frac{y}{n}，而是使用以下公式：\n\n\n核心公式 E(\\theta|y) = \\frac{y+1}{n+2} , 或 P(\\tilde{y}=1 | y) = \\frac{y+1}{n+2}\n\ny：目前觀測到的超標次數（或事件發生次數）。\nn：目前的總樣本數。\n1 與 2：這是貝氏修正項（來自均勻先驗分佈，也就是 \\text{Beta}(1, 1)）。\n\n\\text{Beta}(1, 1) 意味著在還沒開始採樣前，我們先「虛擬地」假設已經有 2 次試驗：一次成功（超標），一次失敗（合規）。\n這代表我們先驗認為「超標率」在 0 到 1 之間是均勻分佈的，沒有偏向任何一邊。\n\n後驗預測參數均值（Posterior Predictive Mean）即為 \\frac{y+1}{n+2} 。\n\n\n\n\n\n\n在職業衛生中，我們最怕的情況是：「採樣 3 次都沒超標，老闆就以為這裡絕對安全。」\n傳統統計 (Maximum Likelihood, MLE)：\n\n若 n=3, y=0 \\rightarrow 超標率 = 0/3 = 0\\%。\n結論： 風險為零。這在小樣本下是極度危險的誤導。\n\n拉普拉斯預測：\n\n若 n=3, y=0 \\rightarrow 下一次超標機率 = \\frac{0+1}{3+2} = \\frac{1}{5} = 20\\%。\n結論： 雖然目前沒看到超標，但我們保留了 20% 的可能性，認為下次可能會超標。\n\n\n\n\n情境 A：小樣本的ＥＡ1\n\n狀況： 某新製程剛運作，您進行了 5 次 空氣採樣，結果 0 次 超標。超標風險真的是 0 嗎？\n拉普拉斯解讀： P(\\text{下次超標}) = \\frac{0+1}{5+2} = \\frac{1}{7} \\approx 14.3\\%\n合理推論：「雖然我們測了 5 次都合格，但因為樣本數太少，統計上我們不能說風險是零。依據貝氏法則保守估計，下一次採樣仍有約 14% 的機率可能超標。因此，我們建議維持目前的防護具等級與控制措施，直到累積更多數據為止。」\n\n\n\n情境 B：小樣本的ＥＡ2（避免過度反應）\n\n狀況： 某工廠發生 2 次 意外洩漏，您剛好去測了 2 次，結果 2 次 都超標。 該工廠是否「百分之百」沒救了？\n拉普拉斯解讀： P(\\text{下次超標}) = \\frac{2+1}{2+2} = \\frac{3}{4} = 75\\%\n傳統算法會說這裡 100% 不合格 (\\frac{2}{2})，這可能太過悲觀。拉普拉斯法則告訴我們，預測下一次超標的機率是 75%。這意味著雖然現況很糟，但並非毫無改善或出現合格樣本的機會（還有 25% 的合規空間），我們需要更多調查，但現在就應該採行些控制措施。」\n\n\n\n\n\n\n平滑化（Smoothing）： 拉普拉斯預測就像把數據「磨圓」了一點。它避免讓機率變成極端的 0 或 1。\n保守原則： 在安全衛生領域，當證據不足（樣本少）時，我們寧可高估風險（從 0% 變成 20%），也不要低估風險，這符合 OHS 的預防原則。\n隨著樣本增加 (n \\to \\infty)：當 n 變得很大時（例如 n=1000, y=100），\\frac{101}{1002} \\approx 10.08\\% 與 \\frac{100}{1000} = 10\\% 幾乎沒有差別。\n這體現了貝氏統計的核心精神——當數據少時，先驗知識（這裡是保守的 50/50 假設）幫助我們穩定預測；當數據多時，就讓數據說話。\n拉普拉斯連鎖律（Laplace’s Law of Succession）」。它解決了傳統頻率學派（\\frac{y}{n}）在預測未來單次試驗時最致命的缺陷：「零機率陷阱」與「過度自信」。\n\n\n\n\n\n又稱為「貝氏後驗平均估計（Bayesian Posterior Mean Estimate）」。\n核心公式： E(\\theta|y) = \\frac{y + \\alpha}{n + \\alpha + \\beta}\n在職業衛生實務中，我們有時並不是一無所知（Uniform），我們可以使用「廣義的拉普拉斯預測」（即一般化的貝氏更新）。\n\n情境： 假設過去經驗告訴我們，這類製程通常被穩定控制，大概測定 20 次才會有 1 次超標。\n設定先驗： 我們可以設 \\text{Beta}(1, 19)。\n\n\\alpha=1 (虛擬超標 1 次)\n\\beta=19 (虛擬合規 19 次)\n先驗平均風險 = 1/(1+19) = 5\\%。\n\n新數據： 現場採樣 5 次，0 次超標 (y=0, n=5)。\n預測公式就變成了：\\frac{y + \\alpha}{n + \\alpha + \\beta} = \\frac{0 + 1}{5 + 1 + 19} = \\frac{1}{25} = 4\\%\n\n「先驗選擇」對「預測結果」的影響，展示如下表：（假設採樣結果皆為：n=5 次採樣，y=0 次超標）\n\n\n\n\n\n\n\n\n\n\n\n預測方法\n先驗假設 (Prior)\n計算公式\n預測下一次超標機率\nOHS 意義\n\n\n傳統統計 (MLE)\n無 (完全看數據)\n\\frac{y}{n}\n\\frac{0}{5} = \\mathbf{0\\%}\n極度危險：宣稱零風險，忽視採樣誤差。\n\n\n拉普拉斯預測\n均勻先驗 Beta(1,1)\n(假設超標/合規機會均等)\n\\frac{y+1}{n+2}\n\\frac{1}{7} \\approx \\mathbf{14.3\\%}\n最保守/防禦性：當我們對現場完全陌生時使用。\n\n\n廣義貝氏預測\n訊息先驗 Beta(1,19)\n(依據過去經驗認為風險低)\n\\frac{y+1}{n+20}\n\\frac{1}{25} = \\mathbf{4.0\\%}\n折衷/合理：結合了「現場好紀錄」與「專家經驗」。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#後驗機率分佈",
    "href": "0104CH2.html#後驗機率分佈",
    "title": "BDA3_CH2 單參數模型",
    "section": "後驗機率分佈",
    "text": "後驗機率分佈\n\n1. 決策指標\n\n理想情況下，我們應該報告整個後驗機率分佈 p(\\theta|y)，因為它包含了關於參數的所有資訊 。但在實務上，我們需要各種「數值摘要（Numerical Summaries）」來溝通。\n管理者往往只想知道兩個問題：1. 最可能的暴露濃度是多少？（點估計），2. 你有多大的把握？（區間估計）」\n\n位置的摘要：點估計 (Summaries of Location)\n\n均值 (Mean)： 後驗期望值 E(\\theta|y) 。\n\n代表「長期平均風險」。在 Beta 分佈範例中，均值為 \\frac{y+\\alpha}{n+\\alpha+\\beta} 。這是做累積暴露評估時最常用的指標。\n\n中位數 (Median)： 50% 的分位數。\n\n當數據有極端值（如突然的一次洩漏）導致分佈歪斜時，中位數比均值更穩健（Robust）。\n\n眾數 (Mode)： 機率密度最高的點，即「最可能的值」。\n\n在 Beta 分佈中，眾數是 \\frac{y}{n}（即 MLE），這代表「當下最可能發生的狀況」。\n\n\n不確定性的摘要：區間估計 （通常報告 95% 區間）\n\n中央後驗區間 (Central Posterior Interval)\n\n定義： 直接取後驗分佈的 2.5% 和 97.5% 分位數，中間的範圍包含了 95% 的機率 。可以說成：『我們有 95% 的信心，真實的暴露風險是落在 X 與 Y 之間。』\n\n最高後驗密度區域 (Highest Posterior Density Region, HPD)\n\n定義： 這是包含 95% 機率的「最短」區間，且區間內所有點的機率密度都高於區間外 。\n與中央區間的差異： 如果分佈是對稱單峰的，HPD 與中央區間是一樣的 。但如果分佈嚴重歪斜，HPD 會更短、更精確。\n特別適用於暴露濃度呈現雙峰分佈時。\n\n\n\n\n善用區間： 永遠不要只給一個數字（點估計），一定要附上貝氏可信區間（Uncertainty），這是專業的表現 。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#d.訊息先驗分佈",
    "href": "0104CH2.html#d.訊息先驗分佈",
    "title": "BDA3_CH2 單參數模型",
    "section": "D.訊息先驗分佈",
    "text": "D.訊息先驗分佈\n\n當我們對參數 \\theta 不是一無所知，而是有一些背景知識時，該如何構建先驗分佈，以及這會如何影響最終的推論。\n\n\n1. 先驗分佈的兩種解釋 (Two Interpretations)2. 二項式模型的共軛先驗 (Conjugate Priors for Binomial)3. 後驗均值：數據與信念的加權平均4. 非共軛先驗 (Nonconjugate priors)5. 常態近似 (Normal Approximation)小結\n\n\nGelman 首先探討了我們為什麼可以設定先驗分佈，提出了兩種哲學觀點 1：\n\n母群體解釋 (Population Interpretation)：\n先驗分佈代表一個真實存在的「母群體」。\n\nOHS 例子： 您要評估某個新工廠的職災率。您的先驗分佈可以來自「全台灣同類型工廠過去十年的職災率分佈」。這是有實體數據支持的。\n\n知識狀態解釋 (State of Knowledge Interpretation)：\n先驗分佈代表我們主觀的「不確定性」與「信念」。\n\nOHS 例子： 針對一個全新的化學製程，沒有歷史數據。但依據您的毒理學知識與工程控制原理，您「判斷」其洩漏風險應該很低。這種「專家判斷」就是先驗。\n\n\n\n\n\n\n為了讓計算方便（有封閉解），選擇與似然函數（二項式）形狀相似的先驗(即 Beta 分佈)共軛 。\n似然函數 (Likelihood): \\theta^y (1-\\theta)^{n-y}\n先驗分佈 (Prior): \\text{Beta}(\\alpha, \\beta) \\propto \\theta^{\\alpha-1} (1-\\theta)^{\\beta-1}\n後驗分佈 (Posterior): \\text{Beta}(\\alpha+y, \\beta+n-y)\n\n\\alpha - 1：代表我們先驗認為已經發生過的「成功（超標）次數」。\n\\beta - 1：代表我們先驗認為已經發生過的「失敗（合規）次數」。\n\n共軛的便利性： 我們只要把「已有資訊的次數（先驗）」加上「實際看到的次數（數據）」，就是「新的認知（後驗）」，這讓後驗分佈具有高度的可解釋性。\n\n\n\n\n\n後驗均值公式：E(\\theta|y) = \\frac{\\alpha+y}{\\alpha+\\beta+n}\n這個公式可以改寫為加權平均的形式，權重取決於「先驗的強度」與「數據的樣本數」。\n如果 \\alpha+\\beta（先驗的樣本數）很大，代表專家非常固執（或經驗非常豐富），那麼新的數據 n 必須很大才能改變專家的看法。\n隨著 n \\to \\infty，先驗的影響力會歸零，結果完全由數據決定。\n可以使用不同強度的先驗來進行敏感度分析 (Sensitivity Analysis)\n\n\n\n\n\n如果我們的知識形狀很奇怪，Beta 分佈描述不了怎麼辦？（例如：我們認為超標率要嘛是 0，要嘛大於 10%，不可能是中間值）。\n方法： 使用網格法 (Grid approach) :\n步驟：\n\n把 \\theta 切成很多小格子（如 0.00, 0.01, …, 1.00）。\n算出每一格的先驗機率 p(\\theta)。\n算出每一格的似然機率 p(y|\\theta)。\n相乘並標準化，得到後驗分佈。\n\n結論： 即使沒有漂亮的數學公式（共軛），電腦也能幫我們暴力算出結果，這在現代非常容易實現。\n\n\n\n\n\n當樣本數夠大時，後驗分佈會趨近於常態分佈。(中央極限定理)\n在OHS 實務上， 為了讓近似更準確，建議對 \\theta 進行 Logit 轉換 (\\log(\\frac{\\theta}{1-\\theta}))，將範圍從 [0,1] 拉展到 (-\\infty, \\infty)，這樣更符合常態分佈的鐘形曲線特性。\n\n\n\n\n\n\n不要浪費你的專業： 你可以透過設定 \\alpha 和 \\beta（共軛先驗），把『這製程通常很安全』這種模糊的概念，轉化為數學上的『虛擬合規次數』，加入模型運算。\n數據越多，專家越不重要： 當你採樣了幾百個點之後，先驗設定是多少已經不重要了，數據會說話。\n敏感度分析： 如果你不確定先驗該設多少，就試試看不同的設定（如书中的 Table 2.1）。如果結果都差不多，你的結論就是穩健的。」",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#e.已知變異數的常態分佈",
    "href": "0104CH2.html#e.已知變異數的常態分佈",
    "title": "BDA3_CH2 單參數模型",
    "section": "E.已知變異數的常態分佈",
    "text": "E.已知變異數的常態分佈\n\nNormal distribution with known variance（已知變異數的常態分佈）適用在職業衛生（OHS）與儀器分析領域是非常基礎且實用的模型，特別是當我們使用的測量設備具有已知的精確度（Known Precision）時。\n我們要做的是：『已知儀器誤差下的平均值推估』。\n\n\n1. 適用於「單參數模型」？2. 精確度的加法3. OHS情境與應用4. 後驗預測分佈 (Posterior Predictive Distribution)小結\n\n\n\n在標準的常態分佈 N(\\theta, \\sigma^2) 中，通常有兩個未知參數：平均值 \\theta 和變異數 \\sigma^2。\n如果做出了一個關鍵假設：變異數 \\sigma^2 是已知的（Known）。如果 \\sigma^2 被視為常數，模型中剩下唯一需要估計的未知數就只有 平均值 \\theta。因此，這依然符合「單參數模型（Single-parameter models）」的定義。\n例如使用直讀式儀器（PID, FID）或噪音計，儀器原廠規格書通常會告知「測量誤差（儀器精確度）」。我們可以將這個誤差視為已知的 \\sigma^2，專心去推估環境中真實的「平均暴露濃度 (\\theta)」即可。\n\n\n\n\n\n在貝氏統計的常態模型中，不用變異數（Variance, \\sigma^2），常用它的倒數—精確度（Precision, 1/\\sigma^2 ＝\\tau_0^2)）。\n共軛：當我們有一個常態先驗 N(\\mu_0, \\tau_0^2) 和一組常態數據 y（已知變異數 \\sigma^2）時，算出來的後驗分佈依然是常態分佈 N(\\mu_n, \\tau_n^2) 。\n後驗參數的更新法則：\n\n後驗精確度 = 先驗精確度 + 數據精確度. \\frac{1}{\\tau_n^2} = \\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}\n\n信心（精確度）是累加的。每多採一個樣，你的信心就增加一份（1/\\sigma^2）。\n\n後驗平均值 = 加權平均 (Weighted Average)\n\\mu_n = \\frac{\\frac{1}{\\tau_0^2}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac{1}{\\tau_0^2} + \\frac{n}{\\sigma^2}}\n\n新的估計值 (\\mu_n) 是「舊信念 (\\mu_0)」與「新數據 (\\bar{y})」的加權平均。權重就是各自的精確度。誰的變異數小（精確度高），誰說話就大聲，結果就往誰那邊靠。\n\n\n\n\n\n\n\n情境：評估勞工的真實噪音暴露量\n已知條件 (\\sigma^2)： 我們使用的噪音計經過校正，原廠手冊說測量標準差是 \\sigma = 2 dB（即變異數 \\sigma^2 = 4）。這是已知的。\n未知參數 (\\theta)： 勞工真實的長期平均暴露分貝數。\n先驗 (\\mu_0, \\tau_0^2)： 根據過去對該製程的了解，我們認為平均暴露大概在 85 dB，但不太確定，所以給一個較寬的變異數 \\sigma^2 = 16（即標準差 4 dB）。\n\n先驗分佈： N(85, 16)\n\n數據 (n, \\bar{y})： 我們測量了 n=4 次，平均值是 \\bar{y} = 90 dB。\n貝氏運算：\n\n\n先驗精確度： 1/16 = 0.0625\n數據精確度： 4 \\times (1/4) = 1.0 （因為測了 4 次，每次精確度 0.25）\n誰說話大聲？ 數據精確度 (1.0) 遠大於先驗精確度 (0.0625)。\n後驗結果： 估計值會被強力拉向數據的 90 dB，稍微被先驗的 85 dB 拉回去一點點。\n\n計算： \\mu_n = \\frac{0.0625 \\times 85 + 1.0 \\times 90}{0.0625 + 1.0} \\approx 89.7 \\text{ dB}\n\n\n\n結論：雖然先驗認為是 85 dB，但因為儀器很準（\\sigma 小）且測了 4 次，證據確鑿，所以我們修正看法，認為真實暴露約為 89.7 dB 6。\n\n\n\n\n\n如果我們要預測「下一次測量 (\\tilde{y}」會是多少？\n結果也是常態分佈，但變異數包含兩部分：\n\n\\text{預測變異數} = \\sigma^2 + \\tau_1^2\n\n\\sigma^2 (Aleatoric uncertainty)： 這是物理世界的隨機性（儀器本身的誤差），你測再多次也消除不了。\n\\tau_1^2 (Epistemic uncertainty)： 這是我們對 \\theta 認知的不確定性。隨著樣本 n 增加，這部分會趨近於 0。\n\n\n\n\n\n為什麼叫單參數？因為我們假設儀器的誤差（\\sigma）是已知的常數，只專心猜測環境的真實濃度（\\theta）。\n如果你的儀器很爛（\\sigma 大），或是採樣數很少（n 小），貝氏公式會自動叫你多聽聽專家經驗（Prior）。\n如果你的儀器很準，或者你測了很多次，貝氏公式就會叫你相信數據，把專家經驗放一邊。\n這就是完全自動化的權重分配系統。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#f.廣泛的單參數暴露風險模式",
    "href": "0104CH2.html#f.廣泛的單參數暴露風險模式",
    "title": "BDA3_CH2 單參數模型",
    "section": "F.廣泛的單參數暴露風險模式",
    "text": "F.廣泛的單參數暴露風險模式\n\n在職業衛生（OHS）的應用不被侷限在「二項式（超標/合規）」與「常態（平均濃度）」這兩個框架裡。\nOther standard single-parameter models：在現實工廠中，我們還有兩類極其重要的數據：\n\n計數數據（Counts）：今年發生了幾次洩漏？幾個人得了職業病？（這是整數，不是連續的濃度）。\n時間數據（Waiting Times）：這個濾毒罐還能撐多久？下次故障或發生火災可能是多久以後？（這是時間，且必須大於 0）。\n\n以下這介紹 Poisson（卜瓦松）分佈 與 Exponential（指數）分佈 ，它們讓我們能處理更廣泛的單參數風險問題。\n\n\n1. 卜瓦松模型 (Poisson Model)：處理「計數」與「率」2. 指數模型 (Exponential Model)3. 已知平均值的常態分佈4. 負二項式分佈給學員的單參數模型整理一覽表單參數模型與共軛分佈總結表 (OHS 應用版)貝氏統計的共軛「簡潔美」：\n\n\n\n這是 OHS 流行病學與事故分析的核心模型 。適用場景：\n\n當我們計算一定時間或空間內的稀有事件次數時。\n例： 全廠每年的職傷件數、某製程每年的氣體外洩次數、健檢中發現的第三級人數。\n\n模型架構：\n\n先驗： y_i \\sim \\text{Poisson}(x_i \\theta) 。\n\ny_i：事故件數。\nx_i：暴露量（Exposure），在 OHS 中通常指「總工時（Man-hours）」或「受雇人數」。\n\\theta：真正的風險率（例如：每百萬工時的事故率）。\n\n似然函數 (Likelihood)： p(y|\\theta) \\propto \\theta^{y} e^{-n\\theta} 。這裡 \\theta 代表發生率（Rate）。\n共軛先驗 (Conjugate Prior)： Gamma 分佈 (\\alpha, \\beta) 。\n\n\\alpha 代表過去觀察到的總事故數，\\beta 代表過去觀察的總時間（或人時）。\n\n後驗分佈 (Posterior)： 依然是 Gamma 分佈。\n\\theta|y \\sim \\text{Gamma}(\\alpha + \\sum y, \\beta + n)\n\n新的 \\alpha = 舊事故 + 新事故；新的 \\beta = 舊時間 + 新時間。\n\n\n實例： 「氣喘死亡率」。\n\n假設某城市 20 萬人中有 3 人死於氣喘。若我們有過去的世界平均數據（先驗），就可以結合這單一年度的數據，算出該城市真實的潛在死亡率。這完全可以直接套用在「工廠職業病發生率」的估算上。\n\n\n\n\n\n\n處理「壽命」與「時間間隔」，這是可靠度工程（Reliability Engineering）與防護具管理的基礎。\n適用場景：當我們關注「要等多久事件才會發生」（Waiting times）或「存活時間」時。\n\nOHS 例子： 呼吸防護具濾罐的破出時間（Breakthrough time）、安全閥兩次故障的間隔時間、感測器失效前的運作時數。\n\n模型架構：\n\n似然函數 (Likelihood)： p(y|\\theta) = \\theta \\exp(-y\\theta) 。這裡 \\theta 是「速率（Rate）」，即壽命的倒數。\n特性： 無記憶性（Memoryless）。這意味著如果一個零件現在沒壞，它未來的故障機率跟它已經用了多久無關（這適用於隨機失效，雖不完全適用於老化磨損，但常用作基礎模型）。\n共軛先驗 (Conjugate Prior)： Gamma 分佈 (\\alpha, \\beta) 。\n後驗分佈 (Posterior)： Gamma 分佈。\n\\theta|y \\sim \\text{Gamma}(\\alpha + n, \\beta + \\sum y)\n\n這裡的 \\beta 更新是加上「總等待時間（\\sum y）」。\n\n\nOHS 應用：\n\n「如果你想估算工廠泵浦平均多久壞一次（MTTF），但你只觀察到 5 次故障數據。利用 Exponential 模型加上 Gamma 先驗（參考原廠數據），你可以算出比單純平均值更準確的故障率，從而制定更好的維修保養計畫。」\n\n\n\n\n\n\n(Normal with known mean, unknown variance)，這是一個比較特殊的單參數模型，通常用於「儀器校正」或「品質控制」。\n\n\n\n適用場景：我們已知中心點（平均值 \\theta），但想知道「變異程度（\\sigma^2）」有多大。\n\nOHS 例子： 我們買了一個標準氣體（已知濃度 \\theta = 100 ppm），用新的檢測儀器測了 10 次。我們想估算這台新儀器的「精確度/穩定性」（即估計 \\sigma^2）。\n\n模型架構：\n\n共軛先驗： 反卡方分佈 (Inverse-\\chi^2) 或 反伽瑪分佈 (Inverse-Gamma) 。\n後驗分佈： 依然是 反卡方分佈 。\n\n新的估計變異數，會是「先驗變異數」與「數據變異數」的加權平均。\n\n\n\n\n\n\n\nNegative Binomial，適合於卜瓦松的預測分佈\n概念： 如果數據來自 Poisson 分佈，而其參數 \\theta 本身又有不確定性（Gamma 分佈），那麼這些數據的邊際分佈（Marginal Distribution）就是負二項式分佈。\nOHS 意義：Poisson 假設變異數等於均值（Mean = Variance）。但在真實的職災數據中，往往有「過度離散（Overdispersion）」現象（即變異數 &gt; 均值，例如某年突然發生化工廠大爆炸或局限空間職災）。這時，使用 Negative Binomial 作為預測模型會比 Poisson 更穩健（Robust），因為它允許數據有更大的波動範圍。\n\n\n\n\n在教學時，您可以用這張表總結知道何時該用什麼工具：\n\n\n\n\n\n\n\n\n\n數據類型\nOHS 應用問題 (範例)\n推薦模型 (Likelihood)\n搭配的先驗 (Prior)\n\n\n二項 (0/1)\n超標了嗎？合規嗎？\nBinomial (二項式)\nBeta\n\n\n連續數值 (濃度)\n平均暴露濃度是多少？\nNormal (常態)\n(已知變異數)\nNormal\n\n\n計數 (整數)\n今年發生幾件職災？幾次外洩？\nPoisson (卜瓦松)\nGamma\n\n\n時間 (大於0)\n設備多久會失效？濾罐能撐多久？\nExponential (指數)\nGamma\n\n\n連續數值 (誤差)\n這台儀器穩不穩定 (變異數)？\nNormal\n(已知平均值)\nInverse-Gamma\n(反伽瑪)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n你的數據類型\nOHS 應用問題 (範例)\n推薦模型 (Likelihood)\n搭配的先驗 (Prior)\n算出來的後驗 (Posterior)\n後驗更新\n\n\n二元 (0/1)\n超標了嗎？合規嗎？\nBinomial\n(二項式)\nBeta\n(貝塔)\nBeta\n(貝塔)\n次數相加：\n新\\alpha = 舊\\alpha + 超標數\n新\\beta = 舊\\beta + 合格數\n\n\n連續數值\n(濃度)\n平均暴露濃度是多少？\nNormal\n(常態)\n(已知變異數)\nNormal\n(常態)\nNormal\n(常態)\n加權平均：\n新平均值是「舊平均」與「數據平均」的加權折衷\n\n\n計數\n(整數)\n今年發生幾件職災？\n幾次外洩？\nPoisson\n(卜瓦松)\nGamma\n(伽瑪)\nGamma\n(伽瑪)\n累加事故：\n新\\alpha = 舊事故數 + 新事故數\n新\\beta = 舊觀察時間 + 新時間\n\n\n時間\n(大於0)\n設備多久會失效？\n濾罐能撐多久？\nExponential\n(指數)\nGamma\n(伽瑪)\nGamma\n(伽瑪)\n累加壽命：\n新\\alpha = 舊觀察數 + 新觀察數\n新\\beta = 舊總時間 + 新總時間\n\n\n連續數值\n(誤差)\n這台儀器穩不穩定？\n(變異數)\nNormal\n(常態)\n(已知平均值)\nInverse-\\chi^2\n(反卡方)\n或 Inv-Gamma\nInverse-\\chi^2\n(反卡方)\n或 Inv-Gamma\n自由度累加：\n新自由度 = 舊自由度 + 樣本數\n新變異 = 加權平均\n\n\n\n\n\n\n『先驗』和『後驗』分佈一致。\n\n共軛性：這意味著我們不需要做複雜的微積分。如果你的先驗是 Beta 分佈（例如你假設超標率 5%），只要加上新的數據，你的後驗保證還是 Beta 分佈，只是形狀變了（例如變成超標率 8%）。這讓我們可以不斷地隨著新數據更新風險模型，而不會讓模型變得越來越複雜。」\n\n「更新就是做加法」\n\n想算新的超標率分佈？把『看到的超標次數』加到先驗參數上。\n想算新的職災率分佈？把『看到的職災件數』加到先驗參數上。\n\n所以，不要被『貝氏機率』這個名詞嚇到，它骨子裡就是一個非常直觀的累加器，幫你把過去的經驗（先驗）和現在的數據（Likelihood）加在一起而已。」",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0104CH2.html#g.貝氏推論各縣市營造業職災死亡率評估",
    "href": "0104CH2.html#g.貝氏推論各縣市營造業職災死亡率評估",
    "title": "BDA3_CH2 單參數模型",
    "section": "G.貝氏推論：各縣市營造業職災死亡率評估",
    "text": "G.貝氏推論：各縣市營造業職災死亡率評估\n\n\n1. 問題背景：地圖上的假象 (The Problem)\n\n分析台灣職災最高\\最低職災率都集中在人口稀少的縣市。\n連江縣 (馬祖) 的困境： 勞工人數極少（假設約 3,000 人）。\n\n如果今年 0 人 死亡，死亡率是 0（全台最低）。\n如果今年不幸 1 人 死亡，死亡率是 1/3000 = 33.3 (每十萬人)。\n\n新北市的穩定： 勞工人數極多（假設約 200 萬人）。\n\n平均每年約 60 人死亡，死亡率約 3.0 (每十萬人)。\n\n傳統統計的誤導：\n\n如果您只看「原始死亡率 (\\frac{y}{n})」，您會發現全台「最危險」和「最安全」的縣市，永遠都是離島或人口少的縣市（如澎湖、金門、連江）。但這不是因為那裡真的特別危險或安全，純粹是因為樣本數 (n) 太小，變異數太大。\n\n\n\n\n\n2. 建立貝氏模型 (The Model)\n\n我們使用貝氏方法來修正這個問題。\n假設模型 (Likelihood)：\n\n假設第 j 個縣市的死亡人數 y_j 服從卜瓦松分佈：y_j \\sim \\text{Poisson}(n_j \\theta_j)\n其中 n_j 是該縣市勞工人數，\\theta_j 是我們想知道的「真實潛在死亡率」。\n\n建立先驗 (Prior)：\n\n我們需要一個「全國平均標準」作為基準。利用 Gamma 分佈（卜瓦松的共軛先驗）。\n假設根據過去十年全台數據，營造業平均死亡率約為 每十萬人 4 人 (\\theta \\approx 4 \\times 10^{-5})。\n我們設定先驗分佈為 \\text{Gamma}(\\alpha=20, \\beta=500,000)（這裡的數字是為了湊出平均值 20/500,000 = 4 \\times 10^{-5}，且 \\alpha=20 代表我們給予這個先驗約等於 20 個死亡案例的權重，相當穩健）。\n\n\n\n\n\n3. 貝氏推論結果\n\n數據修正 (The Posterior Results)：後驗分佈為：\n\n\\theta_j | y_j \\sim \\text{Gamma}(\\alpha + y_j, \\beta + n_j)\n\n後驗平均值（修正後的死亡率）為：\n\nE(\\theta_j | y_j) = \\frac{20 + y_j}{500,000 + n_j}\n\n\n\n\n案例 A：人口少的「離島縣」 (Small Population)\n\n情境： 勞工 n_j = 5,000 人。\n狀況 1 (運氣好)： 今年 0 人 死亡 (y_j=0)。\n\n原始率： 0 (看似超安全)。\n貝氏修正： \\frac{20 + 0}{500,000 + 5,000} \\approx \\frac{20}{505,000} \\approx \\textbf{3.96} \\text{ (每十萬人)}。\n解讀： 雖然沒死人，但模型知道你只是人少運氣好，真實風險被拉回接近全國平均 (4.0)。\n\n狀況 2 (運氣差)： 今年 1 人 死亡 (y_j=1)。\n\n原始率： 1/5,000 = \\textbf{20.0} (每十萬人)。驚人的高！是全國平均的 5 倍！\n貝氏修正： \\frac{20 + 1}{500,000 + 5,000} \\approx \\frac{21}{505,000} \\approx \\textbf{4.16} \\text{ (每十萬人)}。\n解讀： 模型知道這 1 人死亡在小樣本中可能是偶然，因此將極端值 20.0 強力「收縮 (Shrinkage)」回 4.16 7。縣市管理者不會因為這單一事件被冤枉成「績效極差」。\n\n\n\n案例 B：人口多的「直轄市」 (Large Population)\n\n情境： 勞工 n_j = 1,000,000 人 (100萬人)。\n狀況： 今年 40 人 死亡 (y_j=40)。\n\n原始率： 40/1,000,000 = \\textbf{4.0} (每十萬人)。\n貝氏修正： \\frac{20 + 40}{500,000 + 1,000,000} = \\frac{60}{1,500,000} = \\textbf{4.0} \\text{ (每十萬人)}。\n解讀： 對於大縣市，數據量 (n_j) 夠大，足以壓倒先驗 (\\beta)。貝氏估計值幾乎等於原始數據 。\n\n\n\n\n\n\n4. 小結\n\n「當我們在比較各廠區或各縣市的職災率時，千萬不能只看『發生率』的數字大小，尤其是那些人數很少的小廠。\n透過貝氏推論（Poisson-Gamma 模型），我們可以借用全國的平均經驗來修正這些極端值，給出一個公允、抗雜訊的真實風險評估。這才是科學的職安衛管理。」",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "2.單參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#介紹",
    "href": "0109CH3.html#介紹",
    "title": "0109CH3 多參數模型",
    "section": "介紹",
    "text": "介紹\n\n幾乎所有統計學中的實際問題都涉及不止一個未知或無法觀測的量。\n\n當拿到一組只有 3 個採樣點的數據時，你既不知道真實的平均暴露濃度（GM），也不知道真實的變異程度（GSD）。這兩個未知數彼此牽制、互相影響。如果你只盯著其中一個看（例如只看平均值），而忽略了另一個（變異程度）的不確定性，你對風險的評估就會失準，甚至可能做出錯誤的決策，導致勞工受害。\n\n在職業衛生EA中，這「不止一個未知量」通常指的就是 幾何平均數（GM） 和 幾何標準差（GSD）。\n\n這兩個參數共同決定了對數常態分佈（Lognormal Distribution）的形狀，也就是勞工暴露的分佈樣貌。\n傳統統計方法（如 t 檢定或最大似然估計）在樣本數很少時（OSH 的常態），處理這兩個未知參數往往顯得左支右絀，容易低估不確定性。\n而貝氏方法提供了一個統一的框架，讓我們能夠同時處理這些未知數。\n\n在這種情況下，貝氏分析的最終目標是獲得特定感興趣參數的「邊際後驗分佈」（marginal posterior distribution）。\n\n想像經理問你：「勞工暴露超過容許濃度（OEL）的機率是多少？」這就是「感興趣的參數」（或由參數推導出的量）。經理並不關心暴露數據的變異係數是多少，也不關心標準差的精確數值。他只關心那個核心的風險指標。\n為了回答經理的問題，我們必須把那個他不關心的、但又影響計算結果的參數（例如標準差）給「處理」掉。這個「處理」的過程，在數學上就叫做「邊際化」（Marginalization）。\n\n實現這一目標的路徑：我們首先需要所有未知數的「聯合後驗分佈」（joint posterior distribution），然後我們對那些非當前感興趣的未知數進行積分（integrate），從而獲得所需的邊際分佈。\n\n這就是貝氏分析的標準作業程序（SOP）：\n\n建立聯合模型：把 GM 和 GSD 綁在一起看，形成一座機率的「山峰」（聯合後驗分佈）。\n積分（Integration）：這是一個數學動作，相當於從側面看這座山，把所有可能的 GSD 值都加總起來，只留下我們關心的 GM 分佈。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#a-對滋擾參數進行平均",
    "href": "0109CH3.html#a-對滋擾參數進行平均",
    "title": "0109CH3 多參數模型",
    "section": "3.1A 對「滋擾參數」進行平均",
    "text": "3.1A 對「滋擾參數」進行平均\n\n現代貝氏計算（包括 MCMC、Gibbs Sampling）的邏輯基石。\n\n\n3.1.1 什麼是「滋擾參數」？3.1.2 數學架構的建立3.1.3 核心邏輯：條件機率的混合3.1.4 計算策略：模擬積分\n\n\n\n在許多問題中，我們需要建立一個真實的模型，因此必須包含某些參數，但我們並不想對這些參數進行推論。這類參數通常被稱為「滋擾參數」（nuisance parameters）。最經典的例子就是測量問題中的隨機誤差尺度（scale of random errors），也就是變異數（variance）或標準差。\n試想你在評估暴露平均值時，變異數（標準差）會影響你的評估結果。你的目標是準確估計平均暴露，但是，如果你忽略變異數，你就可能會有估計誤差。所以，標準差對你來說是一個「滋擾」（Nuisance）。你必須測量它、考慮它，把它納入計算。\n在統計上，我們透過「對滋擾參數進行平均」來消除它的影響，同時保留它帶來的不確定性。\n\n\n\n\n參數向量 \\theta 可以分為兩部分：\\theta = (\\theta_1, \\theta_2)。\n\n\\theta_1：我們感興趣的參數（例如：平均暴露濃度 \\mu）。\n\\theta_2：滋擾參數（例如：變異數 \\sigma^2）。\n\n我們的目標是求出 p(\\theta_1 | y)，即在給定數據 y 的情況下，我們感興趣參數的後驗分佈。\n\n公式解析：積分公式： p(\\theta_1 | y) = \\int p(\\theta_1, \\theta_2 | y) d\\theta_2\n\n「這個公式的意思是，我們考慮了 \\theta_2（變異數）所有可能的值。對於每一個可能的變異數值，我們都計算一次 \\theta_1（平均值）的可能性，然後把這些結果全部加總起來（加權平均）。這樣一來，我們最終得到的平均值估計，就已經『包含』了變異數可能忽大忽小的風險。」\n\n\n\n\n接著將聯合後驗分佈 p(\\theta_1, \\theta_2 | y) 分解（這是理解貝氏邏輯的關鍵一步）\n\np(\\theta_1, \\theta_2 | y) = p(\\theta_1 | \\theta_2, y) p(\\theta_2 | y)， 將其代入積分公式，\np(\\theta_1 | y) = \\int p(\\theta_1 | \\theta_2, y) p(\\theta_2 | y) d\\theta_2\n\n它告訴我們，邊際後驗分佈 p(\\theta_1 | y) 其實是條件後驗分佈 p(\\theta_1 | \\theta_2, y) 的混合（Mixture）。\n\n\n\n\n\n\n\n\n\n數學項\n統計意義\n解釋\n\n\np(\\theta_1|y)\n\n邊際後驗分佈\n\n\n\\int... d\\theta_2\n對滋擾參數積分\n我們不只看一種情況，而是全面考量所有可能的變異程度。\n\n\np(\\theta_1|\\theta_2, y)\n\n條件後驗分佈\n\n\np(\\theta_2|y)\n\n滋擾參數的邊際後驗\n\n\n\n\n\n[OHS應用]\n\n想像我們評估一個工廠的風險，數據很少，我們不確定這個工廠的製程是否穩定（因為變異數未知）。貝氏思考如下：\n\n情境 A：如果製程很穩定（變異數小），那平均暴露可能是 10 ppm。數據顯示這種情況的可能性是 20%。\n情境 B：如果製程很不穩定（變異數大），那為了符合現有的數據，平均暴露可能其實只有 5 ppm（因為大變異數會讓偶爾測到的高值變得不那麼奇怪）。數據顯示這種情況的可能性是 50%。\n情境 C…\n\n貝氏公式 (3.1) 就是在做這件事：它把情境 A、B、C… 的結果，依照它們發生的可能性（加權），全部混合起來。最終給出的答案，不是基於某個單一的猜測，而是綜合了所有可能性的加權平均。這就是為什麼貝氏方法在小樣本下比較『周延』，因為它沒有忽略那些極端情況的可能性。」\n\n\n\n\n\n\n我們很少真的去手算這個積分，相反地，使用一種 計算策略，這也是現代軟體（如 JAGS, Stan, Expostats）的運作原理。\n策略步驟：\n\n\n第一步：從滋擾參數的邊際後驗分佈 p(\\theta_2 | y) 中抽取一個樣本。\n\n電腦做的事：根據數據，隨機選一個「可能」的 GSD 值（例如 GSD = 2.1）。\n\n第二步：利用剛剛抽到的 \\theta_2，從條件後驗分佈 p(\\theta_1 | \\theta_2, y) 中抽取一個 \\theta_1。\n\n電腦做的事：假設 GSD = 2.1 是真的，再根據數據推算 GM 可能是多少（例如 GM = 0.5 ppm）。\n\n重複：重複上述步驟成千上萬次。\n\n\n結果：如果把這成千上萬個抽出來的 \\theta_1（GM）畫成直方圖，這個直方圖就是我們夢寐以求的 邊際後驗分佈 p(\\theta_1 | y)。\n透過模擬，我們繞過了複雜的微積分，直接用電腦的算力完成了「對滋擾參數平均」的任務。這就是為什麼在 Expostats 中按下 “Calculate” 後需要等幾秒鐘，因為電腦正在後台進行這場成千上萬次的「情境演練」。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#b-職業衛生中的滋擾參數從-gsd-到測量誤差",
    "href": "0109CH3.html#b-職業衛生中的滋擾參數從-gsd-到測量誤差",
    "title": "0109CH3 多參數模型",
    "section": "3.1B 職業衛生中的滋擾參數：從 GSD 到測量誤差",
    "text": "3.1B 職業衛生中的滋擾參數：從 GSD 到測量誤差\n\n在 OSH 領域，最惡名昭彰的滋擾參數就是 幾何標準差（GSD）。\n\n\n4.1 對數常態分佈中的 \\mu 與 \\sigma4.2 傳統方法的失敗：Plug-in 估計4.3 貝氏方法的優越性4.4 其他滋擾參數：測量誤差\n\n\n\n職業暴露數據通常服從對數常態分佈。若 X 為暴露濃度，則 \\ln(X) \\sim N(\\mu, \\sigma^2)。\n\n\\mu：對數幾何平均值（Log GM）。\n\\sigma：對數幾何標準差（Log GSD）。\n\n通常，我們關心的 \\theta_1 是 第 95 百分位數（95th Percentile, X_{95}） 或 超過容許濃度的機率（Exceedance Fraction）。\n\nX_{95} = \\exp(\\mu + 1.645\\sigma)\n\n這裡的參數 (\\theta_1) 實際上是 \\mu 和 \\sigma 的函數，但在貝氏分析的過程中，我們通常會將 \\sigma 視為滋擾參數來處理 \\mu 的不確定性，或者更準確地說，我們在計算 X_{95} 的後驗分佈時，是同時考慮了 (\\mu, \\sigma) 的聯合分佈。\n\n\n\n\n在傳統做法中（例如使用 AIHA 的舊版試算表或手算），衛生師通常會先計算樣本的 GM 和 GSD，然後直接代入公式：\n\n\\text{點估計 } X_{95} = \\text{Sample GM} \\times (\\text{Sample GSD})^{1.645}\n\n這相當於假設 樣本 GSD = 真實 GSD。也就是說，它把 \\theta_2 當作了一個已知的常數，完全忽略了 \\theta_2 的不確定性。\n\n當樣本數 n&lt;=6 時，樣本 GSD 的變動非常大（可能從 1.5 到 3.5 都有可能）。\n如果你運氣好，採樣到的 GSD 偏小，你算出來的 X_{95} 就會嚴重低估風險，導致你誤判環境是安全的，勞工可能因此受害。\n這就是未進行「滋擾參數平均」的後果。\n\n\n\n\n\n貝氏分析不假設 GSD 是某個定值。它會考慮：「雖然樣本 GSD 是 1.8，但真實 GSD 有可能是 2.5（機率 10%）。」\n在計算 X_{95} 的分佈時，那 10% 的「高 GSD 情境」會被納入考量，拉高 X_{95} 的上界。\n這導致貝氏信用區間（Credible Interval）通常比傳統信賴區間更寬、更偏向保守（在小樣本下），這正符合職業衛生的 預警原則（Precautionary Principle）。\n\n\n\n\n滋擾參數不僅限於 GSD。在 brms 軟體包的介紹中，提到了 測量誤差（Measurement Error） 的處理。\n在 OSH 中，採樣泵和實驗室分析都有誤差（例如 CV = 5%）。\n\n傳統上：我們忽略它，或者假設它包含在環境變異中。\n\n貝氏模型應用：我們可以把「真實濃度」視為 \\theta_1，把「儀器誤差」視為 \\theta_2。\n\n透過對儀器誤差進行平均（積分），我們可以還原出更接近真實的暴露分佈。這在處理接近偵測極限（LOD）的數據時特別重要。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#c-工具expostats-與-aiha-bda",
    "href": "0109CH3.html#c-工具expostats-與-aiha-bda",
    "title": "0109CH3 多參數模型",
    "section": "3.1C 工具：Expostats 與 AIHA BDA",
    "text": "3.1C 工具：Expostats 與 AIHA BDA\n\n5.1 Expostats：貝氏工具箱5.2 AIHA 貝氏決策分析（BDA）\n\n\n\n由 Lavoué 等人開發的 Expostats 是目前國際上最先進的 OSH 貝氏分析工具。\n\n核心機制：Expostats 使用 JAGS（Just Another Gibbs Sampler）作為運算引擎。\n\n運行方式：\n\n使用者輸入數據（包括未檢出數據 &lt;LOQ）。\nJAGS 在後台定義了 \\mu 和 \\sigma 的先驗分佈（Priors）。\nJAGS 進行 MCMC 模擬：\n\n抽取 \\sigma（滋擾參數）。\n抽取 \\mu（給定 \\sigma）。\n計算當下的 X_{95}。\n\n積分結果：Expostats 最後呈現的「過度暴露風險圖」（Overexposure Risk）和 X_{95} 的信用區間，就是對 \\sigma 積分後的 邊際後驗分佈。\n\n不確定性管理：Expostats 特別強調「個體過度暴露機率」（Probability of Individual Overexposure），這是在階層模型（Hierarchical Model）下，將「群體變異」（Between-worker variability）視為滋擾參數進行平均後，對「隨機工人」暴露風險的評估。\n\n\n\n\nHewett 等人提出的 AIHA BDA 模型是另一個經典案例。\n參數空間（Parameter Space）：被限制在一個合理的 (\\mu, \\sigma) 參數空間內。\n先驗決策圖：職業衛生師根據專業判斷（Professional Judgment）設定先驗機率。這其實是在定義 p(\\theta_1, \\theta_2) 的形狀。\n決策機率：最終輸出的「第 4 類暴露機率為 80%」，這個 80% 是怎麼來的？它是透過對所有落在第 4 類定義範圍內的 (\\mu, \\sigma) 組合進行積分（加總其後驗機率）得來的，這屬於離散化應用。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#d常態分佈均值與變異數未知",
    "href": "0109CH3.html#d常態分佈均值與變異數未知",
    "title": "0109CH3 多參數模型",
    "section": "3.1D常態分佈均值與變異數未知",
    "text": "3.1D常態分佈均值與變異數未知\n理解「平均掉滋擾參數」的威力。\n\n6.1 標準常態模型6.2 滋擾參數的邊際後驗6.3 關注參數的邊際後驗E.小結\n\n\n\n假設數據 y \\sim N(\\mu, \\sigma^2)。我們想估計 \\mu，但不知道 \\sigma^2。使用無訊息先驗（Noninformative Prior）：\n\np(\\mu, \\sigma^2) \\propto (\\sigma^2)^{-1}\n\n\n\n\n\n根據 Gelman 的推導，\\sigma^2 的邊際後驗分佈服從 Scaled Inverse-Chi-Square 分佈。這告訴我們，由於數據量有限，變異數有可能是某個很大的值（分佈有長尾）。\n\n\n\n\n如果我們知道 \\sigma，\\mu 的後驗分佈應該是常態分佈（Normal）。\n當把那個服從 Inverse-Chi-Square 的 \\sigma^2 積掉之後，\\mu 的邊際後驗分佈變成了什麼？答案是：t 分佈（Student’s t-distribution）。\n\n\\mu | y \\sim t_{n-1}(\\bar{y}, s^2/n)\n\n這也就是「為什麼我們在小樣本時要用 t 檢定，而不是 Z 檢定（常態分佈）？」。因為，「因為樣本數小，標準差未知。」。\nt 分佈之所以比常態分佈『胖』（Fatter tails），正是因為它包含了對未知標準差（滋擾參數）的平均！」\n那個胖胖的尾巴，就是貝氏積分過程中所保留下來的「不確定性」。這證明了貝氏方法與經典統計學在這一點上是殊途同歸的，而且貝氏方法提供了更直觀的數學解釋：我們為了解決對 \\sigma 的無知，付出了讓 \\mu 的估計範圍變寬的代價。\n\n\n\n\n不要假裝知道我們不知道的事（例如真實的 GSD）。透過對這些滋擾參數進行嚴謹的積分或模擬，我們給出的暴露評估結果才是經得起考驗的，才能真正保護勞工免受潛在危害的威脅。\n傳統統計與貝氏比較表\n\n\n\n\n\n\n\n\n\n\n比較項目\n傳統頻率學派\n貝氏統計 (Bayesian)\n對 OSH 的影響\n\n\n參數視角\n參數是固定的常數 (\\theta)\n參數是隨機變數，有其機率分佈\n貝氏能描述 GSD 的不確定性範圍\n\n\n滋擾參數處理\nPlug-in Method (直接代入樣本估計值)\nMarginalization (對所有可能值進行積分/平均)\n傳統方法在小樣本下易低估風險\n\n\n結果呈現\n點估計 + 信賴區間 (Confidence Interval)\n後驗機率分佈 + 信用區間 (Credible Interval)\n貝氏產出可直接用於決策的機率 (如: &gt;95% OEL 的機率)\n\n\n小樣本表現\n往往過度自信 (區間過窄)\n較為保守 (區間較寬，如 t 分佈)\n貝氏更符合預警原則\n\n\n\n\n\n參考資料：\n\nGelman et al., Bayesian Data Analysis, Chapter 3.\nHewett et al., Rating Exposure Control Using Bayesian Decision Analysis.\nLavoué et al., Expostats: A Bayesian Toolkit.\nbrms package documentation (Measurement Error).",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#已知變異數的多變量常態模型",
    "href": "0109CH3.html#已知變異數的多變量常態模型",
    "title": "0109CH3 多參數模型",
    "section": "3.5 已知變異數的多變量常態模型",
    "text": "3.5 已知變異數的多變量常態模型\n（Multivariate normal model with known variance）\n\nA. 多變量常態模型B. 暴露概況的向量化C. 變異數-共變異數矩陣 (\\Sigma)D. OHS實務應用E. 小結\n\n\n\n我們先建立對「多變量」（Multivariate）世界的直觀理解。在傳統的統計課程中，我們習慣處理單一變數（Scalar），例如某位工人的 8 小時時量平均濃度（TWA）是 5 ppm。但在多變量模型中，我們的基本單元不再是一個數字，而是一個「向量」（Vector）。\n\n\n\n\n假設我們正在評估一組石化廠維修工人的暴露情況，他們同時暴露於苯（Benzene）、甲苯（Toluene）、乙苯（Ethylbenzene）和二甲苯（Xylene），即所謂的 BTEX 混合物。對於每一次的正式採樣，我們獲得的不是一個數據，而是一組數據。\n我們定義觀察值向量 y 為一個 d \\times 1 的欄向量（Column Vector），其中 d 代表化學物質的數量（維度）。對於 BTEX 案例， d=4。\n\ny = \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_d \\end{pmatrix}\n\n在職業衛生實務中，環境測测數據通常呈現對數常態分佈（Lognormal Distribution），這意味著數據受限於正值且具有右偏的長尾特性。為了符合常態分佈的假設，我們通常會先將濃度取自然對數（ln）。因此，y_1 代表苯濃度的對數值，y_2 代表甲苯濃度的對數值，依此類推。\n在這個模型中，我們想要推論的未知參數不再是單一的平均值 \\theta，而是一個 平均數向量（Mean Vector） \\mu：\n\n\\mu = \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\\\ \\vdots \\\\ \\mu_d \\end{pmatrix}\n\n這個向量 \\mu 代表了該相似暴露群（Similar Exposure Group, SEG）在長期暴露下的真實中心趨勢。它是一個多維空間中的「點」，代表了該群體暴露的重心。\n\n\n\n\n在單變量統計中，我們用變異數 \\sigma^2 來描述數據的分散程度。但在多變量世界裡，分散程度的描述變得更加複雜，因為我們不僅要關心每一種化學物質本身的變異，還要關心它們之間的「連動關係」。這就是 變異數-共變異數矩陣（Variance-Covariance Matrix） \\Sigma 的角色。\n\n\\Sigma = \\begin{pmatrix} \\sigma_1^2 & \\sigma_{12} & \\dots & \\sigma_{1d} \\\\\\sigma_{21} & \\sigma_2^2 & \\dots & \\sigma_{2d} \\\\\\vdots & \\vdots & \\ddots & \\vdots \\\\\\sigma_{d1} & \\sigma_{d2} & \\dots & \\sigma_d^2 \\end{pmatrix}\n對角線元素 (\\sigma_j^2)： 代表第 j 種化學物質的變異數（Variance）。例如，\\sigma_1^2 反映了苯濃度在不同天數或不同工人間的波動幅度。在職業衛生中，這通常與幾何標準差（GSD）有關。\n非對角線元素 (\\sigma_{ij})： 代表第 i 種與第 j 種化學物質之間的共變異數（Covariance）。這是多變量模型的核心靈魂。如果 \\sigma_{12} 是正值且數值很大，這意味著當苯濃度升高時，甲苯濃度通常也會升高。\n\n為什麼化學物質會「共變」？\n\n\n共同來源： BTEX 通常來自同一個液體混合物（如汽油或溶劑）。當溶劑揮發時，根據拉午耳定律（Raoult’s Law），所有成分會同時釋放到空氣中。因此，它們的濃度呈現高度正相關。\n共同控制機制： 通風系統的效率影響所有污染物的移除。如果局部排氣裝置故障，所有污染物的濃度會同時飆升。\n負相關的可能性： 雖然較少見，但也可能發生。例如，如果工人輪流執行兩個任務，任務 A 產生化學物質 X，任務 B 產生化學物質 Y。花在任務 A 的時間越多，花在任務 B 的時間就越少，這可能導致 X 與 Y 的日暴露量呈現負相關。\n\n\n假設：變異數矩陣 \\Sigma 是已知的，這意味著我們假設我們已經完全掌握了該暴露群的波動特性和物質間的相關結構，唯一的未知數是它們的平均濃度 \\mu。\n\n\n3.1 概似函數（The Likelihood Function）：數據的聲音\n\n在貝氏分析中，概似函數描述了「已知參數下，觀察到這組數據的機率」。\n\n\n\n3.2 共軛先驗分佈（Conjugate Prior）：專家的直覺\n\n貝氏分析的精髓在於引入「先驗資訊」（Prior Information）。在進行昂貴的採樣之前，資深的工業衛生師通常對暴露情況已有預判。這些預判可能來自：\n\n物理模型：根據化學品的蒸氣壓、使用量和通風率進行的推估 3。\n歷史數據：該工廠過去十年的監測紀錄。\n類似暴露群（SEG）的類推：參考同業其他類似製程的數據。\n\n對於平均數向量 \\mu，其共軛先驗分佈也是一個多變量常態分佈。\n「共軛性」（Conjugacy）：如果先驗是常態分佈，概似函數是常態分佈，那麼數學推導出來的後驗分佈（Posterior Distribution）保證也是常態分佈 。這大大簡化了計算，讓我們可以直接獲得解析解（Analytical Solution），而不需要依賴複雜的蒙地卡羅模擬（MCMC）。\n\n\n\n3.3 後驗分佈（The Posterior）：知識的融合\n\n借用力量（Borrowing Strength）。假設 \\Sigma 顯示苯和甲苯高度相關。在某次採樣中，苯的數據因為感測器干擾而變得非常不穩定（變異數大），但甲苯的數據非常精確且顯示濃度偏高。透過矩陣乘法，甲苯的資訊會「流向」苯的估計。模型會推斷：「既然甲苯這麼高，且兩者通常正相關，那麼那個模糊不清的苯讀數，很可能也是偏高的。」這修正了單獨看苯數據可能產生的誤判。這就是多變量貝氏分析在職業衛生中最具價值的特性之一：利用相關性來彌補數據品質的不足。\n\n\n\n\n\n1 案例背景：石化廠維修作業\n\n假設我們關某石化廠的維修工人，他們負責維修輸送重組油（Reformate）的泵浦。重組油富含芳香烴，主要成分為 BTEX。\n危害特性： 苯是確認的人類致癌物（白血病風險），甲苯和二甲苯則是中樞神經抑制劑，並可能導致耳毒性（聽力損失）。\n暴露情境： 暴露發生在法蘭拆卸時的瞬間洩漏。由於來源相同，我們預期這些化學物質的濃度會同步波動。\n\n\n\n2 設定「已知變異數矩陣」 \\Sigma\n\n根據文獻 1，環境中的 BTEX 相關係數通常很高（r &gt; 0.7）。我們可以設定如下的結構（假設為對數尺度）：\n\n變異數（對角線）：假設 GSD 為 2.5（職業暴露的典型值），換算成對數變異數約為 \\sigma^2 \\approx 0.84。\n相關係數（非對角線）：設苯與甲苯的相關係數為 0.8。\n這給了我們一個強大的 \\Sigma 矩陣，告訴模型：「這些物質是同進同退的」。\n\n\n\n\n3 應用一：缺失數據的插補\n\n情境：工廠進行了 5 次全班次採樣。但在第 3 次採樣中，實驗室回報苯的樣本分析失敗（例如採樣管破損或層析圖干擾），但甲苯、乙苯和二甲苯的數據是有效的，且顯示當天濃度異常高（高暴露日）。\n傳統做法（頻率學派）：\n\n直接刪除第 3 筆數據。這可能會導致嚴重偏差，因為我們刪除了一個「高暴露日」的數據，導致最終評估低估了工人的平均暴露風險。\n\n貝氏多變量做法：\n\n利用條件後驗分佈（也是常態分佈），\n我們可以計算： p(\\text{苯} | \\text{甲苯}, \\text{乙苯}, \\text{二甲苯}, \\mu, \\Sigma)。\n\n由於 \\Sigma 包含強正相關，模型會利用當天偏高的甲苯數據，預測出當天的苯濃度也應該偏高，並給出一個帶有不確定性範圍的估計值。\n這種方法稱為「聯合模型插補」（Joint Modeling Imputation），它保留了高暴露日的資訊，提供了更誠實的風險評估。\n\n\n\n\n\n4 應用二：混合物風險評估與法規符合度\n\n傳統的法規符合度評估是針對個別化學物質。例如，檢查苯是否超過 1 ppm，甲苯是否超過 100 ppm。\n然而，ACGIH 和 NIOSH 建議對於具有相似毒理作用的物質（如有機溶劑對中樞神經的影響），應評估其加成效應（Additive Effect）。\n\n我們需要計算混合物指標（Hazard Index, HI）：\n\nHI = \\frac{C_{\\text{Benzene}}}{OEL_{\\text{Benzene}}} + \\frac{C_{\\text{Toluene}}}{OEL_{\\text{Toluene}}} + \\dots\n\n\n使用多變量貝氏模型，我們不僅得到每個物質的平均濃度 \\mu 的點估計，我們得到的是 \\mu 的聯合後驗分佈（Joint Posterior Distribution）。這是一團位於多維空間中的「機率雲」。\n我們可以計算這團雲落在「安全區域」（即 HI &lt; 1 的區域）內的體積比例。\n如果苯和甲苯呈負相關（極少見，但在某些輪替工作中可能發生），高苯會伴隨低甲苯，混合風險可能較低。\n如果呈正相關（常見情況），高苯伴隨高甲苯，發生聯合超標（Joint Exceedance）的機率會急劇上升。\n多變量貝氏模型能夠精確地捕捉這種相關性對總體風險的放大效應，這是單變量分析完全無法做到的。這對於保護工人健康至關重要，因為忽略相關性往往會低估混合暴露的風險。\n\n\n\n5 應用三：貝氏決策分析（BDA）\n\nSnippet 提到利用貝氏方法將暴露分級（Category 0-4）。這通常涉及計算第 95 百分位數（P95）超過容許濃度（OEL）的機率。\n在多變量情境下，我們可以設定一個更複雜的決策規則。例如：「是否有超過 5% 的機率，苯的 P95 超標 或者 混合物 HI 超標？」\n透過固定變異數 \\Sigma（使用保守的預設值，如 GSD=3.0），我們可以快速篩選出高風險的相似暴露群（SEG），決定哪些群體需要立即實施工程控制（如密閉製程或局部排氣），哪些只需要行政管理。\n\n\n\n\n\n世界是多變量的： 不要只盯著單一化學物質看，學習看到數據背後的「關聯結構」。\n相關性即資訊： 透過多變量模型，我們可以利用容易測量的物質（如甲苯）來推斷難以測量或數據缺失的物質（如苯）。\n貝氏更新是加權平均： 後驗估計是我們「先驗信念」與「數據證據」之間的拉鋸戰，而權重取決於誰更「精確」。\n已知變異數是工具而非真理： 它簡化了問題，讓我們能專注於評估平均暴露水準，但在應用時必須保持對變異數不確定性的警覺。\n\n\n在未來，當你面對複雜的混合暴露、稀缺的監測數據以及保護工人健康的重責大任時，希望你們能想起這個模型，並利用它做出更科學、更合理的決策。\n\n\n\n此節參考文獻\n本報告綜合了 Gelman 等人的貝氏統計理論架構，以及多項關於 BTEX 職業暴露、尿液生物指標 、缺失數據插補與貝氏決策分析 的研究成果。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#未知平均值與變異數的多變量常態分佈",
    "href": "0109CH3.html#未知平均值與變異數的多變量常態分佈",
    "title": "0109CH3 多參數模型",
    "section": "3.6 未知平均值與變異數的多變量常態分佈",
    "text": "3.6 未知平均值與變異數的多變量常態分佈\n\n當我們面對真實世界中複雜的化學品暴露——特別是多種有機溶劑、金屬燻煙或粉塵同時存在的「混合暴露（Mixed Exposure）」情境時，傳統的單變量（Univariate）統計模型往往顯得捉襟見肘。\n對於職業衛生師來說，理解單一參數（如二項分佈的機率 \\theta 或常態分佈的平均值 \\mu）相對容易，因為它符合我們對「平均值」的直觀認知。但在 OSH 實務中，我們幾乎從未遇到只有一個未知數的情況。當我們進入現場進行空氣採樣時，我們既不知道真實的長期平均濃度（Long-term Average, \\mu），也不知道該環境中濃度的變異程度（Variance, \\sigma^2）。更甚者，當勞工同時暴露於苯（Benzene）與甲苯（Toluene）時，我們還面臨第三個未知數：這兩者之間的相關性（Correlation, \\rho）。\n貝氏統計提供了一個統一且強大的框架來處理這些多重未知數。不同於頻率學派將參數視為固定常數，貝氏學派將所有未知參數（\\mu, \\sigma）視為隨機變數，並透過機率分佈來描述我們對它們的認知狀態。這種思維模式特別適合 OSH 領域，因為我們經常需要在數據極度稀缺（Small Sample Size，例如 N &lt; 6）的情況下做出關乎勞工健康的重大決策。\n\n\nA. 職業衛生中的多變量常態模型Ｂ. 共軛先驗的選擇Ｃ. 後驗分佈的推導D. 邊際後驗分佈：處理滋擾參數與 t 分佈的回歸E. Expostats 實務應用與計算模擬F. 小結\n\n\n\n1 為什麼我們需要多變量模型？\n\n在傳統的工業衛生實務中，若我們要評估一個噴漆作業員的健康風險，我們通常會分別測量其接觸的甲苯、二甲苯與丁酮濃度，並分別計算其是否符合各自的容許濃度標準（PEL）。如果三者具有相似的毒理作用（例如中樞神經抑制），我們可能會計算「加成效應指數（Hazard Index, HI）」。\n這種做法隱含了一個假設：各個化學物質的濃度波動是相互獨立的。事實上，在同一個工作場所中，汙染物的濃度往往呈現高度的「正相關性」。可能因為：\n\n共同來源（Common Source）： 當通風系統效率下降時，甲苯濃度升高，二甲苯濃度通常也會隨之升高。\n製程配方（Formulation）： 油漆中的溶劑比例是固定的，這導致揮發到空氣中的成分比例也具有某種線性關係。\n\n如果我們忽略這種相關性（Correlation），我們就會低估「聯合超標」的風險。例如，在獨立假設下，甲苯與二甲苯同時出現極端高值的機率很低；但在高度正相關的真實世界中，這卻是常態。多變量常態模型（Multivariate Normal Model, MVN）正是為了捕捉這種複雜的相關結構而生 。  \n\n\n\n\n\n常態-逆韋沙分佈（Normal-Inverse-Wishart）\n\n在貝氏統計中，為了讓後驗分佈具有解析解（Analytical Solution），我們通常會選擇共軛先驗（Conjugate Prior）。對於「未知平均值、未知變異數」的多變量常態模型，其共軛先驗家族被稱為 常態-逆韋沙分佈（Normal-Inverse-Wishart, NIW） 。\n\n\n\n\n\n當我們先驗的信念（Prior）遇到現場採樣的數據（Likelihood），我們就利用貝氏定理進行更新，得到後驗分佈（Posterior Distribution）。\n對於 常態-逆韋沙分佈 Normal-Inverse-Wishart 模型，後驗分佈 p(\\mu, \\Sigma | y) 依然是 常態-逆韋沙分佈，形式完全不變，只是四個超參數被「更新」了。\n\n\n後驗參數的更新公式\n我們將更新後的參數標記為下标 n（代表納入了 n 個樣本）：\n\n平均值的更新（\\mu_n）： \\mu_n = \\frac{\\kappa_0}{\\kappa_0 + n} \\mu_0 + \\frac{n}{\\kappa_0 + n} \\bar{y}\n解讀： 這是一個經典的加權平均（Weighted Average）。後驗平均值 \\mu_n 是「先驗猜測 \\mu_0」與「數據平均 \\bar{y}」的折衷。權重取決於 \\kappa_0（先驗強度）與 n（數據量）的比例。\n\n情境 A： 新製程，數據少（n=3），但我們對同類製程很有經驗（\\kappa_0=10）。此時 \\mu_n 會被拉向 \\mu_0，避免因少數幾個隨機樣本而誤判。\n情境 B： 進行了大規模採樣（n=100）。此時 n \\gg \\kappa_0，數據說話，\\mu_n 會幾乎等於 \\bar{y}。\n\n信心強度的更新（\\kappa_n 與 \\nu_n）：\n\n\\kappa_n = \\kappa_0 + n\n\\nu_n = \\nu_0 + n\n解讀： 這代表「資訊量的累積」。每多採樣一個樣本，我們對系統的了解就增加一分，自由度也隨之增加。這反映了貝氏統計是一個不斷學習、累積知識的過程。\n有兩個關鍵的超參數（Hyperparameters），作為實務專家，我們必須懂得如何設定它們：\n\n\\nu_0（自由度，Degrees of Freedom）：\n\n數學意義： 它決定了分佈的「集中程度」或我們對先驗資訊的「信心強度」。\\nu_0 必須大於 d-1 才能保證分佈是合法的（Proper）。\nOSH 實務解讀： \\nu_0 可以被視為我們先驗資訊的「等效樣本數」。如果你根據過去 20 年的同業資料庫，非常有信心認為甲苯和二甲苯的相關係數在 0.8 左右，你可以設定一個較大的 \\nu_0（例如 50）。如果你對這個新製程完全陌生，心裡沒底，你應該設定 \\nu_0 為最小值（例如 d+1），這代表一種「弱訊息先驗（Weakly Informative Prior）」，讓現場數據主導結果。\n\n假設我們對一位勞工進行了 n 次監測，每次監測包含 d 種化學物質（例如 d=2 代表苯與甲苯）。\n\n\n\\kappa_0（先驗樣本數係數）：\n\n這控制了我們對 \\mu_0 的信心。請注意，\\mu 的變異數被設定為 \\Sigma / \\kappa_0。\nOSH 實務解讀：它意味著我們對「平均值」的不確定性，是與「環境本身的變異程度（\\Sigma）」掛鉤的。如果一個作業環境本身濃度忽高忽低（\\Sigma 大），我們對其真實平均值的估計自然也比較沒把握（\\mu 的變異數大）。這完全符合工業衛生的直覺。\\kappa_0 越大，代表我們先驗信心越強，\\mu 就越被鎖定在 \\mu_0 附近。\n\n\n\n當事實（數據）與預期（先驗）發生衝突時，貝氏模型會自動增加後驗的變異數。換句話說，衝突導致不確定性增加。這是一個非常健康的風險管理機制，它提醒我們：「你的模型可能有問題，或者情況比你想像的更混亂。」\n\n\n\n\n\n在職業衛生暴露評估中，我們通常最關心的是 \\mu（真實平均暴露濃度），因為這直接關係到是否符合 8 小時日時量平均容許濃度（PEL-TWA）。而 \\Sigma（變異數矩陣）雖然決定了變異程度，但在判斷「平均值是否超標」時，它往往被視為滋擾參數（Nuisance Parameter）。\n貝氏分析的強大之處在於，我們可以透過積分將滋擾參數「積掉（Integrate out）」，從而得到僅關於 \\mu 的邊際後驗分佈。\n\n\n\n\n現代工具如 Expostats 是建立在這些貝氏原理之上 。\n\n\n1 方法：從公式到模擬\n\n在 BDA的時代，我們不再依賴查表，而是使用電腦模擬（Simulation）來解這些分佈。對於多變量常態分佈的模型，我們可以採用直接抽樣（Direct Sampling）策略，因為它是共軛模型，無需動用複雜的 MCMC。\n\n\n\n2 案例：混合溶劑暴露評估\n\n情境： 某印刷廠使用含有甲苯與丁酮（MEK）的溶劑。兩者皆有 OEL = 200 ppm。我們採集了 5 個樣本 (n=5)。問題： 勞工是否面臨聯合暴露超標的風險？\n\n分析步驟：\n\n設定先驗： 根據過往經驗，設定 \\mu_0 為 ，並設定 \\Lambda_0 反映兩者有正相關（例如 \\rho=0.6），因為它們來自同一溶劑揮發。\n輸入數據： 輸入 5 組採樣數據，計算 \\bar{y} 和 S。\n更新參數： 計算 \\mu_n, \\Lambda_n, \\nu_n。\n模擬風險： 產生 10,000 組後驗樣本。對於每一組 (\\mu^{(j)}, \\Sigma^{(j)})，我們可以計算該情境下的「加成效應指數（Hazard Index, HI）」超過 1 的機率。\n\nP(\\text{HI} &gt; 1) = \\frac{1}{10000} \\sum_{j=1}^{10000} I\\left( \\frac{\\mu_{\\text{tol}}^{(j)}}{200} + \\frac{\\mu_{\\text{mek}}^{(j)}}{200} &gt; 1 \\right)\n\n\n結果解讀：\n\n如果我們忽略相關性（假設 \\Sigma 是對角矩陣），我們可能算出超標機率只有 5%。但因為考慮了正相關（當甲苯高時 MEK 也高），多變量模型可能告訴我們超標機率高達 20%。這 15% 的差距，就是忽略相關性所帶來的隱藏風險。\n\n\n\n3 Expostats 的連結\n\nExpostats 工具包中的 Tool 2 處理「工人內（Within-worker）」與「工人均（Between-worker）」的變異。這本質上是一個多層次模型（Hierarchical Model）。\n在該模型中，每個工人的平均暴露 \\mu_i 被視為從一個母群體分佈中抽樣出來的。\nExpostats 利用貝氏方法計算「個別工人過度暴露的機率（Probability of Individual Overexposure）」，這正是利用了後驗預測分佈的概念，將參數不確定性與個體變異性整合起來。\n\n\n\n\n\n未知平均值與變異數的多變量常態分佈，是職業衛生邁向精準化管理的基石。\n\n\n還原真實： 它允許我們建立包含相關結構的模型，真實反映混合物暴露的風險，避免了獨立性假設帶來的偏差。\n擁抱不確定性： 透過 t 分佈與 NIW 先驗，它量化了我們因樣本稀缺而產生的無知，強迫我們在決策時保留安全係數。\n整合知識： 它提供了一個數學管道（先驗參數），讓資深專家的經驗與歷史數據能合法、客觀地進入風險評估流程，穩定了小樣本下的決策品質。\n\n\n對於 OSH 專家而言，掌握這些貝氏工具不僅是統計能力的提升，更是對勞工生命安全做出更嚴謹承諾的表現。\n\n單變量與多變量常態模型貝氏推論對照表\n\n\n\n\n\n\n\n\n\n特徵\n單變量常態模型 (Sec 3.2)\n多變量常態模型 (Sec 3.6)\nOSH 實務意義\n\n\n觀測值\n純量 y_i (如：苯濃度)\n向量 y_i (如：[苯, 甲苯])\n能夠同時評估多種危害因子\n\n\n平均值參數\n純量 \\mu\n向量 \\mu\n估計多種物質的 GM\n\n\n變異數參數\n純量 \\sigma^2\n矩陣 \\Sigma (共變異數矩陣)\n捕捉物質間的相關性 (Correlation)\n\n\n共軛先驗\nNormal-Inverse-\\chi^2\nNormal-Inverse-Wishart (NIW)\n數學結構一致，矩陣運算取代純量\n\n\n先驗參數\n\\mu_0, \\kappa_0, \\nu_0, \\sigma_0^2\n\\mu_0, \\kappa_0, \\nu_0, \\Lambda_0\n\\Lambda_0 設定了預期的相關結構\n\n\n邊際後驗\nStudent’s t 分佈\nMultivariate Student’s t 分佈\n變異數未知導致厚尾，風險評估更保守\n\n\n主要優勢\n簡單直觀，適合單一物質\n考慮相關性，適合混合物\n避免低估聯合暴露風險",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#生物檢體測定bioassay範例剖析",
    "href": "0109CH3.html#生物檢體測定bioassay範例剖析",
    "title": "0109CH3 多參數模型",
    "section": "3.7 生物檢體測定（Bioassay）範例剖析",
    "text": "3.7 生物檢體測定（Bioassay）範例剖析\n\n當我們想要評估勞工的平均暴露濃度（\\mu）是否超過容許濃度（PEL）時，我們同時也面臨著暴露變異數（\\sigma^2）未知的情況。這個變異數雖然不是我們決策的直接目標，但在模型中卻是不可或缺的。在貝氏統計中，這類參數被稱為「擾亂參數」（Nuisance parameters）。本節將引導讀者理解如何透過積分運算「處理掉」這些擾亂參數，從而獲得我們真正關心的參數的邊際後驗分佈（Marginal Posterior Distribution）。\n\n\nA. 擾亂參數的處理與邊際化B. 常態數據與無訊息先驗C. 多變量常態模型D. 職業衛生應用的延伸E. 小結表 1：傳統方法與貝氏方法在生物檢定分析中的比較表 2：BDA3 第三章概念在職業衛生中的應用對照\n\n\n\n1 擾亂參數的概念與挑戰\n\n想像我們正在評估一個噴漆作業員的甲苯暴露風險。我們最關心的是他的長期平均暴露濃度（\\theta_1），因為這直接關係到慢性健康的風險。然而，要準確估計這個平均值，我們必須知道暴露數據的波動程度，也就是標準差（\\theta_2）。如果數據波動很大，我們對平均值的估計就會變得非常不確定；反之，如果波動很小，平均值的估計就會精準許多。\n在這種情境下，標準差 \\theta_2 就是一個「擾亂參數」。它本身並非我們決策的最終依據（我們不會因為標準差很大就直接開罰單，而是看濃度是否超標），但它卻深刻影響著我們對 \\theta_1 的判斷。在傳統統計中，我們往往被迫使用點估計（Point Estimate）來固定 \\theta_2，例如直接使用樣本標準差 s 來代替母體標準差 \\sigma。這種做法在樣本數很大時是可以接受的，但在職業衛生常見的小樣本數據中，這種做法會嚴重低估我們的不確定性，導致「虛假的精確」（False Precision）。\n\n\n\n2 貝氏邊際化的數學原理\n\n貝氏分析提供了一種優雅的解決方案，即透過積分將擾亂參數「平均」掉。這一過程稱為邊際化（Marginalization）。我們的目標是獲得感興趣參數 \\theta_1 的邊際後驗機率密度函數 p(\\theta_1 | y)。\n根據機率法則，我們可以從聯合後驗分佈 p(\\theta_1, \\theta_2 | y) 出發。這個聯合分佈同時描述了平均值和變異數的所有可能組合及其機率。為了得到僅關於 \\theta_1 的資訊，我們對 \\theta_2 進行積分：\n\np(\\theta_1 | y) = \\int p(\\theta_1, \\theta_2 | y) \\, d\\theta_2\n\n這個積分式告訴我們，\\theta_1 的邊際後驗機率，實際上是所有可能的 \\theta_2 值所對應的條件機率 p(\\theta_1 | \\theta_2, y) 的加權平均，而權重正是 \\theta_2 本身的後驗機率 p(\\theta_2 | y)。\n這可以用下式更清晰地表達：\n\np(\\theta_1 | y) = \\int p(\\theta_1 | \\theta_2, y) p(\\theta_2 | y) \\, d\\theta_2\n\n這意味著，我們不需要假設變異數是某個固定值，而是考慮了變異數可能是 0.5、1.0 或 5.0 等所有可能性，並根據數據支持這些變異數的程度（權重），將對應的平均值分佈疊加起來。這種方法誠實地反映了因為變異數未知而帶來的額外不確定性，這對於涉及人命安全的職業衛生決策至關重要。\n\n\n\n3 模擬策略的應用\n\n在實際操作中，尤其是當積分難以解析計算時，我們採用MCMC模擬（Simulation）的方法來實現這一過程。這是現代貝氏計算的基石。我們可以分兩步進行：\n\n\n首先，從擾亂參數的邊際後驗分佈 p(\\theta_2 | y) 中抽取一個樣本 \\theta_2^*。\n接著，利用這個抽出的 \\theta_2^*，從條件後驗分佈 p(\\theta_1 | \\theta_2^*, y) 中抽取我們感興趣的參數 \\theta_1^*。\n\n\n重複這個過程數千次，我們就得到了一組 \\theta_1 的樣本，這組樣本自然地形成了解析積分後的邊際分佈。在職業衛生暴露評估工具（如 Expostats）中，這正是背後運算的邏輯基礎。我們不假設我們確切知道勞工的變異係數（GSD），而是模擬出成千上萬種可能的 GSD 情境，從而推導出超標風險的真實機率分佈。\n\n\n\n\n\n（Normal data with a noninformative prior distribution）\n\n直接對應到日常處理的連續型暴露數據（如噪音分貝數、空氣中有害物濃度）。\n\n\n\n1 模型的建立與先驗的選擇\n\n假設我們有一組獨立的觀測值 y_1, \\dots, y_n，它們服從常態分佈 N(\\mu, \\sigma^2)。這兩個參數 \\mu（平均值）和 \\sigma^2（變異數）都是未知的。這正是我們在進行作業環境監測時最常遇到的情況。\n為了進行貝氏推論，我們需要設定先驗分佈。在缺乏先前資訊的情況下（例如一個全新的製程，我們沒有任何歷史數據），我們使用「無訊息先驗」（Noninformative Prior）。對於位置參數 \\mu 和尺度參數 \\sigma，標準的無訊息先驗假設它們是獨立的，且 \\mu 在實數軸上是均勻分佈的，而 \\sigma^2 的對數是均勻分佈的。這導出了著名的傑弗里斯先驗（Jeffreys’ Prior）：\n\np(\\mu, \\sigma^2) \\propto (\\sigma^2)^{-1}\n\n這個先驗的選擇保證了分析結果具有尺度不變性（Scale Invariance），也就是說，無論我們是用 ppm 還是 mg/m³ 來計量，推論的結果都是一致的。\n\n\n\n2 聯合後驗分佈的推導\n\n將上述先驗與常態分佈的概似函數（Likelihood）相乘，我們得到聯合後驗分佈：\n\np(\\mu, \\sigma^2 | y) \\propto \\sigma^{-n-2} \\exp \\left( -\\frac{1}{2\\sigma^2} \\left[ (n-1)s^2 + n(\\bar{y} - \\mu)^2 \\right] \\right)\n\n這裡的 \\bar{y} 是樣本平均值，s^2 是樣本變異數。這個公式雖然看起來複雜，但它包含了所有我們對這組數據的知識。它告訴我們，\\mu 和 \\sigma^2 之間存在著依賴關係：數據的分散程度（\\sigma^2）會影響我們對中心位置（\\mu）的判斷。\n\n\n\n3 變異數的邊際後驗分佈：逆卡方分佈\n\n為了處理擾亂參數，我們先對 \\mu 進行積分，得到 \\sigma^2 的邊際後驗分佈。數學推導的結果顯示，\\sigma^2 服從一個「縮放逆卡方分佈」（Scaled Inverse-Chi-Square Distribution）：\n\n\\sigma^2 | y \\sim \\text{Inv-}\\chi^2(n-1, s^2)\n\n它告訴我們，儘管我們不知道真實的變異數，但我們可以確定它的分佈形狀完全由樣本數（n）和樣本變異數（s^2）決定。對於職業衛生專家來說，這解釋了為什麼在小樣本下（自由度 n-1 很小），我們會看到變異數的分佈呈現長尾形狀，這意味著真實的暴露變異可能遠大於我們僅從 3-5 個樣本中觀察到的變異。這也提醒我們，在小樣本下直接使用樣本標準差作為母體標準差的點估計是非常危險的，極易低估風險。\n\n\n\n4 平均值的邊際後驗分佈\n\n學生 t 分佈\n\n如果我們將聯合分佈中的 \\sigma^2 積分掉，\\mu 的邊際後驗分佈會是什麼樣子？答案是：\n\n\\frac{\\mu - \\bar{y}}{s/\\sqrt{n}} \\bigg| y \\sim t_{n-1}\n\n這正是 t 分佈（Student’s t-distribution）。在傳統統計學中，我們被告知當變異數未知時要用 t 檢定；而在貝氏統計中，我們透過數學證明了，當我們對變異數的不確定性進行積分（平均化）後，常態分佈自然地演變成了 t 分佈。\nt 分佈比常態分佈有著更厚的尾部（Heavier Tails）。這反映了因為我們不知道真實的 \\sigma，所以極端值出現的機率比常態分佈預測的要高。當樣本數 n 增加時，t 分佈逐漸收斂於常態分佈，這與我們的直覺一致：數據越多，不確定性越小。對於只有 6 個採樣點的暴露評估，使用 t 分佈的貝氏區間估計，能比單純使用常態假設提供更保守、更安全的防護建議。\n\n\n\n\n5 實例分析\n\n光速測量與暴露異常值\nBDA3 書中引用了 Simon Newcomb 在 1882 年測量光速的經典案例。Newcomb 進行了 66 次測量，數據大致呈現常態分佈，但有兩個極低的異常值（Outliers）。\n\n在使用常態模型進行貝氏分析時，這兩個異常值會顯著拉低平均值的後驗分佈，並極大得拉寬變異數的估計。\n這給職業衛生數據分析帶來了深刻的意涵：我們在現場經常會遇到「異常值」（例如採樣泵故障、工人意外接觸洩漏源）。標準的常態模型對異常值非常敏感。這暗示了在進階分析中，我們可能需要更穩健（Robust）的模型，例如直接假設數據服從 t 分佈而非常態分佈。\n\n\n\n\n\n\n（Multivariate normal model with known variance）\n\n在職業衛生領域，勞工往往不只是暴露於單一危害因子。油漆工同時接觸甲苯、二甲苯和乙酸乙酯；銲接工同時吸入錳、鉻和鎳的燻煙。這些暴露之間往往存在高度的相關性（Correlation）。\n\n\n\n1 從單變量到多變量\n\n將單變量的概念推廣到多變量常態分佈（Multivariate Normal, MVN）。在這裡，觀測值 y 不再是一個數，而是一個向量；平均值 \\mu 也是一個向量，而變異數 \\sigma^2 則變成了一個共變異數矩陣（Covariance Matrix, \\Sigma）。\n\ny \\sim N(\\mu, \\Sigma)\n\n\n\n\n2 相關性的實務意義\n\n為什麼我們要使用多變量模型？假設我們在評估一個混合溶劑的健康風險。如果我們分別獨立分析甲苯和二甲苯，我們就忽略了它們「共進退」的特性。\n資訊借用（Borrowing Strength）： 在貝氏多變量模型中，如果我們知道甲苯和二甲苯高度正相關（例如相關係數 \\rho = 0.8），那麼即使某次採樣中二甲苯的分析數據遺失了，但甲苯濃度很高，模型也會自動推斷二甲苯濃度可能也很高。這種透過相關性來增強推論能力的特性，是多變量貝氏分析的一大優勢。\n聯合風險評估： 對於具有加成效應（Additive Effect）的化學物質，我們關心的是總劑量是否超標。多變量後驗分佈可以直接計算 \\frac{C_1}{PEL_1} + \\frac{C_2}{PEL_2} 的機率分佈，正確處理 C_1 和 C_2 之間的相關性，這是傳統獨立分析無法做到的。\n儘管此節探討了變異數未知的複雜情況（涉及到 Inverse-Wishart 分佈），但對於初學者而言，理解相關性如何影響我們對聯合暴露風險的評估是首要任務。\n\n\n\n\n\n\n雖然工業衛生師很少親自做老鼠實驗，但這個邏輯架構（羅吉斯迴歸 + 貝氏推論）完全適用於我們的領域：\n流行病學劑量反應： 將「老鼠死亡」換成「工人聽力損失」或「肺功能異常」，將「劑量」換成「累積噪音暴露」或「粉塵濃度」。我們可以估計導致 10% 工人致病的閾值（Benchmark Dose, BMD）。\n職業暴露限值（OEL）設定： 現代的 OEL 設定越來越依賴這種機率模型來推導 BMDL（Benchmark Dose Lower Confidence Limit），這本質上就是貝氏後驗區間的下限。\n法規符合度判斷： 如果我們將模型改為預測「超過 OEL 的機率」，這就是 Expostats 等工具的核心邏輯。\n\n\n\n\n\n1 從解析到模擬\n\n生物檢定範例標誌著一個分水嶺。對於簡單的常態模型（3.2節），我們有數學公式（t 分佈）。但對於像羅吉斯迴歸這樣更真實的模型，我們必須依賴計算機模擬。\n對於 1-2 個參數，網格逼近法是直觀且有效的。\n但如果參數增加到 3 個以上（例如我們引入了工廠間的變異、季節效應等），網格點的數量會呈指數爆炸（Curse of Dimensionality）。這時，我們就需要更高級的 馬可夫鏈蒙地卡羅（MCMC） 方法，如 Gibbs Sampling 或 Metropolis演算法。這些將在 BDA3 的後續章節介紹。\n\n\n\n2 職業衛生的ＢＤＡ\n\n建立模型： 根據數據特性選擇概似函數（如暴露數據用對數常態，問卷用多項式，二元結果用二項式）。\n設定先驗： 如果有歷史數據或專家判斷，使用訊息先驗；否則使用無訊息先驗。\n計算後驗： 簡單模型用解析解（共軛）或 Expostats 這樣的現成工具；複雜模型使用 JAGS/Stan 進行 MCMC 模擬。\n推導決策變數： 從後驗樣本中計算我們真正關心的指標（如 95% 分位數、超標機率、LD50）。\n決策分析： 基於後驗機率做出行動建議（如「該暴露群組有 90% 機率是安全的，建議降低監測頻率」）。\n\n\n\n\n3 建議\n\n貝氏統計為職業衛生暴露評估提供了一套嚴謹且靈活的數學框架。它不強迫我們在數據不足時做出武斷的點估計，而是允許我們誠實地擁抱不確定性。\n此章教會我們如何處理擾亂參數，讓我們能專注於真正重要的風險指標。\n第 3.7 節的生物檢定範例展示了即使在無法寫出公式的情況下，我們依然可以用計算力（網格法）來繪製出風險的全貌。\nLD50 的推導邏輯與我們計算 OEL 的超標機率在本質上是相通的：它們都是從參數的後驗分佈中衍生出來的實務指標。\n對於職業安全衛生專家而言，不需要背誦繁複的積分公式，但必須掌握這種「分佈思考」的思維模式。當你面對一個少得可憐的採樣數據時，不要只給出一個平均值，試著給出一個分佈，告訴管理者風險的可能範圍。這才是貝氏統計賦予我們的真正力量。\n\n\n\n\n\n\n\n\n\n\n\n\n\n特性\n傳統頻率學派 (MLE)\n貝氏方法 (網格逼近)\n\n\n參數估計\n點估計 (\\hat{\\alpha}, \\hat{\\beta})\n後驗機率分佈 p(\\alpha, \\beta)\n\n\n不確定性\n漸近標準誤 (假設樣本數無限大)\n精確的機率圖譜 (適用於 n=20 的小樣本)\n\n\nLD50 估計\n單一數值 (如 1.2 g/ml)\nLD50 的機率直方圖 (包含偏態與長尾)\n\n\n推論邏輯\n“如果我們重複實驗無限次…”\n“基於這次觀測到的數據，機率是…”\n\n\n風險解讀\nP 值、信賴區間\n毒性大於某閾值的具體機率\n\n\n\n\n\n\n\n\n\n\n\n\nBDA3 概念\n職業衛生 (OSH) 應用\n\n\n擾亂參數 (Nuisance Parameters)\n在估計平均暴露時，處理未知的變異係數 (GSD)\n\n\n常態模型 (t-分佈)\n分析小樣本 (n&lt;10) 的空氣採樣數據\n\n\n多項式模型 (Multinomial)\n分析肌肉骨骼症狀調查問卷 (症狀分級)\n\n\n生物檢定 (Logistic Regression)\n劑量-反應評估、基準劑量 (BMD) 設定\n\n\n後驗預測 (Posterior Predictive)\n驗證暴露模型是否能解釋現場的極端值",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#基礎建模與計算總結",
    "href": "0109CH3.html#基礎建模與計算總結",
    "title": "0109CH3 多參數模型",
    "section": "3.8 基礎建模與計算總結",
    "text": "3.8 基礎建模與計算總結\n（Summary of elementary modeling and computation）\n\n3.8",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0109CH3.html#總結",
    "href": "0109CH3.html#總結",
    "title": "0109CH3 多參數模型",
    "section": "3.8 總結",
    "text": "3.8 總結\n基礎建模與計算總結（Summary of elementary modeling and computation）\n\n在現實世界，特別是職業衛生領域，我們面對的數據結構絕非單一參數所能描述。當你走進一家化工廠，評估勞工接觸苯（Benzene）或焊接燻煙（Welding fumes）的風險時，你面對的暴露數據通常呈現對數常態分佈（Lognormal distribution）。這意味著，你至少同時面對兩個未知的參數：GM與GSD。\n\n\nA. 章節重點B. 職業衛生情境下的貝氏應用C. 現代計算工具的應用D. 從理論到實踐的轉化E. 學習建議\n\n\n\n在職業衛生中，當我們評估暴露風險時，我們最關心的往往是第 95 百分位數（95th percentile, X95）或是超越率（Exceedance Fraction），這些指標主要受平均暴露濃度影響，但也強烈依賴於變異程度。假設我們只想知道平均暴露濃度是否超過容許濃度（OEL），那麼變異數（Variance）對我們來說就是一個討厭參數（Nuisance Parameters）。\n在貝氏統計的框架下，我們有一個統一且優雅的解決方案：邊際化（Marginalization）。\n直觀意義極為深遠：我們對感興趣參數 \\theta_1 的推論，是考慮了所有可能的討厭參數值之後的加權平均。\n當樣本數 n 很小時（例如職業衛生中常見的 n=3），t 分佈的尾部非常厚，這導致了極寬的信賴區間（Credible Interval）。這解釋了為什麼在 Hewett et al. (2006) 的論文中提到，傳統統計方法在小樣本下的 95% 上限（UCL）會大得離譜，甚至超過 OEL 的 20 倍 。貝氏分析透過這種數學結構，誠實地告訴了我們：「基於這麼少的數據，你的不確定性就是這麼大。」\n\n\n\nHewett et al. (2006) 論文深度解析\n\n現在，讓我們將這些理論（常態模型、網格逼近、模擬推論）應用到你最關心的職業衛生領域。Hewett et al. (2006) 的經典論文《Rating Exposure Control Using Bayesian Decision Analysis》正是 BDA3 第三章理論的完美實踐。\n\n\n4.1 問題背景：小樣本的困境\n\n在工業衛生實務中，我們經常面臨一個嚴峻的現實：數據極度稀缺。對於一個包含 50 名工人的相似暴露群組（SEG），一年可能產生 12,500 個工作日的暴露。然而，受限於預算，IH 可能一年只能收集 6 到 10 個樣本，甚至更少。這僅佔母體的 0.08% 。\n如果你使用傳統頻率學派的方法（例如計算 95% 信賴區間的上限 UCL），當樣本數 n=3 時，由於 t 分佈的尾部極厚，計算出的 UCL 可能會是容許濃度（OEL）的 20 倍以上。這導致決策癱瘓：數據告訴你「可能沒事，也可能超標 20 倍」，這對風險管理者來說毫無用處。\n\n\n\n4.2 貝氏解決方案：引入先驗與常態模型\n\nHewett 的方法直接對應 BDA3 Section 3.2 的常態模型，但做了一個關鍵的改變：引入訊息先驗（Informative Prior）。\n\n\n數據模型與參數空間\n\n暴露數據 X 通常服從對數常態分佈，取對數後 Y = \\ln(X) 服從常態分佈 N(\\mu, \\sigma^2)。這正是 BDA3 3.2 節的標準模型。\n\n參數 \\mu 對應職業衛生中的 幾何平均數的對數（ln GM）。\n參數 \\sigma 對應職業衛生中的 幾何標準差的對數（ln GSD）。\n\nHewett 將參數空間限制在一個「現實」的範圍內，例如 GSD 通常在 1.5 到 4.0 之間。這本身就是一種弱訊息先驗，排除了數學上可能但物理上不合理的極端變異數。\n\n\n\n先驗分佈的構建（The Prior）\n\n這是該方法的精髓。Hewett 提倡利用 IH 的「專業判斷（Professional Judgment）」來構建先驗分佈。\nIH 根據工廠的通風控制、原料毒性、操作頻率等，主觀判斷該暴露情境屬於「高度控制」還是「控制不佳」。\n這種定性的判斷被轉化為 (\\mu, \\sigma) 參數空間上的機率分佈。例如，如果你認為控制很好，你的先驗機率密度就會集中在低 \\mu 和低 \\sigma 的區域。這對應了 BDA3 中提到的「訊息先驗」可以壓制小樣本帶來的巨大不確定性。\n\n\n\n似然函數（Likelihood）與後驗計算\n\nHewett 使用的計算方法本質上就是 BDA3 Section 3.7 的 網格逼近法。\n\n他將 (\\text{GM}, \\text{GSD}) 的空間劃分為網格。\n計算每一組 (\\text{GM}, \\text{GSD}) 生成觀測數據的似然機率。\n將先驗網格與似然網格相乘，得到後驗網格。\n\n這完全是 Section 3.7 Bioassay 範例在職業衛生領域的再現，只是參數從 (\\alpha, \\beta) 變成了 (\\text{GM}, \\text{GSD})。\n\n\n\n\n4.3 決策分析：暴露等級分類\n\nHewett 的模型最終輸出不是一個單一的數值（如 mean），而是一個決策機率分佈。他將暴露情況分為五個等級（AIHA Exposure Categories），基於真實的第 95 百分位數（X95）與 OEL 的比值 ：\n\n\n\n\n\n\n\n\n\n\n暴露等級 (Category)\n描述 (Description)\n統計定義 (True X95 relative to OEL)\n建議行動 (Action)\n\n\nCategory 0\n可忽略 (Negligible)\nX_{95} \\le 1\\% \\text{ OEL}\n無需行動\n\n\nCategory 1\n高度控制 (Highly Controlled)\n1\\% &lt; X_{95} \\le 10\\% \\text{ OEL}\n一般危害通識\n\n\nCategory 2\n控制良好 (Well Controlled)\n10\\% &lt; X_{95} \\le 50\\% \\text{ OEL}\n化學品特定危害通識\n\n\nCategory 3\n受控 (Controlled)\n50\\% &lt; X_{95} \\le 100\\% \\text{ OEL}\n暴露監測、醫學監護\n\n\nCategory 4\n控制不佳 (Poorly Controlled)\nX_{95} &gt; 100\\% \\text{ OEL}\n立即改善工程控制、佩戴呼吸防護具\n\n\n\n\n決策輸出範例：\n經過貝氏計算後，我們得到的不是「X95 小於 10 ppm」，而是：「有 80% 的機率屬於 Category 2，有 15% 的機率屬於 Category 3，有 5% 的機率屬於 Category 4」。\n這種機率性的陳述（Probabilistic Statement）直接呼應了 BDA3 Section 3.8 中「透過後驗分佈來總結推論」的原則。這讓管理者能夠依據風險的機率進行決策，而不是被傳統統計中巨大的 UCL 嚇得無所適從。\n\n\n\n\n\nExpostats 與進階模擬 (Lavoué et al., 2019)\n\n隨著計算能力的提升，我們從 Hewett 時代的網格法進化到了現代的 MCMC（Markov Chain Monte Carlo）。Expostats 工具代表了 BDA3 第三章概念在現代計算環境下的極致應用。\n\n\n\n1 從網格到 MCMC\n\nExpostats 使用 JAGS（Just Another Gibbs Sampler）作為計算引擎。這對應了 BDA3 後續章節（第 11 章）的內容，但其核心模型依然是第三章的常態模型。\nMCMC 的優勢：當模型變得更複雜（例如引入分層結構或處理設限數據）時，網格法會遇到「維度詛咒（Curse of Dimensionality）」。MCMC 允許我們在高維空間中高效抽樣。\n這正是 Section 3.8 預示的未來：從簡單的解析/網格計算，轉向通用的模擬算法。\n\n\n\n2 處理設限數據（Censored Data）：貝氏方法的殺手鐧\n\n在職業衛生中，我們經常遇到「未檢出（Non-detects, NDs）」的數據，即濃度低於偵測極限（LOD）。這是典型的左設限（Left-censored）數據。\n傳統方法：常使用 LOD/2 或 LOD/\\sqrt{2} 替換 ND 值。這在統計上是有偏誤的（Biased）。\n貝氏方法（Expostats）：利用貝氏推論，將這些未檢出的數值視為參數（Parameters）而非固定的數據。在 MCMC 抽樣過程中，演算法會根據截斷的對數常態分佈，自動「填補（Impute）」這些 ND 值。\n這體現了 BDA3 的核心哲學：將所有未知量（包括缺失數據）都視為機率變數進行處理。Expostats 能同時處理左設限（&lt;x）、右設限（&gt;x）和區間設限（[a, b]），這在理論上是處理 ND 數據的最佳解（Theoretically Optimal）1。\n\n\n\n3 關鍵指標的計算：超標率與 P95\n\nExpostats 關注兩個核心指標，這兩個指標都是參數 \\mu 和 \\sigma 的函數：\n\n\n超標率（Exceedance Fraction）：暴露濃度超過 OEL 的機率。\n\n\\theta = P(X &gt; \\text{OEL} | \\mu, \\sigma)\n\n第 95 百分位數（P95）：\n\nX_{95} = \\exp(\\mu + 1.645\\sigma)\n\n\n\n在貝氏框架下，我們不需要進行複雜的誤差傳播計算。我們只需要在 MCMC 的每一次迭代中，利用抽出的 (\\mu^{(l)}, \\sigma^{(l)}) 計算出對應的 \\theta^{(l)} 和 X_{95}^{(l)}。重複成千上萬次後，我們就直接得到了這兩個指標的完整後驗分佈。\n這正是 Section 3.7 生物檢測範例中 LD50 計算邏輯的直接延伸：Simulate, then summarize。\n\n\n\n4 過度暴露風險（Overexposure Risk）\n\nExpostats 引入了一個強大的概念：超度暴露風險。這是指「真實的 P95 大於 OEL」的後驗機率。\n\nP(\\text{True } X_{95} \\ge \\text{OEL} | \\text{Data})\n\n這是一個直接回答管理者問題的機率：「這個工作環境不合格的機率是多少？」如果這個機率大於 30%（或 5%），我們就判定為控制不佳。這種直接的機率陳述比頻率學派的 p-value 或信賴區間更直觀、更具行動導向 。\n\n\n\n\n\n\nOH 應用的對照表\n\n\n\n\n\n\n\nBDA3 Section 3.8 核心概念\n職業衛生暴露評估應用 (Hewett / Expostats)\n\n\n多參數模型 (Multiparameter Model)\n暴露分佈由 GM (μ) 和 GSD (σ) 共同決定，缺一不可。風險決策同時依賴這兩個參數。\n\n\n討厭參數 (Nuisance Parameters)\n我們關心的是 P95 或超標率（主要受 μ 影響但包含 σ），σ 的不確定性必須被邊際化考慮進去。t 分佈的使用反映了這種不確定性。\n\n\n先驗資訊 (Prior Information)\n利用 IH 的「專業判斷」或「歷史數據」構建 Informative Prior，解決小樣本 (n&lt;10) 帶來的決策困境。\n\n\n模擬與推論 (Simulation as Inference)\n不再依賴查表找 UCL，而是透過 Monte Carlo (MCMC) 模擬生成 P95 的後驗分佈，直接計算「超標風險機率」。\n\n\n計算策略\n從早期的網格逼近（Hewett 的圖表）進化到現代的 MCMC 採樣（Expostats 的 JAGS 引擎）。\n\n\n\n\n\n\n\n直面不確定性：職業衛生的數據往往是骯髒且稀缺的。不要試圖用傳統統計去掩蓋這種不確定性（例如只報一個點估計值）。貝氏方法教導我們誠實地面對不確定性，並利用先驗知識來縮小它。\n動手實作：不要只看公式。試著用 R 語言重現 Section 3.7 的 Bioassay 網格法。一旦你親手寫出那幾行程式碼，你會發現「後驗分佈」不再是抽象的概念，而是一個你可以存取、排序、畫圖的陣列。這將為你理解 Expostats 的運作原理打下堅實基礎。\n理解模型假設：無論是 BDA3 的常態模型還是 Hewett 的決策分析，都假設數據服從（對數）常態分佈。在應用這些工具前，務必檢查你的數據是否符合這個假設（例如透過 Q-Q plot，Expostats 裡有提供）。\n擁抱模擬：當你看到積分符號時，試著在腦海中將其轉化為「加權平均」或「蒙地卡羅模擬」。這會讓你更容易理解像 p(μ∣y) 為什麼會變成 t 分佈這樣的抽象概念。\n\n\n透過理解 Section 3.8 的建模與計算摘要，並將其與 Hewett 的決策框架及 Expostats 工具連結，你已經站在了現代職業衛生統計學的制高點。這是一套能讓你在資料極度缺乏的惡劣環境下，依然能做出科學、理性且保護勞工健康的強大工具。\n\n\n(參考文獻整合說明) 本報告深度整合了 Bayesian Data Analysis (Gelman et al.) 第三章的核心理論 ，並結合了 Hewett et al. (2006) 關於貝氏決策分析在暴露評估的應用 ，以及 Lavoué et al. (2019) 關於 Expostats 工具與設限數據處理的現代方法 。所有引用的概念與數據均來自於這些權威文獻，以確保報告的學術嚴謹性與實務參考價值。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "3.多參數模型"
    ]
  },
  {
    "objectID": "0112CH4.html",
    "href": "0112CH4.html",
    "title": "0112CH4 漸近理論與非貝氏方法的連結",
    "section": "",
    "text": "Asymptotics and connections to non-Bayesian approaches",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "4.漸近理論"
    ]
  },
  {
    "objectID": "0112CH4.html#事後分佈的常態近似",
    "href": "0112CH4.html#事後分佈的常態近似",
    "title": "0112CH4 漸近理論與非貝氏方法的連結",
    "section": "4.1 事後分佈的常態近似",
    "text": "4.1 事後分佈的常態近似\n\n1. 核心觀念2. 數學意義？3. 職業衛生EA案例4. 留意陷阱5.OHS實務6. 職業衛生EA應用7. 小結\n\n\n\n當樣本數 (n) 足夠大時，事後分佈 p(\\theta|y) 會趨近於一個常態分佈（Normal Distribution），其中心點位於後驗眾數（Posterior Mode），變異數則由該點的曲率（Curvature）決定。\n在職業衛生中，我們常說「數據會說話」。當你收集的暴露監測數據夠多時，數據的聲音會大過你原本的主觀判斷（先驗分佈 Prior），而且這時我們對真實風險的不確定性，會呈現一個漂亮的「鐘形曲線」。\n不管你原本信什麼： 除非你的先驗極端到認為某件事「絕對不可能發生」（機率為 0），否則隨著監測數據增加，事後分佈都會收斂到同一個結果。\n計算變簡單： 因為它變成了常態分佈，我們就不需要跑複雜的模擬（如 MCMC），只要算出「平均值」和「標準差」，就能快速掌握風險範圍。\n\n\n\n\n\n泰勒展開式（Taylor series expansion）與二次近似（Quadratic approximation）？\n假設我們在評估某化學工廠的「苯」暴露濃度平均值（這是參數 \\theta）。\n\n\n眾數 \\hat{\\theta} (The Mode)\n\n這是事後分佈機率最高點，代表在考慮了現有數據後，最有可能的真實暴露濃度。\n在大樣本下，這通常非常接近傳統統計（頻率學派）算出的最大概似估計值（MLE）。\n\n觀測資訊量 I(\\hat{\\theta}) (Observed Information)\n\n陡峭的鐘形： 代表數據非常一致且充足，我們對這個評估結果非常有信心，變異數（不確定性）很小。\n扁平的鐘形： 代表數據雖然指出了方向，但我們還是不太確定，變異數（不確定性）很大。\n\n近似公式的實務意義\n書中公式：p(\\theta|y) \\approx N(\\hat{\\theta}, [I(\\hat{\\theta})]^{-1})\n\n真實暴露濃度的分佈 \\approx 常態分佈（中心點在最可能的值，寬度是資訊量的倒數）。\n應用： 這意味著在數據量大時，我們可以用簡單的加減乘除（像算信賴區間那樣）來報告貝氏結果，這對向工廠管理層解釋非常方便。\n\n\n\n\n\n\n情境： 你在監測一個高風險的焊接作業區，想知道「錳」的幾何平均濃度 (GM)。\n狀況 A：小樣本 (n=3)\n\n這是我們最常遇到的情況。這時 4.1 節的理論通常不適用。事後分佈可能歪七扭八（偏態），或是受你選的先驗（Prior）影響很大。如果你這時硬套用常態近似，可能會嚴重低估高暴露的風險，導致工人失去保護。\n\n狀況 B：大數據/連續監測 (n=1000)\n\n現在很多工廠裝設了即時感測器 (Real-time sensors)，數據量極大。\n此時無論你一開始覺得這工廠乾淨或髒，事後分佈都會變成一個很窄的常態分佈。\n這告訴我們，當我們擁有大數據時，貝氏統計與傳統統計（如 t-test）的結果會幾乎一樣。貝氏的優勢在於解釋力（我們可以直說：「真實濃度有 95% 機率落在這裡」），而不在於數值上的巨大差異。\n\n\n\n\n\n\n參數邊界問題 (Edge Cases)：\n\n暴露濃度不可能為負值。常態分佈是對稱的，左尾巴會延伸到負無限大。\n如果你評估的物質濃度很低（接近 0 ppm），使用「常態近似」可能會算出「95% 信賴區間下限是 -0.5 ppm」這種荒謬結果。\n解決方案： 這也是為什麼我們在職業衛生中，習慣對數據取 Log (對數) 後再分析。在 Log 尺度上的常態近似（即 Lognormal），更符合物理現實。\n\n尾端風險 (Tail Risk) 被低估：\n\nＥＡ往往關注的是極端值（例如：95th percentile 暴露是否超過 OEL）。\n常態近似在「中心」很準，但在「尾巴」可能不準。如果真實分佈稍微有一點厚尾（Heavy tail），常態近似會讓你誤以為發生極端高暴露的機率很低。\n\n區分評估目標：常態近似理論於職業衛生數據（通常經 Log 轉換）時，\n\n如果你要算 GM (中位數趨勢)：\n\n\\text{GM} = \\exp(\\hat{\\mu}_{\\log})\n可以直接使用 \\exp 轉換，且估計結果與變異數無關（獨立）。\n\n如果你要算 AM (長期暴露風險/總劑量)：\n\n\\text{AM} = \\exp(\\hat{\\mu}_{\\log} + 0.5\\hat{\\sigma}_{\\log}^2)\n警告： 不能只用 \\exp(\\hat{\\mu}_{\\log}) 當作平均濃度，那樣會嚴重低估工人的真實暴露風險！\n進階： 在這種情況下，雖然參數 \\mu 和 \\sigma 在數學上是獨立的，但在計算 AM 時，它們會「糾纏」在一起。這也是為什麼在小樣本下推估 AM 特別困難，通常建議使用完整的貝氏 MCMC 方法（如 Expostats 軟體），而非僅依賴簡單的近似公式。\n\n\n\n\n\n\n\n未知平均值與變異數的常態分佈：在職業衛生暴露評估中，我們面對化學品濃度數據（經對數轉換後通常呈現常態分佈），我們幾乎永遠都不知道兩個最重要的參數：\n\n\n\\mu ：真實的平均暴露濃度（這決定了工人的長期健康風險）。\n\\sigma ：製程的變異程度（這決定了忽高忽低的風險，也就是幾何標準差 GSD 的概念）。\n\n\n以下展示如何在大樣本下，用簡單的正態近似來同時推估這兩個傢伙。\n\n\n1. 參數的轉換\n\n問題： 標準差 \\sigma 必須是正數（\\sigma &gt; 0）。如果我们直接用常態分佈來近似 \\sigma，常態分佈的左邊尾巴會延伸到負數，這不符合物理現實。\n解法： 我們改為估計 (\\mu, \\log \\sigma)。\n\n\\mu 可以是負的（例如 0.01 ppm 取 log 後是負數）。\n\\log \\sigma 也可以是負的（當 \\sigma &lt; 1 時）。\n這樣我們就把參數的範圍拉開到全體實數軸 (-\\infty, \\infty)，常態近似的效果會好非常多。\n\n\n\n\n2. 數學核心：資訊矩陣 (The Information Matrix)\n\n觀察資訊矩陣 (Observed Information Matrix, I(\\theta))。這是一個 2 \\times 2 的矩陣，因為我們有兩個參數。\n\nI(\\theta) = - \\frac{d^2}{d\\theta^2} \\log p(\\theta|y)\n\n經過推導，在 \\hat{\\theta}（最大概似估計值，也就是樣本平均數 \\bar{y} 和樣本標準差 s）這一點，矩陣是對角化的：\n\nI(\\hat{\\theta}) = n \\begin{pmatrix} \\frac{1}{s^2} & 0 \\\\ 0 & 2 \\end{pmatrix}\n\n這告訴我們兩件驚人的事（職安衛重點）：\n\n\n對角線外是 0 (Independence)：\n\n這表示在大樣本下，我們對「平均值 \\mu」的估計，跟對「變異程度 \\sigma」的估計，彼此是獨立的 (asymptotically independent)。\n\n實務意義： 你算出的平均暴露濃度準不準，不會受到你對變異數估計準不準的干擾。我們可以分開來看這兩個風險指標。\n\n\n矩陣的反矩陣 (Inverse)：\n\n資訊矩陣的「倒數」就是事後分佈的「變異數」。\nVar(\\hat{\\theta}) = [I(\\hat{\\theta})]^{-1} = \\frac{1}{n} \\begin{pmatrix} s^2 & 0 \\\\ 0 & \\frac{1}{2} \\end{pmatrix}\n\n\n\n\n3. 最終結果\n\n依據上述矩陣，我們可以寫出兩個參數的近似分佈：\n\n\n(1) 平均值的近似分佈\n\\mu|y \\approx N(\\bar{y}, s^2/n)\n\n真實平均值 \\mu 的分佈，中心在樣本平均數 \\bar{y}，標準差是 s/\\sqrt{n}。\n職業衛生應用： 這就是我們熟悉的標準誤 (Standard Error)。這告訴我們，樣本越多 (n 大)，我們對平均暴露濃度的估計就越精準（鐘形越窄）。\n\n\n\n(2) 變異數（對數尺度）的近似分佈\n\\log \\sigma|y \\approx N(\\log s, 1/2n)\n\n真實變異程度的對數 (\\log \\sigma)，中心在 \\log s，變異數是 1/2n。\n職業衛生應用： 這公式告訴我們，要準確估計 GSD（變異程度），比估計平均值更難！ 注意那個係數，變異程度的不確定性主要只跟樣本數 n 有關。樣本數如果不夠大，你的 GSD 估計值會非常不可靠。\n\n\n\n\n\n\n\n情境：你在評估一家噴漆廠的甲苯暴露。你採集了 n=50 個樣本（屬於大樣本，適用本節理論）。\n數據經過 Log 轉換後：\n\n樣本平均數 \\bar{y} = 3.0 (對應幾何平均 GM \\approx 20 ppm)\n樣本標準差 s = 1.0 (對應幾何標準差 GSD \\approx 2.7，屬於高變異作業)\n\n平均濃度的不確定性：\n\n我們對 \\mu 的信心區間寬度取決於 s/\\sqrt{50} = 1/7.07 \\approx 0.14。這很小，表示我們很確定平均濃度就在 3.0 附近。\n\n變異程度的不確定性：\n我們對 \\log \\sigma 的信心區間寬度取決於 \\sqrt{1/(2 \\times 50)} = \\sqrt{0.01} = 0.1。\n在職業衛生中，我們最怕的是 95th percentile (P95) 超標。\n\nP95 的公式通常是：\\mu + 1.645 \\sigma。\n\n這個範例告訴我們，因為 \\mu 和 \\sigma 是漸進獨立的，我們可以用簡單的誤差傳播公式，把上述兩個變異數合併，快速算出 P95 的信賴區間。\n這在沒有電腦跑 MCMC 的年代（或是你在現場只有計算機時），是評估「最壞情況」是否超標的強大工具。\n\n\n\n\n\n這教會我們三件事：\n\n\n轉換參數： 用 \\log \\sigma 讓近似更準確。\n獨立性： 數據夠多時，平均值和變異數的估計互不干擾。\n公式簡單： 只要知道樣本數 n 和樣本標準差 s，你就能立刻算出你對「製程變異程度」掌握了多少信心。\n\n這就是貝氏統計在大樣本下展現的優雅：它證明了傳統統計學的直覺在數據充足時是正確的。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "4.漸近理論"
    ]
  },
  {
    "objectID": "0112CH4.html#section",
    "href": "0112CH4.html#section",
    "title": "0112CH4 漸近理論與非貝氏方法的連結",
    "section": "4.5",
    "text": "4.5",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "4.漸近理論"
    ]
  },
  {
    "objectID": "0112CH4.html#大樣本理論-large-sample-theory",
    "href": "0112CH4.html#大樣本理論-large-sample-theory",
    "title": "0112CH4 漸近理論與非貝氏方法的連結",
    "section": "4.2 大樣本理論 (Large-sample theory)",
    "text": "4.2 大樣本理論 (Large-sample theory)\n\n只要數據夠多，貝氏估計就一定會找到真相。\n\n\n1. 樣本數重要？2. 一致性 (Consistency)3. 漸近常態性 (Asymptotic Normality)4. 我們離「大樣本」有多遠？5. 小結\n\n\n\n我們常被質疑：『貝氏統計都要設一個先驗（Prior），那結果不就是主觀的嗎？\n一致性 (Consistency)： 只要樣本夠多，不管你先驗怎麼設（只要不是太離譜），我們最終都會收斂到唯一的、真實的那個暴露值。\n漸近常態性 (Asymptotic Normality)： 當樣本夠多時，事後分佈一定會變成常態分佈，而且其寬度（不確定性）完全由數據本身決定。」\n\n\n\n\n\n如果真實的參數值是 \\theta_0（例如某工廠真實的苯暴露平均濃度是 5 ppm），隨著樣本數 n \\to \\infty，事後分佈的機率質量會全部集中在 \\theta_0 這一點的一個極小鄰域內。\nOHS實務應用：\n\n情境： 假設有一個工廠，雖然我們還沒去測，但你主觀覺得它很安全（先驗設很低）。\n發生什麼事： 隨著我們開始進場做暴露評估，採集了 10 個、50 個、100 個樣本，如果真實情況其實很危險，數據的力量會把你原本「安全」的信念推翻。\n結論： 貝氏方法具有「自我修正」的能力。只要持續監測，錯誤的先驗終究會被大量的數據導正。這就是科學的客觀性。\n\n\n\n\n\n\n這部分證明了為什麼事後分佈會變成鐘形曲線。\n當樣本無限大時，我們的事後分佈 p(\\theta|y) 與一個以真實值 \\theta_0 為中心的常態分佈之間的「距離」會趨近於零。\n關鍵數學核心：Fisher Information (費雪資訊量)\n\nJ(\\theta) = E \\left[ \\left( \\frac{d}{d\\theta} \\log p(y|\\theta) \\right)^2 \\right]\n\n這是衡量「一個樣本能提供多少關於未知參數的情報」的指標。\nOHS：\n\n有些監測方法很粗糙（比如目視判斷粉塵濃度），其 Fisher Information 很低，你可能需要幾千次觀察才能確定濃度。\n有些監測方法很精密（比如直讀式儀器加上實驗室分析），其 Fisher Information 很高，每一個數據都能大幅縮減不確定性。\n大樣本理論告訴我們：均值事後分佈的標準差（不確定性），大約等於 1/\\sqrt{n J(\\theta)}。 樣本數 n 越大，或者單一樣本資訊量 J 越大，我們對暴露評估的信心就越精確。\n\n\n\n\n\n\n大樣本假設 n \\to \\infty，但現實中我們只有 n=6。這有什麼意義？\n\n\n收斂速度 (Rate of Convergence)：\n\n理論證明收斂速度是 1/\\sqrt{n}。這意味著，要讓信賴區間（不確定性）縮小一半，你需要增加 4 倍 的樣本量。\n當老闆問：「為什麼我們測了 10 個樣本覺得不夠，你要我測 40 個？」你可以用這理論回答：「老闆，因為數學告訴我們，精確度是用樣本數的平方根在提升的，這是數學鐵律。」\n\n先驗的影響力邊界\n\n理論說樣本無限大時先驗不重要。反過來說，樣本有限時，先驗很重要。\n這正好證實了在職業衛生小樣本評估（SEG 只有 3-5 人）中，為什麼我們需要使用 「知情先驗 (Informative Prior)」（例如引用同業數據、Expostats 的演算法）。因為我們還沒達到「大樣本境界」，所以我們必須依賴專業判斷來彌補數據的不足。\n\n\n\n\n\n\nOHS人員最關心的「採樣策略」與「樣本數規劃」問題，適當思維如下：\n\n信心的來源： 數學證明了，只要持續收集數據，貝氏分析一定會給出正確的暴露評估結果（一致性）。\n常態的必然： 大數據下，風險分佈趨向常態是必然的。這讓我們在處理海量數據（如大數據監測）時，可以用簡單的統計模型來篩選高風險群。\n實務的警惕： 雖然理論保證了最終的勝利，但在還沒到達「大樣本」的途中（也就是我們日常工作的狀態），我們必須謹慎選擇先驗，因為這時候數據還不夠強大到能完全主導結果。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "4.漸近理論"
    ]
  },
  {
    "objectID": "0112CH4.html#定理的反例",
    "href": "0112CH4.html#定理的反例",
    "title": "0112CH4 漸近理論與非貝氏方法的連結",
    "section": "4.3 定理的反例",
    "text": "4.3 定理的反例\n(Counterexamples to the theorems)\n\n如果你模型設錯了，數據再多也會帶你往懸崖衝。\n在某些特定的結構下，更多的數據並不會導致正確的結論，甚至會收斂到錯誤的值。這對於我們設計採樣策略（Sampling Strategy）至關重要。\n\n\n1. 識別性不足的模型2. 參數隨樣本數增加3. 混疊 (Aliasing)4. 真實值在邊界上5. 尾部風險小結\n\n\n(Underidentified models)\n\n如果模型中的參數無法被數據唯一確定，似然函數（Likelihood）不會形成一個尖峰，而是形成一個「平坦的山脊」。這時，無論數據多少，事後分佈都不會收斂到一個點，而是由先驗分佈（Prior）決定結果。\n想像你在解方程式 A + B = 10。只有這一個數據，A 可以是 1，B 是 9；A 也可以是 5，B 是 5。你永遠不知道 A 和 B 到底是多少。\nOHS實務：\n\n生物偵測（Biomonitoring）中的混淆來源。假設你在測量尿液中的代謝物濃度（Y），這個濃度來自兩個源頭：\n\n工廠暴露（\\theta_{job}）\n生活背景，如抽菸或飲食（\\theta_{home}）\n\n模型：Y \\sim N(\\theta_{job} + \\theta_{home}, \\sigma^2)\n\n如果你只收集工人的尿液數據（Y），卻沒有去調查他們回家的生活習慣（沒有獨立測量 \\theta_{home}），那麼無論你測了 1,000 個工人的尿液，你永遠無法區分「這家工廠很髒（\\theta_{job} 高）」還是「這群工人很愛吃燒烤（\\theta_{home} 高）」。\n\n在這種情況下，貝氏分析的結果完全取決於你一開始「猜」背景濃度是多少（先驗）。如果你猜錯了，結果就全錯。這提醒我們：如果沒有區分源頭的數據，不要妄想靠統計軟體拆解風險。\n\n\n\n\n\n(Number of parameters increasing with sample size)\n\n當數據量 n 增加時，如果未知參數的數量也跟著 n 等比例增加，最大概似估計（MLE）和貝氏估計可能會失效（不一致性）。\n通常我們認為數據越多，參數估計越準。但如果每多一個數據，就多一個未知數要解，你的資訊量其實並沒有累積，反而被稀釋了。\nOHS實務：\n\n個別勞工暴露評估 vs. 相似暴露群 (SEG)。\n假設你有 100 個工人，你給每個人都測了 2 次暴露濃度（n=200）。你想知道這個製程整體的變異程度（\\sigma^2）。\n\n錯誤模型： 你把每個工人的平均暴露（\\mu_i）都當作一個獨立的、不相關的參數。\n隨著工人數量增加，你需要估計的 \\mu_i 也越來越多（100 個工人就有 100 個 \\mu）。\n後果： 數學證明，在這種情況下估計出來的變異數 \\sigma^2 會嚴重偏差（通常是低估的一半或偏差），而且永遠不會修正回來。\n\n這就是為什麼現代職業衛生統計（如 Expostats, BDA3 第 5 章）都要用 「階層模型 (Hierarchical Models/Random Effects)」。我們必須假設這些工人的 \\mu_i 來自同一個母群體（Population Distribution），這樣才能在大樣本下得到正確的變異數估計。千萬不要把每個工人都當作完全獨立的個體來硬算。\n\n\n\n\n\n\n當似然函數有對稱性時（例如兩個參數互換，結果一樣），事後分佈會出現多個峰值（Multimodal）。這時「正態近似」完全失敗，因為正態分佈只有一個峰。\nＯＨＳ實務：\n\n混合暴露群體（Mixture Models）。假設你的一個 SEG (相似暴露群) 其實分成了兩派：一半的人有戴防護具（低暴露），一半的人沒戴（高暴露），但你記錄數據時忘記標記誰是誰了。\n當你用貝氏模型去跑「雙峰分佈」時，模型會告訴你：「有一群平均是 10 ppm，另一群是 100 ppm」。但是模型分不清楚 「群組 A 是 10」 還是 「群組 B 是 10」（標籤置換問題）。\n\n這時事後分佈長得像駝峰，如果你硬要用 4.1 節的「常態近似」去算一個總平均值，你會得到一個位於 55 ppm 的平均值，但實際上工廠裡根本沒有人暴露在 55 ppm（大家都在 10 或 100）。平均值在這種情況下毫無意義，甚至會誤導職災預防策略。\n\n\n\n\n(True value on the boundary)\n\n如果真實參數位於參數空間的邊緣（例如 \\theta=0 且限制 \\theta \\ge 0），正態近似會失效，因為正態分佈是對稱的，會延伸到邊界之外。\nOHS實務：\n\n零暴露或完全合規 (Zero Exposure)。有些化學物質在製程中是完全密封的，真實洩漏率可能是 0\n當我們採樣時，可能測到幾個 “Non-detect” (ND)。如果我們試圖估計平均濃度 \\mu：\n\n真實 \\mu = 0。\n但正態近似會試圖畫一個鐘形曲線包住 0。這意味著它會預測有 50% 的機率濃度是負的（這在物理上不可能），或者它會被迫截斷，導致對 95% 上限（UCL）的估計完全錯誤。\n\n處理極低濃度或大量 ND 的數據時，4.1 的常態近似公式不能用。必須使用專門處理截斷數據（Censored Data）的模型（如 Tobit model 或 BDA3 中的插補法），否則你會算出荒謬的「負濃度」安全區間。\n\n\n\n\n\n(Tails of the distribution)\n\n即便樣本數很大，正態近似通常在分佈的中心（平均值附近）很準，但在尾巴（極端值） 部分往往不準。\nOHS實務：\n\n這是職安衛最痛的點：P95 (95th Percentile)。我們做暴露評估，最關心的不是「平均每個人吸多少」，而是「最倒楣的那個人吸多少」（P95）。\nBDA3 在這裡警告我們：雖然大樣本理論保證了平均值的估計是常態的，但它並沒有保證極端值（尾部機率） 的估計也是準的。\n如果真實的暴露分佈是 「厚尾的 (Heavy-tailed)」（例如偶爾會有一次大洩漏，發生率低但濃度極高），標準的正態近似會嚴重低估這種極端事件發生的機率。\n\n千萬別只看平均值的信賴區間就覺得天下太平。對於高風險化學品，我們必須檢查數據是否有厚尾特性（Outliers），並考慮使用 t-分佈或其他更穩健的模型，而不是盲目相信常態假設。\n\n\n\n\n\n「統計學的大樣本理論像是『自動駕駛』，在平直的公路上（標準模型）它可以開得很好。\n但本節某些情況—數據來源混雜、參數太多、真實值是零、或是關注極端風險—就像是險峻的山路。\n在這些情況下，自動駕駛（常態近似）會失靈。身為專業人員，你必須手動介入（使用更精細的階層模型、截斷模型），否則就會翻車。」",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "4.漸近理論"
    ]
  },
  {
    "objectID": "0112CH4.html#貝氏推論的頻率學派評估",
    "href": "0112CH4.html#貝氏推論的頻率學派評估",
    "title": "0112CH4 漸近理論與非貝氏方法的連結",
    "section": "4.4 貝氏推論的頻率學派評估",
    "text": "4.4 貝氏推論的頻率學派評估\nFrequency evaluations of Bayesian inferences\n\n職業安全衛生（OSH）法規與傳統訓練，大都是建立在「頻率學派（Frequentist）」的基礎上（例如：t 檢定、95% 信賴區間）。當你開始推廣貝氏統計時，最常被傳統派挑戰的問題就是：\n\n「你算出來的那個貝氏區間，真的能代表 95% 的信心嗎？還是只是你自己主觀覺得有 95%？」\n\n這一節就在教我們：如何用傳統統計的標準（頻率特性），來檢驗貝氏模型的品質。\n\n\n1. 核心觀念2. 關鍵指標一：區間覆蓋率3. 關鍵指標二：點估計的偏差與變異4. 如何進行評估？5. 小結\n\n\n\n雖然貝氏推論是基於「給定數據下的參數機率（Posterior）」，但我們仍然可以問：如果我們重複使用這個貝氏方法處理很多組不同的數據，它的長期表現如何？這就是頻率評估（Frequency evaluation）。\n我們可以用頻率學派的指標（如覆蓋率 Coverage、偏差 Bias）來確保我們的貝氏模型不是在「亂猜」，而是具有客觀的可靠性。\n\n\n\n\n(Coverage of Posterior Intervals)\n\n定義：一個 100(1-\\alpha)\\% 的貝氏區間，其頻率覆蓋率是指在多次重複實驗中，該區間包含真實參數值 \\theta 的比例。\nOHS實務：\n\n假設你用 Expostats（貝氏軟體）計算某個相似暴露群（SEG）的 P95（第 95 百分位數）是否超標。軟體給你一個「95% 貝氏可信區間 (Credible Interval)」。\n\n理想狀態（校準良好）： 如果你對 100 個不同的 SEG 做分析，這 100 個算出來的區間，應該大約有 95 個會把「真實的 P95」包在裡面。這代表你的先驗分佈（Prior）設得很好，模型很準。\n校準不良（Overconfident）： 如果 100 次裡面，只有 50 次包住真值，代表你的模型「過度自信」（區間太窄了）。這在職安上很危險，因為你會誤以為風險很低，實際上可能已經超標。\n校準不良（Conservative）： 如果 100 次裡面，有 99 次都包住真值，代表你的區間「太寬、太保守」。雖然安全，但可能導致企業花冤枉錢做不必要的改善。\n\n好的貝氏模型，其「主觀信心」應該要等於「客觀頻率」。這就是校準 (Calibration) 的概念。\n\n\n\n\n\n(Bias and Variance of Point Estimates)\n\n在小樣本下，貝氏統計比傳統統計好用。\n傳統統計追求「不偏估計 (Unbiased Estimator)」，即長期的平均值要等於真值。但貝氏估計（通常是後驗平均值或中位數）往往是「有偏的 (Biased)」，因為它會受到先驗（Prior）的拉扯。\nOHS實務（小樣本救星）：\n\n「偏差」不一定是壞事。\n\n情境： 只有 3 個樣本 (n=3)，數值為 10, 12, 100 (極端值)。\n傳統方法 (MLE)： 平均值會被那個 100 拉得非常高。雖然數學上這是「不偏」的，但單次估計的誤差（Variance）極大，結果很不穩定。\n貝氏方法 (With Prior)： 如果我們有一個合理的先驗（例如：根據過去經驗，濃度不太可能超過 50），貝氏估計會把那個 100 稍微往回拉（Shrinkage effect）。\n結果： 雖然貝氏估計「偏」了一點（Bias），但它大幅降低了變異（Variance）。總體誤差（MSE = Bias² + Variance）反而比傳統方法更小！\n\n\n「在職業衛生常見的小樣本數據中，我們寧願要一個『稍微有點偏差但很穩定』的貝氏估計，也不要一個『理論上不偏但忽大忽小』的傳統估計。」\n\n\n\n\n\n模擬實驗 (Simulation studies)\n\n既然真值 \\theta 通常是未知的，我們怎麼知道覆蓋率好不好？答案是：模擬 (Simulation)。\n實務操作：\n\n這就是驗證任何暴露評估工具（如 IHSTAT, Expostats）的標準流程。\n\n創造虛擬世界： 用電腦生成 1,000 組假數據，假設我們知道真實的幾何平均數 (GM) 是 5 ppm。\n套用模型： 把這 1,000 組數據丟進你的貝氏模型去算。\n檢查答案： 看看算出來的 1,000 個區間，有多少個真的包含了 5 ppm？\n結論： 如果包含率接近 95%，你就可以大聲跟老闆或勞檢員說：「我的這個貝氏模型經過頻率學派驗證，是準確可靠的！」\n\n\n\n\n\n\n\n\n貝氏與頻率不衝突： 我們用貝氏方法「產生」解答，但可以用頻率學派的方法來「檢查」解答的品質。\n95% 的承諾： 一個好的貝氏分析，它的「95% 可信區間」在長期使用下，應該要有 95% 的機會抓到真值。這叫「校準」。\n小樣本優勢： 透過引入先驗資訊（Prior），貝氏估計能在小樣本情況下，犧牲一點點準確度（Bias），換取大幅度的穩定性（Lower Variance）。這對只有 3-6 個樣本的暴露評估至關重要。",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "4.漸近理論"
    ]
  },
  {
    "objectID": "0112CH4.html#其他統計方法的貝氏詮釋",
    "href": "0112CH4.html#其他統計方法的貝氏詮釋",
    "title": "0112CH4 漸近理論與非貝氏方法的連結",
    "section": "4.5 其他統計方法的貝氏詮釋",
    "text": "4.5 其他統計方法的貝氏詮釋\nBayesian interpretations of other statistical methods\n\n許多傳統（頻率學派）的統計方法，其實可以被視為貝氏分析的「特例」或「近似」。\n\n\n1. 最大概似估計2. 不偏估計量3. 信賴區間4. 排列檢定與隨機化檢定5. 交叉驗證小結\n\n\n(Maximum Likelihood Estimates, MLE)\n\n傳統統計中最常用的點估計方法是 MLE（找出讓數據出現機率最大的參數值）。 從貝氏觀點來看，MLE 等同於「均勻先驗 (Uniform Prior)」下的「後驗眾數 (Posterior Mode)」。\nOHS實務：\n\n情境： 你用軟體算出一組噪音數據的平均數 (GM) 是 85 dBA。這個數字通常就是 MLE。\n貝氏詮釋： 這代表你假設這家工廠的噪音「可能是 0 到無限大之間的任何值，且機率都一樣平等」（這就是均勻先驗）。\n「當你在用 MLE 時，你其實已經是在做貝氏分析了，只是你默認了一個『我對這工廠一無所知』的先驗條件。但如果你明明知道這是一台剛保養好的新機器，卻還裝作一無所知，這就是 MLE 的弱點——它浪費了你的專業知識。」\n\n\n\n\n\n(Unbiased Estimates)\n\n頻率學派非常強調「不偏性 (Unbiasedness)」，即在無限次抽樣中，估計值的平均要等於真值。 從貝氏觀點來看，不偏估計量通常近似於「後驗平均值 (Posterior Mean)」（特別是在大樣本或平坦先驗下）。\nOHS實務：\n\n情境： 我們要評估勞工的長期平均暴露濃度 (Long-term Average)，以預防慢性病。\n衝突點： 頻率學派會為了追求「不偏」，有時會算出很奇怪的數字（例如變異數很大）。但貝氏學派不在乎「無限多次重複採樣的平均有沒有對準」，貝氏在乎的是「針對這一次採樣，誤差越小越好」。\n\n不偏估計（頻率派）： 像是一個散彈槍射手，雖然子彈散得很開，但所有彈孔的中心點正中紅心。\n貝氏估計： 像是一個狙擊手，雖然瞄準點稍微偏了一點點（因為受先驗影響，這叫偏差 Bias），但所有子彈都打在非常集中的一個小點上（低變異 Variance）。\n\n在職業衛生樣本很少（n=3~5）的情況下，我們寧願要貝氏的「穩定」，也不要頻率派的「不偏但亂跳」。\n\n\n\n\n\n(Confidence Intervals)\n\n傳統的 95% 信賴區間，其定義非常饒口：「如果重複做 100 次實驗，有 95 個區間會包住真值」。 但在數據量足夠且使用非資訊先驗時，95% 信賴區間的數值，幾乎等同於 95% 貝氏可信區間 (Credible Interval)。\nOHS實務：\n\n當職安人員算出「95% 上限 (UCL) 是 10 ppm」時，他們心裡通常想的是：「有 95% 的機率，真實濃度小於 10 ppm」。\n傳統統計學家會跳出來說：「錯！真值只有一個，機率不是 1 就是 0，不能這樣解釋！」\n貝氏的救贖： 4.5 節告訴我們，只要沒有強烈的先驗衝突，你可以大膽地用貝氏的方式去解釋傳統的信賴區間。\n以前那種『直覺』的機率解釋法，在貝氏理論下終於合法化了。傳統信賴區間其實就是貝氏區間的一種特例。所以，盡管放心地說『我有 95% 的信心』吧！」\n\n\n\n\n\n(Permutation and Randomization Tests)\n\n這是無母數統計常用的方法，透過重新洗牌數據來檢定顯著性。 貝氏詮釋認為，這與「可交換性 (Exchangeability)」的概念密切相關。如果我們認為數據的順序不影響結果（即數據是可交換的），那麼這種檢定結果通常會與貝氏結果一致。\nＯＨＳ實務：\n\n情境： 比較「早班」與「晚班」工人的暴露是否有差異，但數據分佈很奇怪（不是常態）。\n貝氏觀點： 如果你的先驗認為「早班和晚班在本質上是一樣的」（Null Hypothesis），那麼隨機重新分配數據後的結果，就是你對差異程度的後驗分佈。\n\n請參考後面的範例\n\n\n\n\n(Cross-validation)\n\n把數據分成兩半，一半建模型，一半測準確度。 貝氏觀點將其視為「預測分佈 (Predictive Distribution)」的一種評估方式。\nＯＨＳ實務：\n\n應用： 當我們建立了一個預測模型（例如：用化學品使用量推估空氣濃度），我們很怕模型「過度擬合 (Overfitting)」。\n貝氏方法非常強調「預測下一個數據點」的能力（Posterior Predictive Check）。交叉驗證其實就是在模擬這個過程。如果你算的 P95 連現有的數據都抓不住，那就別拿去預測未來了。\n\n\n\n\n\n\n貝氏統計並不是要推翻過去 30 年學的東西。\n以前用的 MLE、信賴區間、不偏估計，其實都是貝氏統計在『沒意見（無資訊先驗）』或『大數據』下的特例。\n學習貝氏統計，並不是要否定過去，而是要『擴充』你的工具箱。\n\n當你有大數據時，貝氏跟傳統方法結果一樣（殊途同歸）。\n但當你只有 3 個樣本，或者你有很強的專業判斷（強先驗）時，傳統方法會卡住，而貝氏方法能帶你突圍\n\n這就是為什麼我們要升級到貝氏統計的原因。」\n\n\n\n\n\n\n4.6 範例：Wilcoxon Rank Test 的貝氏詮釋\n\n1. 為什麼我們要用「排序（Rank）」？2. 從「檢定」變成「機率」3. 改善工程有沒有效？4. OHS實務5. 小結\n\n\n\n在職業衛生暴露評估中，我們常遇到兩種狀況：\n\n\n分佈不是常態： 數據歪得很厲害，取了 Log 還是很怪。\n未檢出 (Non-detects, ND)： 儀器測不到數值，只知道「小於 0.01 ppm」。\n\n\n這時候我們不能算平均值（因為 ND 是未知數），我們只能「排大小」。\n\n既然 ND 最小，就排第 1 名。\n0.05 ppm 排第 2 名。\n…依此類推。\n\nWilcoxon 檢定就是完全只看「排名」，不看具體數值的傳統方法。它用來回答：「SEG A的暴露是否比 SEG B 高？」\n\n\n\n\n\n傳統觀點（頻率學派）：\n\n計算一個統計量 U（看 A 組贏了 B 組幾次），然後查表得到 p-value。如果 p &lt; 0.05，就說「拒絕虛無假設」，判定兩組有顯著差異。\n\n缺點： p-value 很難向老闆解釋。說「拒絕虛無假設」老闆聽不懂。\n\n\n貝氏觀點：\n\nWilcoxon 檢定的統計量，對應到一個非常直觀的參數 \\alpha：\n\n\\alpha = \\Pr(y_1 &gt; y_2)\n\n意思是：「如果你從第一組（改善前）隨機抽一個數據，再從第二組（改善後）隨機抽一個數據，前者大於後者的機率是多少？\n在標準的貝氏推導下（假設使用 Dirichlet process prior 等無母數先驗），Wilcoxon 統計量其實就是這個機率 \\alpha 的最佳估計值。\n\n\n\n\n\n\n讓我們用一個通風改善工程的例子來說明這個轉換。\n情境：你有改善前（Old）與改善後（New）的兩組苯暴露數據，樣本數都很少（各 5 個），而且有些是 ND。\n\nOld: 10, 12, 8, 20, 15 (ppm)\nNew: 2, 5, ND, 3, 8 (ppm)\n\n我們想知道：改善工程有效嗎？\n\n\nStep 1: 傳統 Wilcoxon 作法\n\n你會把它們混合排序，計算 U 值。\n結果可能給你一個 p-value = 0.004。\n報告方式： 「在顯著水準 0.05 下，改善前後有顯著差異。」\n\nStep 2: 貝氏詮釋 (4.5 節的精髓)\n\n不要只看 p-value，要看統計量背後的含義。\n我們可以計算兩組數據互相比較的「勝率」。\n\nOld 組有 5 個數據，New 組有 5 個數據，總共有 5 \\times 5 = 25 種配對組合。\n在這 25 種組合中，有多少次 Old &gt; New？\n(10 vs 2, 10 vs 5, … 一路比下來)\n\n假設經過計算，25 次裡面有 24 次舊的大於新的。\n\n比例 = 24/25 = 0.96。\n\n\nStep 3: 貝氏結論（給老闆的報告）\n\n\n這個 0.96 就是後驗機率的估計。你可以這樣說：\n\n「經由貝氏分析評估，我們有 96% 的信心 (Probability) 認為，這套新通風系統的暴露濃度會低於舊系統。」\n\n\n\n\n\n\n處理「未檢出 (ND)」的邏輯一致性\n\n傳統統計處理 ND 很頭痛（要補 1/2 LOD 還是 \\sqrt{2} LOD？）。但在這個秩檢定（Rank Test）的貝氏觀點下，ND 就是「肯定比有數值的低」。\n\\Pr(\\text{Detected} &gt; \\text{ND}) = 1。\n這讓我們在處理含有很多 ND 的清潔製程數據時，依然能算出一個「改善機率」。\n\n溝通力\n\n職災預防的決策者通常不是統計學家。\n\n你說：「Wilcoxon 檢定 p 小於 0.05」 \\rightarrow 老闆無感。\n你說：「數據顯示，隨便挑一天，新製程比舊製程安全的機率是 96%」 \\rightarrow 老闆立刻聽懂。\n\n\n\n\n\n\n\n「這個範例揭示了貝氏統計的包容性。即使是你過去最常用的『無母數檢定』，在貝氏眼中也有它的物理意義。\n它不再只是一個用來『拒絕』什麼的冰冷檢定，而是一個用來計算 『A 比 B 風險更高的機率是多少』 的實用工具。這將統計學從『假設檢定』轉化為了『風險量化』，這正是我們職業衛生暴露評估的核心目標。」",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "4.漸近理論"
    ]
  },
  {
    "objectID": "0112CH4.html#範例wilcoxon-rank-test-的貝氏詮釋",
    "href": "0112CH4.html#範例wilcoxon-rank-test-的貝氏詮釋",
    "title": "0112CH4 漸近理論與非貝氏方法的連結",
    "section": "4.6 範例：Wilcoxon Rank Test 的貝氏詮釋",
    "text": "4.6 範例：Wilcoxon Rank Test 的貝氏詮釋\n\n\n\n\n\n\n#### 4. OHS實務\n\n1.  處理「未檢出 (ND)」的邏輯一致性\n\n    -   傳統統計處理 ND 很頭痛（要補 1/2 LOD 還是 $\\sqrt{2}$ LOD？）。但在這個秩檢定（Rank Test）的貝氏觀點下，ND 就是「肯定比有數值的低」。\n\n    -   $\\Pr(\\text{Detected} &gt; \\text{ND}) = 1$。\n\n    -   這讓我們在處理含有很多 ND 的清潔製程數據時，依然能算出一個「改善機率」。\n\n2.  溝通力\n\n    -   職災預防的決策者通常不是統計學家。\n\n        -   你說：「Wilcoxon 檢定 p 小於 0.05」 $\\rightarrow$ 老闆無感。\n\n        -   你說：「數據顯示，隨便挑一天，新製程比舊製程安全的機率是 **96%**」 $\\rightarrow$ 老闆立刻聽懂。\n\n------------------------------------------------------------------------\n\n### 5. 小結\n\n-   「這個範例揭示了貝氏統計的包容性。即使是你過去最常用的『無母數檢定』，在貝氏眼中也有它的物理意義。\n\n-   它不再只是一個用來『拒絕』什麼的冰冷檢定，而是一個用來計算 **『A 比 B 風險更高的機率是多少』** 的實用工具。這將統計學從『假設檢定』轉化為了『風險量化』，這正是我們職業衛生暴露評估的核心目標。」\n:::",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "4.漸近理論"
    ]
  },
  {
    "objectID": "0118CH5.html",
    "href": "0118CH5.html",
    "title": "0118CH5 階層模型",
    "section": "",
    "text": "階層模式（Hierarchical Models）\n\n本章介紹如何把多個類似的實驗（或工廠、SEG）結合起來分析，這運用「借用力量（Borrowing Strength） 」。\n\n\n前言5.1 建構事前分佈5.2 可交換性與階層模式5.3 共軛階層模式的貝氏分析5.4 具可交換參數的常態模式5.5 平行實驗5.6 整合分析5.7 變異數參數的「弱資訊事前分佈」5.9 節習題\n\n\n\n1.1 為什麼需要Hierarchical Model？\n\n在傳統統計或簡單的貝氏分析中，我們通常只關注單一參數。但在現實世界，很多數據是有結構的。許多統計應用涉及多個參數，這些參數在問題結構上是相關聯的。\n例：研究多個醫院的心臟病治療效果，我們預期這些醫院的參數（存活率 \\theta_j）應該彼此相關，因為它們都是「醫院」這個母體的一份子。\n\n\n\n1.2 OHS觀點\n\n如果你要評估一家大型石化公司的 「苯暴露風險」，該公司有 10 個不同的廠區（Plant A, Plant B…）。貝氏思維如下：\n\n\n完全獨立（No Pooling）：如果你認為每個廠區完全無關，只用該廠區的 3 個樣本來評估，誤差會非常大（不確定性太高）。\n完全合併（Complete Pooling）：如果你認為每個廠區都一模一樣，把所有廠區的數據混在一起算一個平均值，你會忽略各廠區製程老舊程度、通風設備的差異（掩蓋了真實風險）。\n階層模式（Partial Pooling）：這是中庸之道。我們假設這些廠區的風險參數 \\theta_j 是來自同一個「母體分佈」。我們允許各廠區有差異，但利用整體數據來修正個別廠區的估計。\n\n\n\n1.3 運作原理\n\n母體分佈：我們假設個別單元（如各廠區）的參數 \\theta_j，是從一個共同的母體分佈抽樣出來的。\n超參數（Hyperparameters）：這個母體分佈本身的參數（例如母體的平均值與變異數），我們稱為「超參數」。\n優勢：階層模式可以容納足夠多的參數來擬合數據，同時透過母體分佈來約束參數，避免「過度擬合（Overfitting）」。這對於數據稀缺的職業衛生評估至關重要。\n\n\n\n\n\n\n當我們手邊有「歷史數據」時，如何利用它們來為當前的ＳＥＧ暴露實態建立一個合理的 事前分佈。（參數化）\n\n\n1. 分析單一暴露並參考歷史數據\n\n情境：我們要估計一個小實驗的參數 \\theta，利用類似的過去實驗（歷史數據）來建構事前分佈。我們假設：將「當前實驗」與「歷史實驗」視為來自同一母體的隨機樣本。\n\n\nＯＨＳ例：噪音作業的聽力損失率\n\n假設我們想評估 「當前」 某個新建沖壓工廠工人的聽力損失風險 \\theta_{71}（假設編號第 71 號）。\n\n現況數據：我們剛檢查了 14 位工人，發現 4 位有聽力異常（4/14）。\n歷史數據：我們手邊有過去 70 個類似工廠的聽力檢查紀錄。\n\n如果只看當前數據，異常率是 4/14 = 28.6\\%。但這個樣本太小，誤差很大。如果過去 70 個工廠的平均異常率只有 10%，我們是否該懷疑這 28.6% 只是運氣不好（抽樣誤差）？\n\n\n\n\n2. 利用歷史數據估計母體分佈（近似法）\n\n模型設定：\n\n假設每個工廠的異常人數 y_j 服從二項式分佈（Binomial）。\n每個工廠的風險機率 \\theta_j 服從 Beta 分佈（這是二項式的共軛事前分佈）。\nBeta 分佈有兩個參數 (\\alpha, \\beta)，這就是超參數。\n\n簡單估計法（非完全貝氏）：\n\n計算過去 70 個工廠的平均異常率和標準差。\n假設數據：平均值 0.136，標準差 0.103。\n利用公式反推 Beta 分佈的 \\alpha 和 \\beta。原文算出 (\\alpha, \\beta) = (1.4, 8.6) ，這代表「所有類似工廠」的風險分佈大概長這樣。(可參考BDA3 Appendix A 公式 ，Beta 分佈的平均值與變異數公式，使用動差法反推)\n\n應用於當前ＥＡ：\n\n將算出來的歷史分佈 Beta(1.4, 8.6) 當作 事前分佈。\n結合當前數據（4 人異常，10 人正常）。\n事後分佈：Beta(1.4+4, 8.6+10) = Beta(5.4, 18.6) 。\n結果：新的估計值（事後平均）是 0.223。\n比較：\n\n原始數據直接算：0.286 (28.6%)\n加入歷史經驗修正後：0.223 (22.3%)\n我們的解讀：因為歷史經驗告訴我們異常率通常較低，所以貝氏方法把那個偏高的 28.6% 往下拉了一點（Shrinkage，這就是平滑化或修正的效果）。\n\n\n\n\n\n3. 「簡單估計法」的問題\n\n問題一：雙重計算（Double Counting）：如果我們把那 70 個歷史工廠的數據拿來算出 \\alpha, \\beta，然後又回頭用這個 \\alpha, \\beta 去評估這 70 個工廠中的某一個，這樣數據被用了兩次，會高估精確度。\n問題二：忽略了不確定性：我們直接把 (\\alpha, \\beta) 鎖定為 (1.4, 8.6)，當作這就是真理。但實際上這兩個數字也是估計出來的，也有誤差。直接鎖定會讓我們低估了最終結果的不確定性。\n問題三：事前分佈應該是「看數據之前」就有的，怎麼會是看完數據後才算出來的？\n這些近似法的問題（缺點），顯示為什麼我們後面需要更進階的階層模式。\n\n\n\n4. 資訊結合的邏輯\n\n為什麼我們要把它們視為一個整體（Joint Distribution）？\n\n假設有兩個工廠（工廠 26 和工廠 27），它們的數據一模一樣（例如都是 20 人中有 2 人異常）。\n連結性：如果你後來得知工廠 26 的真實風險其實很低（例如 \\theta_{26}=0.1），這會不會影響你對工廠 27 的看法？\n答案：會！ 因為這暗示了這些工廠所屬的「母體環境」可能風險都偏低。既然工廠 26 和 27 很像，26 很低，27 應該也不高。\n結論：這兩個參數在事後分佈中應該是 相依的 (Dependent)，不能分開獨立分析。這就是階層貝氏模式的核心精神。\n\n\n\n\n\n小結\n\n學會用「歷史數據」來建立「事前分佈」。\n\n保留舊資料：過去的暴露監測數據，是評估新製程或新工廠極為寶貴的資產。\n修正小樣本偏差：當新採樣數不足時，利用歷史分佈（階層架構）可以避免我們被極端值誤導。\n注意限制：近似法的「先算出固定超參數」的方法只是近似解，它可能低估了風險的不確定性。\n接下來：考慮「超參數不確定性」，我們必須將 \\alpha, \\beta 也視為隨機變數來處理。\n\n\n\n\n\n\n\n可交換性 (Exchangeability)」 是貝氏階層模式的核心基礎，也是我們在職業衛生現場決定「能不能把這群人的數據合在一起分析？」的關鍵判斷標準。\n身為一名職業衛生專家，你測了 A 廠區的苯濃度，能不能拿來預測 B 廠區？或者，把 A、B、C 三個廠區的數據全部混在一起算個總平均合不合理？這就是 「可交換性」 在探討的問題。\n\n\n1. 「可交換性」？\n\n在統計學上，如果你對一組參數 \\theta_1, \\dots, \\theta_J（例如 10 個不同工廠的平均暴露濃度）沒有任何額外的資訊可以用來區分它們，那麼這些參數對你來說就是「對稱」的。\n定義：如果我們把這些參數的編號（標籤）隨意互換（Permutation），你的機率模型（Joint Probability Distribution）都不會改變，那我們就稱這些參數是 「可交換的」。\n\n簡單說：在還沒看到數據之前，我們「無法區分」工廠 A 和工廠 B 誰的風險比較高。既然分不出來，就假設它們來自同一個「超級母體 (Superpopulation)」，擁有共同的特性。\n\n\n\n\nＯＨＳ例：\n\n假設你有 5 個焊接工人（Worker A, B, C, D, E）。\n可交換性：如果你只知道他們都是「焊接工」，沒有其他資訊，那你應該假設他們的暴露風險分佈是可交換的。你不會預設立場覺得 Worker A 一定比 Worker B 吸入更多燻煙。\n不可交換：如果你知道 Worker A 是在「通風良好的戶外」工作，而 Worker B 是在「密閉狹窄空間」工作，這時候他們就 「不可交換」 了。因為你有額外資訊（通風條件）來區別他們。當然ＲＰＥ使用也是。\n\n\n\n2. 無知是可交換 (Ignorance implies exchangeability)\n\n課本名言：「通常，我們知道得越少，就越能自信地宣稱可交換性。」。如果你對這些工廠一無所知，你唯一的選擇就是把它們視為相似的群體來建模。\n骰子比喻：給你一顆骰子，你還沒擲之前，你會假設 6 個面出現的機率是一樣的（對稱、可交換）。但如果你仔細測量發現骰子重心偏向某一邊（有了額外資訊），這種對稱性就被打破了。亦即，有額外資訊，便打破可交換性。\n\n\n\n4. 條件可交換性 —實務上\n\n現實中，我們很少真的「一無所知」。我們通常知道工廠的大小、製程、通風設備等。如果有了這些資訊，還能用階層模式嗎？當然可以！這就是 「條件可交換性」。\n作法：我們把已知的差異（如：通風好壞、製程種類）當作 共變數 (Covariates, x_i) 放進模型裡。\n公式概念： p(\\theta_1, \\dots, \\theta_J | x_1, \\dots, x_J)\n\n雖然 \\theta（暴露風險）本身不可交換，但在「考慮了通風條件 x」之後，剩下的殘差或不確定性是可交換的。\n\n\n\n\n5. OHS應用：SEG (相似暴露群) 的劃分\n\n劃分 SEG (Similar Exposure Group) 的理論基礎：\n\n我們為什麼要把工人分組？就是要讓組內的工人 「在統計上是可交換的」。\n如果一組裡面混了「操作員」和「維修員」，他們的暴露型態不同，就違反了可交換性。\n解決方法：分層（Hierarchical）或分組。把操作員設為一組，維修員設為一組。在每一組內部，我們假設工人是可交換的，然後針對每一組建立各自的階層模型。\n\n\n\n\n6. 對可交換性模型的反對意見\n\n很多人會批評：「每個工廠、每個工人都是獨一無二的，你怎麼可以假設他們來自同一個分佈（可交換）？」。\n回應：是的，參數 \\theta_j 確實各不相同（就像每個人身高不同）。但 「可交換」並不是假設參數數值相同，而是假設它們背後的「產生機制」是相似的。\n除非你有具體的證據（數據或知識）能區分它們，否則「可交換性」是處理不確定性最合邏輯的假設。這就跟做回歸分析一樣，你也是假設殘差符合某個共同分佈。\n\n\n\n7. 事後預測分佈 (Posterior Predictive Distributions)\n\n在階層模式中，我們有兩層參數：\n\n\n個別參數 \\theta_j（例如：某個特定工廠 A 的平均暴露濃度）。\n超參數 \\phi（例如：全公司所有工廠的整體分佈特性）。\n\n\n基於此，有兩種我們可能有興趣的預測情境 ：\n\n\n情境一：預測工廠Ａ的未來\n\n目標：預測未來的數據 \\tilde{y}，基於現有的參數 \\theta_j。\n作法：直接使用我們已經算出來的該工廠事後參數 \\theta_j，去模擬新的數據。\nＯＨＳ例：\n\n你是某化工廠的職安衛人員，你已經對「維修組 (SEG A)」進行了多次苯暴露採樣，算出他們的平均風險 \\theta_{A}。\n問題：下週維修組要進行大修，我想預測他們下週的採樣數據 \\tilde{y} 可能會分佈在哪裡？會不會超過容許濃度 (PEL)？\n應用：這是用來監控既有製程是否維持在受控狀態，因為我們已經有這個組的資料，所以預測會比較精準（不確定性較小）。\n\n\n\n\n情境二：預測新工廠或新 SEG的狀況\n\n定義：這是一個全新的單元（如新工廠或新的 SEG），我們完全沒有它的數據，但它屬於同一個母體（Superpopulation）。\n目標：預測一個新的參數 \\tilde{\\theta}，以及其對應的數據 \\tilde{y} 。\n作法（兩步走）：\n\n先根據超參數 \\phi（母體分佈），抽出一個新的參數 \\tilde{\\theta}（模擬這個新工廠可能的平均風險）。\n再根據這個 \\tilde{\\theta}，模擬出具體的測量數據 \\tilde{y}。\n\nＯＨＳ例：\n公司蓋了一座「新廠房」，製程跟舊廠房（歷史數據）很像，但還沒開始運轉，也還沒採樣。\n問題：環安衛經理問你：「根據舊廠的經驗，你預估這個新廠未來的暴露濃度大概是多少？需不需要預先加裝更強的通風設備？」\n應用：這就是推估未採樣區域的風險。\n關鍵差異：這裡的不確定性會比情境一大很多！因為我們連這個新廠是「優等生」還是「劣等生」都不知道，所以必須把「母體的變異（工廠間的差異）」全部考慮進去。\n\n\n\n\n概念比較\n1. 情境一：針對「既有」工廠 (Existing Experiment)\n\n流程：拿現有的 \\theta_j (已知) \\rightarrow 預測 \\tilde{y} (未來數據)\n\n2. 情境二：針對「全新」工廠 (New Experiment)\n\n流程：拿 \\phi (母體經驗) \\rightarrow 預測 \\tilde{\\theta} (新廠體質) \\rightarrow 預測 \\tilde{y} (新廠數據)\n\n\n\n\n在職業衛生暴露評估報告中，區分這兩者非常重要：\n\n合規性判斷 (Compliance Testing)：通常是用情境一。我們想知道「這群已經在工作的勞工」，明天會不會超標。\n風險管理與設計 (Risk Management & Design)：通常是用情境二。當我們在規劃新產線，或者面對一個還沒預算去採樣的SEG時，我們利用階層模式的「母體分佈」來大膽假設它的風險範圍。\n「事後預測分佈 (Posterior Predictive Distributions)」 是我們做決策、寫評估報告時最有用的產出。簡單來說，我們辛苦建立模型、算出參數，最終目的通常不是為了看參數本身，而是為了回答老闆或勞檢員的問題：「明天這名勞工的暴露會不會超標？」 或者 「那個還沒採樣的新廠區，風險大概是多少？」\n這就是「預測」的功能。在階層模式中，預測分為兩種截然不同的情境。\n\n\n\n\n\n小結\n\n判斷合併的標準：當你想把不同來源的採樣數據（不同廠區、不同班別）放在一起分析時，請先問：「這些來源是可交換的嗎？」\n\n如果是（無區別資訊），大膽使用階層模式，借用數據力量。\n如果不是（有明顯差異），請將差異因子（如區域、製程）納入模型（用回歸或分組），做成 「條件可交換」 的階層模型。\n\n小樣本的救星：可交換性允許我們假設所有工廠都來自同一個「超級母體」。這讓我們在評估某個樣本數極少（n=3）的工廠時，可以合理地「參考」其他工廠的數據，避免因運氣不好而做出極端錯誤的風險判斷。\n下一步：如何透過 貝氏定理 來計算那個共同的「超級母體」參數（也就是超參數）。\n\n\n\n\n\n(Bayesian analysis of conjugate hierarchical models)\n\n我們對母體長相也不完全確定，所以我們要給母體參數（超參數）也建立一個機率分佈。\n\n\n第一階段：解析推導\n\n1. 拆解聯合機率分佈\n\n我們的目標是求出 聯合事後分佈 p(\\theta, \\phi | y)。其中：\n\n\\theta = (\\theta_1, ..., \\theta_J) 是各工廠的風險率。\n\\phi = (\\alpha, \\beta) 是超參數（母體特性）。\ny 是數據。\n\n公式拆解如下： p(\\theta, \\phi | y) \\propto \\underbrace{p(\\phi)}_{\\text{超事前分佈}} \\times \\underbrace{p(\\theta|\\phi)}_{\\text{母體分佈}} \\times \\underbrace{p(y|\\theta)}_{\\text{概似函數}}\n\n\n\n2. 「超參數」的邊際分佈\n\n先不管個別工廠 \\theta，只看數據 y 告訴我們關於母體 \\phi 的什麼資訊。\n課本使用了一個條件機率公式的變形來求 p(\\phi | y) ：\n\np(\\phi | y) = \\frac{p(\\theta, \\phi | y)}{p(\\theta | \\phi, y)}\n\n分子：是我們上面列出的聯合分佈。\n分母：是假設 \\phi 已知的情況下，\\theta 的事後分佈（這在共軛模式下很容易算，就是 Beta 分佈）。\n個等式對 任何 \\theta 值都成立。所以我們不需要做複雜的積分，只要把分子分母代入消去，就能得到只剩下 \\phi 的函數。\n\n\n\n3. 找出條件事後分佈\n\n一旦我們搞定了 \\phi（母體），個別工廠 \\theta 的分佈 p(\\theta | \\phi, y) 就很簡單了。因為在共軛模式下（Beta-Binomial），只要 \\alpha, \\beta 固定，\\theta_j 就是獨立的 Beta 分佈。\n\n\n\n\n\n第二階段：電腦模擬抽樣\n\n數學推導完後，我們得到了一個關於超參數 \\phi 的複雜函數（通常長得不規則）。我們怎麼從中抽樣呢？課本介紹了 Grid Method（網格法），這在參數很少（只有 \\alpha, \\beta 兩個）時非常有效。\n\n\n步驟 1：抽取超參數 \\phi\n\n建立網格：因為我們不知道 \\alpha, \\beta 是多少，我們在可能的範圍內撒下一張大網，例如在 \\log(\\alpha/\\beta) 和 \\log(\\alpha+\\beta) 的座標系上畫格子。\n計算機率：對網格上的每一個點，算出它的 p(\\phi | y) 值。\n抽樣：根據這些算出來的機率值，隨機抽取 1000 組 (\\alpha, \\beta)。這 1000 組就代表了我們對「母體長相」的不確定性。\n\n\n\n步驟 2：抽取參數 \\theta\n\n有了這 1000 組 (\\alpha, \\beta) 後，對於每一組，我們再去抽取個別工廠的 \\theta_j。\n公式：\\theta_j \\sim Beta(\\alpha + y_j, \\beta + n_j - y_j) 。\n因為我們做了 1000 次，所以每個工廠 \\theta_j 也會有 1000 個模擬值。\n\n\n\n\n步驟 3：預測未來\n\n如果有需要（如上一節提到的情境），我們可以再根據抽出來的 \\theta 去模擬未來的數據 \\tilde{y} 。\n\n\n\n\n第三階段：OHS實例應用\n\n1. 設定「超事前分佈 (Hyperprior)」\n\n我們要給 \\alpha, \\beta 設定什麼樣的事前分佈 p(\\alpha, \\beta)？\n例如我們工廠聽力損失的母體分佈一無所知，所以想設一個「無資訊 (Noninformative)」分佈。\n陷阱：如果你直接設 Uniform Prior（均勻分佈），數學上會導致積分發散（Improper Posterior），也就是算出無窮大，模型會壞掉。\n解法：課本建議使用一個特定的擴散型事前分佈： p(\\alpha, \\beta) \\propto (\\alpha + \\beta)^{-5/2}\n\n目的是讓數學積分能夠收斂，同時保持足夠的「平坦」，讓數據來說話。\n\n\n\n\n\n2. 結果比較：全貝氏 vs. 近似法\n\n點估計差不多：兩者算出來的平均風險 \\theta_j 差異不大。\n不確定性變大了：這是重點！全貝氏算出來的信賴區間（Posterior Interval）通常會比較寬。\n\n近似法 (5.1)：假設 \\alpha, \\beta 是固定的真理，忽略了我們其實不確定 \\alpha, \\beta 是多少。\n全貝氏 (5.3)：承認 \\alpha, \\beta 也有誤差，並將這層不確定性傳遞給了 \\theta_j。\n\n\n\n\n\n小結\n\n處理 「階層數據」 的黃金標準流程：\n\n\n不要太有自信：5.1 節的方法雖然快，但會讓你「過度自信（區間太窄）」。在評估致癌風險或工安事故率時，低估不確定性是危險的。全貝氏分析提供了更誠實的風險評估。\n網格法的直觀意義：想像你在地圖上找寶藏（母體參數）。你不知道確切位置，所以你在地圖上畫格子，算出每一格有寶藏的機率。最後你不是「選一個點」，而是「根據機率抓一把點」帶走。這就是由 p(\\phi|y) 抽樣的意義。\n收斂修正 (Shrinkage)：透過這個過程，樣本數少（n 小）的工廠，其風險評估會被強烈地拉向「母體平均」；樣本數多（n 大）的工廠，則會保留更多自己的特性。這自動平衡了整體經驗與個體數據。\n\n\n\n\n\n\n5.3 節（二項式分佈）處理的是「生病/沒生病」這類二分法數據，這節處理的就是職業衛生與工安領域最常見的「連續型數據」。\n化學暴露濃度（ppm, mg/m³）、噪音音量（dBA）、通風系統風速（m/s）、工時或作業頻率等，這些數據通常呈現常態分佈（或是經對數轉換後的對數常態分佈）。\n\n\n1. 數據結構與情境假設\n\n職業衛生情境：我們假設有 J 個不同的工廠（或 J 個不同的相似暴露群 SEG）。\n數據：第 j 個工廠有 n_j 個採樣數據 y_{ij}。\n假設：\n\n數據服從常態分佈：y_{ij} \\sim N(\\theta_j, \\sigma^2_j) 。\n已知變異數：為了簡化，本節假設採樣的變異數 \\sigma^2_j 是已知的（這在樣本數夠大時是合理的近似）。\n\n我們的目標是估計每個工廠真實的平均暴露濃度 \\theta_j。\n\n\n\n\n2. 部分合併 (The Problem of Pooling)\n\n在決定如何估計 \\theta_j 時，傳統統計常面臨兩難 ：\n不合併 (No Pooling)：\\hat{\\theta}_j = \\bar{y}_{\\cdot j}\n\n作法：只相信該工廠自己的採樣平均值。\n缺點：如果某個工廠只採了 2 個樣本（小樣本），結果剛好都很高，你就會誤判該工廠風險極高。這忽略了其他類似工廠的資訊。\n\n完全合併 (Complete Pooling)：\\hat{\\theta}_j = \\bar{y}_{\\cdot \\cdot}\n\n作法：假設所有工廠都一模一樣，把所有數據混在一起算總平均。\n缺點：這會掩蓋掉「髒工廠」與「乾淨工廠」的真實差異，導致對高風險廠區的警覺不足。\n\n階層模式 (Partial Pooling / Shrinkage)\n\n作法：加權平均。\n\\hat{\\theta}_j \\approx \\lambda_j \\bar{y}_{\\cdot j} + (1 - \\lambda_j) \\bar{y}_{\\text{all}}\n這就是本節的核心：利用母體分佈（\\tau^2）來決定要「拉」多少回來。\n\n\n\n\n\n3. 階層常態模式的架構\n\n我們建立兩層模型來執行上述的「部分合併」：\n第一層（採樣層）：每個工廠的平均值 \\bar{y}_{\\cdot j} 來自以 \\theta_j 為中心的常態分佈 。\n第二層（母體層）：這些工廠的真實參數 \\theta_j，是從一個「超級母體」抽出來的：\n\\theta_j \\sim N(\\mu, \\tau^2)\n\n\\mu：所有工廠的總平均暴露。\n\\tau：廠與廠之間的變異 (Between-group standard deviation)。這是關鍵參數！\n\n\n\n\n\n4. 貝氏分析：收斂效應 (The Shrinkage Effect)\n\n數學結果是 條件事後分佈的平均值。假設我們知道了母體的特性（\\mu, \\tau），那麼某個工廠 j 的修正後估計值 \\tilde{\\theta}_j 是 ：\n\n\\tilde{\\theta}_j = \\frac{ \\frac{1}{\\sigma_j^2}\\bar{y}_{\\cdot j} + \\frac{1}{\\tau^2}\\mu }{ \\frac{1}{\\sigma_j^2} + \\frac{1}{\\tau^2} }\n\n這是一個 「精確度加權平均 (Precision-weighted average)」。\n精確度 (Precision) 是變異數的倒數（1/\\text{Variance}）。變異越小，精確度越高，講話越大聲。\n加權這就像一場 拔河比賽：\n\n左邊選手：該工廠自己的數據 \\bar{y}_{\\cdot j}（力氣是 1/\\sigma_j^2，取決於樣本數多寡）。\n右邊選手：整個行業的平均值 \\mu（力氣是 1/\\tau^2，取決於廠間差異大小）。\n\n\n\n兩種極端情況：\n\n如果該工廠樣本數很多 (n_j 大，\\sigma_j 小)：左邊力氣大，結果 \\tilde{\\theta}_j 就會靠近自己的數據 \\bar{y}_{\\cdot j}。（數據夠多，我相信自己）。\n如果廠與廠之間差異很小 (\\tau 小)：右邊力氣大，結果 \\tilde{\\theta}_j 就會被強力拉向總平均 \\mu。（大家都差不多，你的極端值可能是誤差，我要把你修正回來）。\n\n\n這就是 收斂 (Shrinkage)：把不可靠的小樣本估計值，往母體平均的方向「拉」，以減少估計誤差。\n\n\n\n\n\n5. 處理超參數 \\tau\n\n在全貝氏分析中，我們必須算出 \\tau（廠間差異）的事後分佈 p(\\tau|y)。\n為什麼要算 \\tau？ 因為我們不知道這些工廠到底有多像。\\tau 越大，代表工廠間差異很大，我們就該少做一點收斂（Pooling）；\\tau 越小，代表工廠都很像，我們就該多做一點收斂。\n計算方法：課本推導出了一個公式 p(\\tau|y) ，這是一個關於 \\tau 的複雜函數。\n\n\n\n比較：貝氏方法 vs. 傳統 ANOVA\n\n課本特別提到，傳統的變異數分析 (ANOVA) 也可以估計 \\tau^2（透過 MS_B 和 MS_W）。但 ANOVA 有一個致命缺點：\nANOVA 的算式可能算出負的變異數 (\\hat{\\tau}^2 &lt; 0)！ 。這在物理上是不可能的（變異數必須是正的）。\n貝氏方法的優勢：我們計算的是 p(\\tau|y)，這個機率分佈自然地定義在 \\tau &gt; 0 的範圍內，永遠不會給出「負變異數」這種荒謬的結果。\n\n\n\n\n6. 小結\n\n在職業衛生暴露評估中，運用 5.4 節的流程如下：\n\n\n收集數據：取得 J 個工廠的採樣數據。\n模擬 \\tau：利用電腦計算 \\tau 的事後分佈（了解工廠間的異質性）。\n模擬 \\theta：對於每一個可能的 \\tau 值，算出各工廠的風險 \\theta_j（利用上述的加權公式）。\n得到結果：最終你會得到每個工廠風險的「機率分佈」，而不是一個死的數字。\n\n\n但你可能會問：「此節假設 \\sigma_j^2（採樣變異）是已知的，但在現場我根本不知道啊，我還要從數據裡估計它？」\n\n\n\n\n\n(parallel experiments in eight factories)\n\n讓階層模式在「過度樂觀（相信個別數據）」與「過度保守（只相信平均值）」之間，找到科學的決策依據。\n\n\n1. 8 個廠區的安全教育成效\n\n假設你是集團的職安衛總監，你在集團旗下的 8 個不同廠區（Factory A ~ H）推動了一項新的「危害預知訓練」。你想知道這個訓練到底有沒有效？能降低多少職災風險指數（或提升多少安全分數）？\n每所學校都進行了隨機對照試驗。\n\ny_j：該場教育訓練後的平均分數提升量（效果估計值）。\n\\sigma_j：該估計值的標準誤 (Standard Error)（已知，因為樣本數夠大）。\n\n各廠回報的數據（對應 Table 5.2 ）：\n\n\n\n\n\n\n\n\n\n\n廠區 (School)\n觀測到的成效 (yj​) (分數提升量)\n標準誤 (σj​) (測量不確定性)\n廠區狀況解讀\n\n\nA\n28\n15\n驚人的好！ 但誤差很大（可能該廠人數少或變異大）。\n\n\nB\n8\n10\n普普通通。\n\n\nC\n-3\n16\n變差了？ 訓練反而有害？但誤差也很大。\n\n\nD\n7\n11\n普通。\n\n\nE\n-1\n9\n沒效果。\n\n\nF\n1\n11\n沒效果。\n\n\nG\n18\n10\n看起來不錯。\n\n\nH\n12\n18\n好像有效，但很不確定。\n\n\n\n\n面對這張表，你會怎麼下結論？\nA 廠長會說：「我的訓練超有效！提升了 28 分！全公司都該學我！」\nC 廠長會很沮喪：「我們是不是做錯了什麼？怎麼反而退步了？」\n但身為職安衛及統計專家的你，看著那巨大的標準誤（例如 A 廠的 \\sigma_A=15），你心裡會打個大問號：A 廠真的有那麼好嗎？還是只是運氣好抽到了幾個聰明的工人？\n\n\n\n\n2. 傳統統計方法的困境\n\n方法一：個別估計 ( No Pooling)\n\n作法：完全相信每個廠區的報告。認為 A 廠就是提升 28 分，C 廠就是退步 3 分。\n問題：這忽略了「隨機誤差」。\n\nA 廠的 95% 信賴區間大約是 28 \\pm 2 \\times 15 = [-2, 58]。這範圍大到包含了 0。\n雖然 A 看起來很高，但在統計上我們很難說它跟其他廠有顯著差異。\n後果：你會錯誤地獎勵 A 廠長，並可能錯誤地懲罰 C 廠長，但其實這一切可能只是雜訊（Noise）。\n\n\n\n\n方法二：完全合併 (Complete Pooling)\n\n作法：假設這 8 個廠區本質上是一模一樣的（\\tau=0），把所有數據混在一起算一個總平均。\n計算：加權平均後，全公司的平均成效是 7.7 分，標準誤 4.1。\n問題：這假設太強了。\n\n它暗示 A 廠的真實成效就是 7.7，而不是 28。\n它完全抹殺了「A 廠可能真的教得比較好」的可能性。\n卡方檢定 (\\chi^2 test) 雖然沒有顯著拒絕「效果相同」的假設（因為誤差太大），但硬說所有廠區效果都一樣，並不符合科學直覺。\n\n\n\n\n\n\n3. 貝氏階層模式分析\n\n我們採用 5.4 節的常態階層模式：\n\n\n第一層：y_j \\sim N(\\theta_j, \\sigma_j^2) （採樣誤差）\n第二層：\\theta_j \\sim N(\\mu, \\tau^2) （廠區間的真實差異）\n第三層：對 \\mu 和 \\tau 設定無資訊事前分佈。\n\n\n步驟一：看看廠區間的差異 (\\tau) 到底有多大？\n\n我們先計算 \\tau（廠間標準差）的事後分佈 p(\\tau|y)。\n結果：分佈的高峰（Mode）在 0 附近，但也有一條長尾巴延伸到 10 甚至 20。\n解讀：這告訴我們，數據最支持「各廠效果其實差不多 (\\tau \\approx 0)」的假設，但也不排除「各廠間有顯著差異 (\\tau &gt; 0)」的可能性。貝氏分析保留了這種不確定性。\n\n\n\n步驟二：收斂效應 (Shrinkage) —— 修正後的真實成效\n\n利用電腦模擬，算出每個廠區 \\theta_j 的事後分佈中位數。\n讓我們看看 A 廠 發生了什麼事：\n\n原始數據 (y_A)：28\n貝氏修正後 (\\hat{\\theta}_A)：約 10\n發生了什麼？ 估計值被從 28 強力拉回到了總平均（約 8）附近。\n為什麼？ 因為 \\tau 估計值偏小（大家差異不大），加上 A 廠的測量誤差 \\sigma_A=15 很大（數據不可靠），所以模型告訴我們：「別太相信那個 28 分，它大概率是虛高，真實情況應該跟其他人差不多，稍微好一點點而已。」\n\n再看看 C 廠：\n\n原始數據 (y_C)：-3\n貝氏修正後 (\\hat{\\theta}_C)：約 6\n發生了什麼？ 被拉回了正值！\n為什麼？ 模型認為 C 廠不太可能真的那麼差（因為平均大家都有 8 分），那个 -3 分很可能是運氣不好測歪了。\n\n\n\n\n步驟三：回答問題\n\n現在你可以更有底氣地回答：\n\n\n「A 廠是不是最好的？」\n\n透過模擬計算 P(\\theta_A = \\max(\\theta))。\n結果顯示，雖然 A 的觀測值最高，但在考慮誤差後，A 廠真的是第一名的機率其實不大。\n事實上，A 廠真實成效大於 28 分的機率 不到 10% 。\n\n「這個訓練到底有沒有效？」\n\n看總體平均 \\mu 的分佈。大部分質量落在正值區間。\n結論：訓練普遍有效，平均提升約 8 分，但別指望能像 A 廠報告的那樣提升 28 分。\n\n\n\n\n\n\n小結\n\n不要被極端值騙了：在小樣本或高變異的職安數據中，那個表現最好（或最差）的單位，往往只是運氣最好（或最差）的，回歸均值是必然現象。\n保護基層：如果 C 廠長因為數據是 -3 而要被懲處，你可以用貝氏分析幫他辯護：「根據全公司的數據結構，C 廠的真實績效很可能也是正的，那個 -3 只是統計誤差。」這就是數據的正義。\n資源配置：不要看到 A 廠 28 分就投入所有預算去推廣 A 廠經驗。貝氏分析告訴你，A 廠的真實優勢可能沒那麼大。\n\n\n這就是階層模式的威力——它像一個穩重的智者，在眾人為極端數據歡呼或恐慌時，冷靜地告訴你：「別急，讓子彈飛一會兒，真實的情況通常比較中庸。」\n\n\n\n\n\n(Meta-analysis)\n\n期刊時常看到「Meta-analysis（整合分析）」這個詞，(例)通常是學者把過去幾十年關於「矽肺病風險」或「輪班工作與癌症」的所有研究蒐集起來，做一個大總結。\n在貝氏統計的眼中，整合分析其實就是階層模式的標準應用。我們把每一篇發表的論文（Study）視為階層模式中的一個「群組（Group）」或「實驗」，利用我們在 5.4 節學到的技術，將它們有機地結合起來。\n\n\n\n1. 什麼是整合分析？\n\nOHS例：防護具介入成效\n\n假設你想評估「全面配戴防護眼鏡能否降低眼部受傷率」，你蒐集了過去 20 年在不同國家、不同工廠做的 22 份研究報告。\nStudy 1：某小工廠，樣本 50 人，結論「沒差」。\nStudy 4：某大集團，樣本 3000 人，結論「顯著有效」。\n你的任務：給出一個綜合結論。到底有效沒效？如果我明天在一間新工廠實施，預期效果是多少？\n\n\n\n\n\n2. 數據前處理\n\n將「二分法」轉為「常態分佈」\n\n處理二項式數據是用 Beta 分佈，但在整合分析中，為了計算方便且能利用常態階層模式，我們通常會先做一個轉換。\n指標選擇：我們不直接比「受傷率差值」，而是用 「對數勝算比 (Log-odds ratio)」，記為 y_j 。\n\n如果 y_j &lt; 0：代表介入有效（死亡/受傷率降低）。\n如果 y_j = 0：代表沒效。\n如果 y_j &gt; 0：代表有害。\n\n常態近似假設：雖然原始數據是受傷人數（二項式），但當樣本數夠大時，這個算出來的對數勝算比 y_j 近似服從常態分佈： y_j \\sim N(\\theta_j, \\sigma_j^2)\n\n\\theta_j：第 j 個研究的真實效果。\n\\sigma_j^2：該研究的抽樣變異（由該研究的樣本數決定）。\n\n為什麼要這樣做？因為一旦轉成常態分佈，我們就可以直接套用 5.4 節 那套強大的「加權公式」了！\n\n\n\n\n\n3. 推論目的 (Goals of Inference)\n\n在整合這些研究時，我們有三種選擇，這對應到先前學到的概念：\n完全相同 (Complete Pooling)：假設這 22 個研究根本是在做同一件事，唯一的差別只是抽樣誤差。\n\nＯＨＳ觀點：假設美國化工廠的工安文化跟印度紡織廠的一模一樣。這顯然太武斷。\n\n完全無關 (No Pooling)：假設這些研究彼此毫無關係。Study 1 的結果對 Study 2 沒有任何參考價值。\n\nＯＨＳ觀點：這放棄了整合的意義，我們就不用做 Meta-analysis 了。\n\n可交換 (Exchangeable / Hierarchical Model)：這是貝氏的核心。我們承認各研究有差異（工廠環境不同、執行力度不同），但它們都在評估「同一個介入措施」，所以它們的效果 \\theta_j 來自同一個母體分佈。\n\n\n\n\n4. 分析結果：收斂 (Shrinkage)\n\n運用階層模式分析後，我們得到了各研究的修正後效果 \\theta_j。觀察課本 Table 5.4 的數據，你會發現熟悉的現象：\n\n\n\n大樣本研究 (如 Study 4)：原始數據標準誤很小 (\\sigma_j=0.14)。它的貝氏估計值跟原始數據幾乎一樣。它「定住」了整體趨勢。\n小樣本研究 (如 Study 2)：原始數據顯示效果超好 (Log-odds = -0.74，死亡率大幅下降)，但標準誤很大 (\\sigma_j=0.48)。貝氏分析把它「拉」回了總平均，修正後的估計值變成了 -0.40 左右。\n結論：那個看起來像奇蹟的 Study 2，很可能只是運氣好。階層模式幫我們過濾掉了這種雜訊。\n\n(圖示概念：森林圖 (Forest Plot)。原始數據的信賴區間長短不一，經過貝氏階層模式收斂後，所有估計值會向中心靠攏，且信賴區間通常會變窄，除了那些原本就極度不準確的小研究。)\n\n\n\n5. 對「未來」的預測\n\n這是 5.6 節對職業衛生專家最有價值的一段 。\n傳統的 Meta-analysis 往往只告訴你「平均效果 (Overall Mean, \\mu)」是多少。\n\n課本結果：平均效果 \\mu 的 95% 信賴區間是 [-0.37, -0.11]。\n解讀：看起來這個藥（或介入措施）整體來說是有效的，因為區間都小於 0。\n\n但是！ 如果你是要決定「是否在一間新工廠實施這個措施」，你看的不能只是平均值。你要看的是 「預測效果 (Predicted Effect, \\tilde{\\theta}_j)」。\n\n新研究的預測區間：[-0.58, 0.11]。\n驚人的發現：雖然平均來說有效，但這個預測區間包含了正值（0.11）。\n機率解釋：這代表雖然這措施平均有效，但在一個新環境下，它有 超過 10% 的機率 可能是無效甚至有害的（P(\\tilde{\\theta}_j &gt; 0) &gt; 10\\%）。\n\n\n\n\n這解釋了為什麼有些安全措施在 A 廠很成功，搬到 B 廠卻失敗。\n\n因為母體標準差 \\tau（異質性）存在。\n貝氏分析誠實地告訴你：「平均而言這是好主意，但別保證在你的廠一定有效。你仍有 10% 的風險會失敗。」\n這比單純給一個「平均有效」的結論，更能幫助管理者進行風險決策。\n\n\n\n\n\n小結\n\n整合分析即階層模式：不要被醫學術語嚇到，這就是把不同來源的 y_j 和 \\sigma_j 丟進我們在 5.4 節學的那個常態模型裡。\n標準誤 (\\sigma_j) 是權重：在整合文獻時，樣本數大（\\sigma_j 小）的研究講話比較大聲，模型會自動處理這件事，你不需要手動加權。\n關注 \\tau (異質性)：如果 \\tau 很大，代表各研究間差異懸殊，這時候「平均效果」意義不大，你要特別小心推廣到新環境的風險。\n預測未來的風險：如果要評估新專案，請務必看 Predicted Effect 的區間，而不是 Overall Mean 的區間。前者才包含了真實世界的不確定性。\n\n\n\n\n\n(Weakly informative priors for variance parameters)\n\n身為職業衛生專家，我必須特別強調: 「數據太少」 是常態。\n你可能只有 3 個 相似暴露群 (SEG) 的數據，或者只有 3 個 分廠的工安紀錄。當群組數量 J 很小（例如 J &lt; 5）時，你在軟體裡隨便選的一個「預設事前分佈」，可能會導致完全錯誤的風險評估結論。\n如何避開這個陷阱？（找我們 - 專家群😆？）\n\n\n\n1. 問題的根源：當 J 很小時，\\tau 很難算\n\n在階層模式中，\\tau 代表「群組間的標準差」（例如：廠與廠之間的差異程度）。\n如果你有 50 個工廠的數據，數據本身就足以告訴你 \\tau 是多少，事前分佈影響不大。\n但如果你只有 3 個工廠，數據提供的資訊非常少。這時候，你設定的事前分佈 p(\\tau) 就會強烈主導結果。\nOHS情境：你有 3 個工廠 (A, B, C)。\n\nA 廠平均暴露 80。\nB 廠平均暴露 82。\nC 廠平均暴露 78。\n\n問題：這三個廠的差異 (\\tau) 到底是多少？\n\n是差異很小 (\\tau \\approx 2)？\n還是其實差異可能很大，只是剛好抽到這三個接近的？\n\n因為只有 3 個樣本，數據很難排除「\\tau 其實很大」的可能性。\n\n\n\n\n2. 那些年，我們用錯的事前分佈\n(Common Noninformative Priors)\n\n課本檢討了幾種常見的「無資訊」事前分佈，並指出它們在小樣本下的危險性。\n\n\n(1) Inverse-Gamma (\\epsilon, \\epsilon) — 軟體的預設陷阱\n\n背景：在早期貝氏軟體（如 BUGS）中，這是變異數 \\tau^2 的標準預設值（為了數學計算方便，共軛特性。通常設 \\epsilon 為很小的數，如 0.001。\n問題：Inverse-Gamma 分佈在 0 的地方機率是 0。\n後果：它會強迫 \\tau 遠離 0。即使數據顯示這 3 個工廠其實一模一樣 (\\tau=0)，這個事前分佈也會強行告訴模型：「不！它們一定有差異！」\n職安衛影響：你會高估廠間差異，導致收斂效果 (Shrinkage) 變差，無法有效借用其他廠的數據來修正誤差。\n\n\n\n(2) Uniform on \\log(\\tau) —數學上的地雷\n\n作法：假設 \\log(\\tau) 是均勻分佈。\n問題：這會導致事後分佈無法積分（Improper Posterior），算出來的機率總和是無限大。這是數學上的死路，不能用。\n\n\n\n\n(3) Uniform on \\tau (0, A) — 8 個工廠時還可以，但 3 個就不行\n\n作法：假設 \\tau 在一個很寬的範圍（例如 0 到 100）是均勻分佈。\n表現：\n\nJ=8 (八所工廠)：表現不錯，結果合理 。\nJ=3 (三所工廠)：因為只有 3 個數據，無法限制 \\tau 的上限。事前分佈認為 \\tau=1000 的機率跟 \\tau=1 一樣高。結果事後分佈會有一個超級長甚至發散的右尾 (Right tail) 。\n\n職安影響：模型會誤以為廠間差異巨大，導致完全不進行收斂 (No Pooling)，退化成個別估計。\n\n\n\n\n3. 救星：弱資訊事前分佈 (Weakly Informative Priors)\n\n既然「完全無資訊」在小樣本會出事，我們就給它一點點資訊，這就是 「弱資訊 (Weakly Informative)」 的概念。\n\n\n什麼是「弱資訊」？\n\n我們雖然不知道確切的 \\tau，但根據物理或專業知識，我們知道它不可能大到離譜。\n例如：評估噪音暴露，廠與廠之間的平均分貝數差異，頂多是 10-20 dBA，不可能差到 1000 dBA。\n\n\n\n推薦選擇：Half-Cauchy 分佈 (或是 Half-t)\n\n課本強烈推薦使用 Half-Cauchy 分佈（只取正半邊的柯西分佈）來描述 \\tau 。\n特點：\n\n在 0 附近很平坦：允許 \\tau 很小（接受工廠間無差異的可能性），不像 Inverse-Gamma 那樣排斥 0。\n尾巴厚但收斂：它允許 \\tau 變大，但會給予輕微的約束，不讓它像 Uniform 那樣無限制地飄到無限大。\n設定方法：設定一個寬鬆的尺度參數 A（Scale Parameter）。例如設 A=25（大於我們預期的最大差異）。\n\n\n\n\n\n\n4. 實例：3 所學校的實驗\n\n課本為了證明這一點，特地把 8 所學校的數據刪減到只剩 3 所，模擬極端小樣本的情況 。\n\n\n\n實驗 A：使用 Uniform Prior\n\n結果：事後分佈的尾巴長到天邊去。\n解讀：模型說「這三間學校的差異可能高達幾百幾千分！」這顯然不合常理（SAT 總分才 800）。這導致估計完全失效。\n\n\n\n實驗 B：使用 Half-Cauchy Prior (Scale=25)\n\n結果：事後分佈很漂亮地收斂了，尾巴被壓下來了。\n解讀：模型說「雖然數據少，但我限制了差異不會大到離譜。」這樣的估計結果（收斂程度）遠比 Uniform 合理。\n\n\n\n小結\n\n這節是你在操作貝氏軟體（如 Stan, JAGS, 或 R packages）時的救命稻草：\n\n\n警惕小樣本 (J &lt; 5)：當你要合併分析的廠區、班別或 SEG 數量很少時，絕對不要使用軟體預設的 Inverse-Gamma（例如 dgamma(0.001, 0.001)）。這會毀了你的分析。\n物理限制是好朋友：利用你對職業衛生的專業知識（噪音、化學濃度的物理極限），為模型設定一個「弱資訊」的邊界。\n\n比如：設定 \\tau \\sim \\text{Half-Cauchy}(0, 25)。這是在告訴模型：「廠間差異大概在 25 以內，雖然我不確定，但請不要猜 1000。」\n\n檢查事後分佈圖：做完分析後，一定要把 \\tau 的分佈圖畫出來（像 Figure 5.9 那樣）。\n\n如果看到它在 0 的地方由高聳的尖峰變成 0（被推開），或者尾巴無限延伸，那就是事前分佈設錯了。\n\n\n\n有了階層模式，你不再只是看著幾個零星的採樣數據發愁，而是能整間公司的經驗，為每一個角落的勞工提供更精準的保護。這套工具是你從「數據記錄員」進階為「風險預測專家」的關鍵武器。\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "介紹Home",
      "基本概念",
      "5.階層模型"
    ]
  },
  {
    "objectID": "0118CH5.html#階層模型-..panel-tabset-.border",
    "href": "0118CH5.html#階層模型-..panel-tabset-.border",
    "title": "0118CH5 階層模型",
    "section": "階層模型 {.{.panel-tabset .border}}",
    "text": "階層模型 {.{.panel-tabset .border}}\n\n5.1 建構參數化的事前分佈 (Constructing a parameterized prior distribution)\n這一節的重點在於：當我們手邊有「歷史數據」時，如何利用它們來為當前的實驗建立一個合理的 事前分佈（Prior Distribution）。\n\n1. 分析單一實驗並參考歷史數據\n\n情境：我們要估計一個小實驗的參數 \\theta，利用類似的過去實驗（歷史數據）來建構事前分佈 6。\n數學假設：將「當前實驗」與「歷史實驗」視為來自同一母體的隨機樣本 7。\n\n\n\n🛡️ 職業衛生實例：噪音作業的聽力損失率\n假設我們想評估 「當前」 某個新建沖壓工廠（Current Experiment）工人的聽力損失風險 \\theta_{71}（假設編號第 71 號）。\n\n現況數據：我們剛檢查了 14 位工人，發現 4 位有聽力異常（4/14） 8。\n歷史數據：我們手邊有過去 70 個類似工廠（Historical Data）的聽力檢查紀錄 9。\n\n如果只看當前數據，異常率是 4/14 = 28.6\\%。但這個樣本太小，誤差很大。如果過去 70 個工廠的平均異常率只有 10%，我們是否該懷疑這 28.6% 只是運氣不好（抽樣誤差）？\n\n\n2. 利用歷史數據估計母體分佈（近似法）\n原文使用大鼠腫瘤的例子，我們繼續沿用上述聽力損失的邏輯：\n\n模型設定：\n\n假設每個工廠的異常人數 y_j 服從二項式分佈（Binomial）。\n每個工廠的風險機率 \\theta_j 服從 Beta 分佈（這是二項式的共軛事前分佈） 10101010。\nBeta 分佈有兩個參數 (\\alpha, \\beta)，這就是我們的 超參數。\n\n簡單估計法（非完全貝氏）：\n\n計算過去 70 個工廠的平均異常率和標準差。\n原文數據：平均值 0.136，標準差 0.103 111111。\n利用公式反推 Beta 分佈的 \\alpha 和 \\beta。原文算出 (\\alpha, \\beta) = (1.4, 8.6) 12。\n意義：這代表「所有類似工廠」的風險分佈大概長這樣。\n\n應用於當前實驗：\n\n將算出來的歷史分佈 Beta(1.4, 8.6) 當作 事前分佈。\n結合當前數據（4 人異常，10 人正常）。\n事後分佈：Beta(1.4+4, 8.6+10) = Beta(5.4, 18.6) 131313。\n結果：新的估計值（事後平均）是 0.223 14。\n比較：\n\n原始數據直接算：0.286 (28.6%)\n加入歷史經驗修正後：0.223 (22.3%)\n專家解讀：因為歷史經驗告訴我們異常率通常較低，所以貝氏方法把那個偏高的 28.6% 往下拉了一點（Shrinkage，這就是平滑化或修正的效果） 15。\n\n\n\n\n\n3. 這種「簡單估計法」的問題\n教科書很誠實地指出了這一節前段方法的缺點，這也是為什麼我們後面需要更進階的階層模式：\n\n問題一：雙重計算（Double Counting）：如果我們把那 70 個歷史工廠的數據拿來算出 \\alpha, \\beta，然後又回頭用這個 \\alpha, \\beta 去評估這 70 個工廠中的某一個，這樣數據被用了兩次，會高估精確度 16。\n問題二：忽略了不確定性：我們直接把 (\\alpha, \\beta) 鎖定為 (1.4, 8.6)，當作這就是真理。但實際上這兩個數字也是估計出來的，也有誤差。直接鎖定會讓我們低估了最終結果的不確定性 17。\n問題三：哲學問題：事前分佈應該是「看數據之前」就有的，怎麼會是看完數據後才算出來的？ 18\n\n\n\n4. 結合資訊的邏輯 (Logic of combining information)\n這是 5.1 節最後非常精彩的思考實驗，解釋了為什麼我們要把它們視為一個整體（Joint Distribution）：\n\n思考實驗：假設有兩個工廠（工廠 26 和工廠 27），它們的數據一模一樣（例如都是 20 人中有 2 人異常）。\n連結性：如果你後來得知工廠 26 的真實風險其實很低（例如 \\theta_{26}=0.1），這會不會影響你對工廠 27 的看法？\n答案：會！ 因為這暗示了這些工廠所屬的「母體環境」可能風險都偏低。既然工廠 26 和 27 很像，26 很低，27 應該也不高 19。\n結論：這兩個參數在事後分佈中應該是 相依的 (Dependent)，不能分開獨立分析 20。這就是階層貝氏模式的核心精神。\n\n\n\n\n\n👨‍🏫 教授的總結與下一步\n在這一節，我們學到了如何用「歷史數據」來建立「事前分佈」。在職業衛生領域，這意味著：\n\n不要丟掉舊資料：過去的暴露監測數據，是評估新製程或新工廠極為寶貴的資產。\n修正小樣本偏差：當新採樣數不足時，利用歷史分佈（階層架構）可以避免我們被極端值誤導。\n注意限制：5.1 節介紹的「先算出固定超參數」的方法（類似 Empirical Bayes）只是近似解，它低估了風險的不確定性。\n\n接下來你能做什麼？\n為了修正上述「忽略超參數不確定性」的問題，我們必須進入 5.2 節 (Exchangeability and hierarchical models) 與 5.3 節，那裡會介紹**「完全貝氏分析（Fully Bayesian Analysis）」**，也就是將 $\\alpha, \\beta$ 也視為隨機變數來處理。\n請問您希望我繼續為您講解 5.2 節：可交換性 (Exchangeability) 的概念嗎？這在判斷哪些工廠或SEG可以合併分析時非常重要。\n:::"
  },
  {
    "objectID": "0118CH5.html#階層模型",
    "href": "0118CH5.html#階層模型",
    "title": "0118CH5 階層模型",
    "section": "階層模型",
    "text": "階層模型"
  }
]